\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\BKM@entry{id=1,dest={7469746C652E31},srcline={10}}{545C33353574756C6F}
\babel@aux{spanish}{}
\BKM@entry{id=2,dest={636861707465722A2E32},srcline={8}}{41677261646563696D69656E746F73}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Agradecimientos}{\es@scroman  {vii}}{chapter*.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\BKM@entry{id=3,dest={746F632E30},srcline={8}}{5C3331356E646963652067656E6572616C}
\BKM@entry{id=4,dest={636861707465722A2E37},srcline={9}}{4162737472616374}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Abstract}{\es@scroman  {xiii}}{chapter*.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\babel@aux{spanish}{}
\BKM@entry{id=5,dest={636861707465722A2E38},srcline={11}}{526573756D656E}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Resumen}{\es@scroman  {xv}}{chapter*.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\BKM@entry{id=6,dest={706172742E31},srcline={241}}{416E5C3334316C6973697320646520526564657320436F6E766F6C7563696F6E616C6573}
\@writefile{toc}{\contentsline {part}{\numberline {I}Análisis de Redes Convolucionales}{1}{part.1}\protected@file@percent }
\BKM@entry{id=7,dest={636861707465722E31},srcline={5}}{496E74726F64756363695C3336336E}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introducción}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Los tres coches deben identificarse como iguales, aunque se ecuentren desplazados.}}{3}{figure.1.1}\protected@file@percent }
\newlabel{fig:invarianza_traslaciones}{{1.1}{3}{Los tres coches deben identificarse como iguales, aunque se ecuentren desplazados}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Acción de un difeomorfismo en una rejilla.}}{4}{figure.1.2}\protected@file@percent }
\newlabel{fig:difeomorfismo}{{1.2}{4}{Acción de un difeomorfismo en una rejilla}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Todas las imágenes deberían clasificarse como 5, pese a las deformaciones.}}{4}{figure.1.3}\protected@file@percent }
\newlabel{fig:deformaciones_5}{{1.3}{4}{Todas las imágenes deberían clasificarse como 5, pese a las deformaciones}{figure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Deformación excesiva que permite confundir el 1 con el 2 cuando se le aplica el difeomorfismo. Por eso nos centramos en \emph  {``pequeñas''} deformaciones, para no alterar la identidad del objeto en la imagen.}}{4}{figure.1.4}\protected@file@percent }
\newlabel{fig:deformaciones_1}{{1.4}{4}{Deformación excesiva que permite confundir el 1 con el 2 cuando se le aplica el difeomorfismo. Por eso nos centramos en \entrecomillado {pequeñas} deformaciones, para no alterar la identidad del objeto en la imagen}{figure.1.4}{}}
\newlabel{eq::distancia}{{1.0.6}{5}{}{teorema.1.0.6}{}}
\newlabel{def::Lipschitz_cont}{{1.0.7}{6}{}{teorema.1.0.7}{}}
\newlabel{eq::Lipschitz_condition}{{1.1}{6}{}{equation.1.0.1}{}}
\MT@newlabel{eq::Lipschitz_condition}
\MT@newlabel{eq::Lipschitz_condition}
\BKM@entry{id=8,dest={636861707465722E32},srcline={4}}{4D6F64656C697A6163695C3336336E204D6174656D5C3334317469636120646520756E6120526564204E6575726F6E616C20436F6E766F6C7563696F6E616C}
\citation{GroupInvariantScattering}
\BKM@entry{id=9,dest={73656374696F6E2E322E31},srcline={21}}{446520466F75726965722061206C6173206F6E64656C65746173206465204C6974746C65776F6F642D50616C6579}
\BKM@entry{id=10,dest={73756273656374696F6E2E322E312E31},srcline={23}}{456C206D5C33363364756C6F206465206C61205472616E73666F726D61646120646520466F7572696572}
\citation{DigitalImageProcessing}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Modelización Matemática de una Red Neuronal Convolucional}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{brf}{\backcite{GroupInvariantScattering}{{7}{2}{chapter.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}De Fourier a las ondeletas de Littlewood-Paley}{7}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}El módulo de la Transformada de Fourier}{7}{subsection.2.1.1}\protected@file@percent }
\@writefile{brf}{\backcite{DigitalImageProcessing}{{7}{2.1.1}{subsection.2.1.1}}}
\newlabel{lema::invarianza_traslaciones}{{2.1.2}{8}{}{teorema.2.1.2}{}}
\newlabel{eq::lipschitz_condition}{{2.1}{8}{El módulo de la Transformada de Fourier}{equation.2.1.1}{}}
\newlabel{eq:res_auxiliar_1}{{2.2}{9}{El módulo de la Transformada de Fourier}{equation.2.1.2}{}}
\newlabel{eq:res_auxiliar_2}{{2.3}{9}{El módulo de la Transformada de Fourier}{equation.2.1.3}{}}
\MT@newlabel{eq:res_auxiliar_1}
\MT@newlabel{eq:res_auxiliar_2}
\newlabel{eq::1.1}{{2.1.1}{11}{El módulo de la Transformada de Fourier}{equation.2.1.3}{}}
\newlabel{eq::Plancharel}{{2.4}{11}{El módulo de la Transformada de Fourier}{equation.2.1.4}{}}
\MT@newlabel{eq::lipschitz_condition}
\BKM@entry{id=11,dest={73756273656374696F6E2E322E312E32},srcline={212}}{416C7465726E61746976613A204C6173206F6E64656C65746173}
\citation{MallatWavelets}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Como podemos ver en la imagen, para los valores $\epsilon =0.1$, $\xi =100$ y $M=5$ ambas funciones tienen soporte casi disjunto de manera que la diferencia entre ellas en el intervalo $[-5,5]$ coincide prácticamente con $g_1(t)$.}}{12}{figure.2.1}\protected@file@percent }
\newlabel{fig:Grafica_funciones}{{2.1}{12}{Como podemos ver en la imagen, para los valores $\epsilon =0.1$, $\xi =100$ y $M=5$ ambas funciones tienen soporte casi disjunto de manera que la diferencia entre ellas en el intervalo $[-5,5]$ coincide prácticamente con $g_1(t)$}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Alternativa: Las ondeletas}{12}{subsection.2.1.2}\protected@file@percent }
\@writefile{brf}{\backcite{MallatWavelets}{{12}{2.1.2}{subsection.2.1.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Representación gráfica de la ondeleta de Haar.}}{13}{figure.2.2}\protected@file@percent }
\newlabel{fig:Ondeleta_de_Haar}{{2.2}{13}{Representación gráfica de la ondeleta de Haar}{figure.2.2}{}}
\citation{MallatWavelets}
\citation{HaarBasis}
\citation{HaarBasis}
\@writefile{brf}{\backcite{MallatWavelets}{{14}{2.1.2}{figure.2.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces En el ejemplo $1)$ podemos ver un ejemplo de filtro generado por el soporte de una ondeleta para la detección de líneas bordes verticales, en la imagen $2)$ podemos ver un ejemplo de filtro generado por el soporte de una ondeleta para la detección de bordes horizontales, y en el ejemplo $3)$ para las diagonales. Todas tienen soporte cuadrado.}}{14}{figure.2.3}\protected@file@percent }
\newlabel{fig:base_haar}{{2.3}{14}{En el ejemplo $1)$ podemos ver un ejemplo de filtro generado por el soporte de una ondeleta para la detección de líneas bordes verticales, en la imagen $2)$ podemos ver un ejemplo de filtro generado por el soporte de una ondeleta para la detección de bordes horizontales, y en el ejemplo $3)$ para las diagonales. Todas tienen soporte cuadrado}{figure.2.3}{}}
\BKM@entry{id=12,dest={73756273656374696F6E2E322E312E33},srcline={333}}{4C61205472616E73666F726D616461206465204C6974746C65776F6F642D50616C6579}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Ejemplos de aplicar la base de Haar a dos imágenes. Los filtros resaltan los bordes en tres direcciones, horizontal (derecha) vertical (abajo) y en diagonal (abajo derecha). Imagen extraída de \cite  {HaarBasis}.}}{15}{figure.2.4}\protected@file@percent }
\@writefile{brf}{\backcite{HaarBasis}{{15}{2.4}{figure.2.4}}}
\newlabel{fig:ejemplo_haar}{{2.4}{15}{Ejemplos de aplicar la base de Haar a dos imágenes. Los filtros resaltan los bordes en tres direcciones, horizontal (derecha) vertical (abajo) y en diagonal (abajo derecha). Imagen extraída de \cite {HaarBasis}}{figure.2.4}{}}
\citation{WAVELETS}
\citation{WAVELETS}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}La Transformada de Littlewood-Paley}{16}{subsection.2.1.3}\protected@file@percent }
\newlabel{ch:seccion12}{{2.1.3}{16}{La Transformada de Littlewood-Paley}{subsection.2.1.3}{}}
\newlabel{Teorema::Convolucion}{{2.1.4}{16}{}{teorema.2.1.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Como podemos ver, en el caso de la izquierda la ondeleta (en color morado) se ve afectada por una menor escala, lo que le permitirá detectar con mayores frecuencias los cambios que se producen en la señal al convolucionar con esta a lo largo del tiempo. En cambio, en el segundo caso, se ve afectada por una escala mayor, lo que le impedirá detectar con tanta precisión los cambios que se produzcan en la señal. Imagen extraída de \cite  {WAVELETS}.}}{17}{figure.2.5}\protected@file@percent }
\@writefile{brf}{\backcite{WAVELETS}{{17}{2.5}{figure.2.5}}}
\newlabel{fig:small_long_scale}{{2.5}{17}{Como podemos ver, en el caso de la izquierda la ondeleta (en color morado) se ve afectada por una menor escala, lo que le permitirá detectar con mayores frecuencias los cambios que se producen en la señal al convolucionar con esta a lo largo del tiempo. En cambio, en el segundo caso, se ve afectada por una escala mayor, lo que le impedirá detectar con tanta precisión los cambios que se produzcan en la señal. Imagen extraída de \cite {WAVELETS}}{figure.2.5}{}}
\newlabel{eq::norma}{{2.5}{17}{La Transformada de Littlewood-Paley}{equation.2.1.5}{}}
\newlabel{unitario}{{2.1.5}{18}{}{teorema.2.1.5}{}}
\newlabel{eq::1.2}{{2.6}{18}{}{equation.2.1.6}{}}
\MT@newlabel{eq::1.2}
\newlabel{eq::1.3}{{2.7}{18}{La Transformada de Littlewood-Paley}{equation.2.1.7}{}}
\MT@newlabel{eq::1.2}
\MT@newlabel{eq::1.2}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::1.2}
\MT@newlabel{eq::1.3}
\BKM@entry{id=13,dest={73756273656374696F6E2E322E312E34},srcline={509}}{436F6E76656E696F73207061726120667574757261732073656363696F6E6573}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::Plancharel}
\MT@newlabel{eq::norma}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::1.2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Convenios para futuras secciones}{19}{subsection.2.1.4}\protected@file@percent }
\MT@newlabel{eq::1.2}
\BKM@entry{id=14,dest={73656374696F6E2E322E32},srcline={539}}{456C206F70657261646F722064652064697370657273695C3336336E20736F62726520756E2063616D696E6F206F7264656E61646F}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}El operador de dispersión sobre un camino ordenado}{20}{section.2.2}\protected@file@percent }
\newlabel{lema:Invarianza_traslaciones_integral}{{2.2.1}{20}{}{teorema.2.2.1}{}}
\BKM@entry{id=15,dest={73756273656374696F6E2E322E322E31},srcline={592}}{456A656D706C6F2070617261206F6274656E657220636F6566696369656E74657320696E76617269616E74657320706F7220747261736C6163696F6E6573}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Ejemplo para obtener coeficientes invariantes por traslaciones}{21}{subsection.2.2.1}\protected@file@percent }
\newlabel{eq::1.4}{{2.8}{21}{Ejemplo para obtener coeficientes invariantes por traslaciones}{equation.2.2.8}{}}
\BKM@entry{id=16,dest={73756273656374696F6E2E322E322E32},srcline={629}}{456C206F70657261646F72206D5C33363364756C6F}
\citation{JBrunaOperatorsCommutingDiff}
\citation{GroupInvariantScattering}
\citation{bruna2013invariant}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}El operador módulo}{22}{subsection.2.2.2}\protected@file@percent }
\@writefile{brf}{\backcite{JBrunaOperatorsCommutingDiff}{{22}{2.2.2}{subsection.2.2.2}}}
\@writefile{brf}{\backcite{GroupInvariantScattering}{{22}{2.2.2}{subsection.2.2.2}}}
\@writefile{brf}{\backcite{bruna2013invariant}{{22}{2.2.2}{subsection.2.2.2}}}
\MT@newlabel{eq::1.4}
\BKM@entry{id=17,dest={73756273656374696F6E2E322E322E33},srcline={679}}{446566696E6963695C3336336E2064652063616D696E6F206465206672656375656E6369617320792070726F70696564616465732E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Definición de camino de frecuencias y propiedades.}{23}{subsection.2.2.3}\protected@file@percent }
\BKM@entry{id=18,dest={73756273656374696F6E2E322E322E34},srcline={743}}{436F6E737472756363695C3336336E2064656C206F70657261646F722064652064697370657273695C3336336E2E}
\newlabel{proposicionSumaCaminos}{{2.2.6}{24}{}{teorema.2.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Construcción del operador de dispersión.}{24}{subsection.2.2.4}\protected@file@percent }
\newlabel{def:S_barra}{{2.2.7}{24}{}{teorema.2.2.7}{}}
\citation{GroupInvariantScattering}
\BKM@entry{id=19,dest={73656374696F6E2E322E33},srcline={818}}{50726F70616761646F722064652064697370657273695C3336336E207920636F6E736572766163695C3336336E206465206C61204E6F726D61}
\BKM@entry{id=20,dest={73756273656374696F6E2E322E332E31},srcline={821}}{50726F6365736F2064652064697370657273695C3336336E2064656C2070726F70616761646F722E}
\@writefile{brf}{\backcite{GroupInvariantScattering}{{26}{2.2.4}{teorema.2.2.8}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Propagador de dispersión y conservación de la Norma}{26}{section.2.3}\protected@file@percent }
\newlabel{ch:seccion13}{{2.3}{26}{Propagador de dispersión y conservación de la Norma}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Proceso de dispersión del propagador.}{26}{subsection.2.3.1}\protected@file@percent }
\citation{bruna2013invariant}
\citation{bruna2013invariant}
\BKM@entry{id=21,dest={73756273656374696F6E2E322E332E32},srcline={862}}{4469666572656E6369617320792073696D696C69747564657320636F6E20756E6120434E4E}
\citation{lecun2015deep}
\newlabel{eq::1.5}{{2.9}{27}{Proceso de dispersión del propagador}{equation.2.3.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Un PD $U_J$ aplicado a un punto de una señal $f(x)$ calcula $U[\lambda _1]f(x)=|f(x)\ast \psi _{\lambda _1}|$ y como salida a la capa $m=0$ se promedian los coeficientes que han dado $0$ (por tener $2^j<2^{-J}$) obteniendo como salida $S_J[\emptyset ]f(x)=f(x)\ast \phi _{2^J}$ (como se puede ver en la flecha negra). Después se aplica de nuevo $U_J$ a cada coeficiente $U[\lambda _1]f(x)$ del paso anterior ($m=1$) $U[\lambda _1,\lambda 2]f(x)$ obteniendo como salida $S_J[\lambda _1]f(x)=U[\lambda _1]f(x) \ast \phi _{2^J}$. Se repite este proceso de manera recursiva para cada coeficiente $U[p]f(x)$ y obteniendo como resultado $S_J[p]f(x)=U[p]f(x) \ast \phi _{2^J}$. Imagen extraída de \cite  {bruna2013invariant}.}}{27}{figure.2.6}\protected@file@percent }
\@writefile{brf}{\backcite{bruna2013invariant}{{27}{2.6}{figure.2.6}}}
\newlabel{fig:arbol_propag}{{2.6}{27}{Un PD $U_J$ aplicado a un punto de una señal $f(x)$ calcula $U[\lambda _1]f(x)=|f(x)\ast \psi _{\lambda _1}|$ y como salida a la capa $m=0$ se promedian los coeficientes que han dado $0$ (por tener $2^j<2^{-J}$) obteniendo como salida $S_J[\emptyset ]f(x)=f(x)\ast \phi _{2^J}$ (como se puede ver en la flecha negra). Después se aplica de nuevo $U_J$ a cada coeficiente $U[\lambda _1]f(x)$ del paso anterior ($m=1$) $U[\lambda _1,\lambda 2]f(x)$ obteniendo como salida $S_J[\lambda _1]f(x)=U[\lambda _1]f(x) \ast \phi _{2^J}$. Se repite este proceso de manera recursiva para cada coeficiente $U[p]f(x)$ y obteniendo como resultado $S_J[p]f(x)=U[p]f(x) \ast \phi _{2^J}$. Imagen extraída de \cite {bruna2013invariant}}{figure.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Diferencias y similitudes con una CNN}{27}{subsection.2.3.2}\protected@file@percent }
\@writefile{brf}{\backcite{lecun2015deep}{{27}{2.3.2}{subsection.2.3.2}}}
\BKM@entry{id=22,dest={73756273656374696F6E2E322E332E33},srcline={878}}{52656C6163695C3336336E20636F6E2068657272616D69656E74617320636C5C333431736963617320646520766973695C3336336E20706F7220636F6D70757461646F72}
\citation{DistinctiveImageFeatures}
\citation{Daisy}
\BKM@entry{id=23,dest={73756273656374696F6E2E322E332E34},srcline={882}}{4F70657261646F72206E6F20657870616E7369766F2E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Relación con herramientas clásicas de visión por computador}{28}{subsection.2.3.3}\protected@file@percent }
\@writefile{brf}{\backcite{DistinctiveImageFeatures}{{28}{2.3.3}{subsection.2.3.3}}}
\@writefile{brf}{\backcite{Daisy}{{28}{2.3.3}{subsection.2.3.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Operador no expansivo.}{28}{subsection.2.3.4}\protected@file@percent }
\newlabel{proposicion::NoExpansiva}{{2.3.1}{28}{}{teorema.2.3.1}{}}
\MT@newlabel{eq::1.5}
\BKM@entry{id=24,dest={73756273656374696F6E2E322E332E35},srcline={953}}{436F6E736572766163695C3336336E206465206C61206E6F726D612E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Conservación de la norma.}{29}{subsection.2.3.5}\protected@file@percent }
\newlabel{lema::Cota_inferior}{{2.3.2}{29}{}{teorema.2.3.2}{}}
\citation{GroupInvariantScattering}
\newlabel{eq::1.6}{{2.10}{30}{}{equation.2.3.10}{}}
\newlabel{eq::1.7}{{2.11}{30}{}{equation.2.3.11}{}}
\newlabel{lema::Admisibilidad}{{2.3.4}{30}{}{teorema.2.3.4}{}}
\MT@newlabel{eq::1.7}
\newlabel{eq::1.9}{{2.12}{30}{}{equation.2.3.12}{}}
\@writefile{brf}{\backcite{GroupInvariantScattering}{{30}{2.3.5}{equation.2.3.12}}}
\newlabel{teoremaOndeletasAdmisibles}{{2.3.5}{30}{}{teorema.2.3.5}{}}
\MT@newlabel{eq::1.6}
\MT@newlabel{eq::1.9}
\newlabel{eq::1.8}{{2.13}{31}{Conservación de la norma}{equation.2.3.13}{}}
\MT@newlabel{eq::1.8}
\BKM@entry{id=25,dest={73756273656374696F6E2E322E332E36},srcline={1135}}{436F6E636C7573696F6E65732065787472615C3335356461732064656C2074656F72656D61}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Conclusiones extraídas del teorema}{33}{subsection.2.3.6}\protected@file@percent }
\BKM@entry{id=26,dest={636861707465722E33},srcline={3}}{496E76617269616E7A6120706F7220547261736C6163696F6E6573}
\BKM@entry{id=27,dest={73656374696F6E2E332E31},srcline={7}}{4E6F20657870616E736976696461642064656C206F70657261646F722064652076656E74616E6120656E20636F6E6A756E746F732064652063616D696E6F73}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Invarianza por Traslaciones}{35}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:seccion14}{{3}{35}{Invarianza por Traslaciones}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}No expansividad del operador de ventana en conjuntos de caminos}{35}{section.3.1}\protected@file@percent }
\newlabel{eq::1.10}{{3.1}{35}{}{equation.3.1.1}{}}
\MT@newlabel{eq::1.10}
\newlabel{eq::1.11}{{3.2}{35}{No expansividad del operador de ventana en conjuntos de caminos}{equation.3.1.2}{}}
\MT@newlabel{eq::1.11}
\MT@newlabel{eq::1.10}
\MT@newlabel{eq::1.11}
\BKM@entry{id=28,dest={73656374696F6E2E332E32},srcline={146}}{496E76617269616E7A6120706F7220747261736C6163696F6E6573}
\MT@newlabel{eq::1.11}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Invarianza por traslaciones}{38}{section.3.2}\protected@file@percent }
\MT@newlabel{eq::1.7}
\newlabel{lemma:Schur}{{3.2.1}{38}{}{teorema.3.2.1}{}}
\newlabel{lema::constante}{{3.2.2}{38}{}{teorema.3.2.2}{}}
\newlabel{invarianzaTraslaciones}{{3.2.3}{40}{}{teorema.3.2.3}{}}
\MT@newlabel{eq::1.7}
\MT@newlabel{eq::1.9}
\BKM@entry{id=29,dest={636861707465722E34},srcline={3}}{436F6E636C7573696F6E657320792074726162616A6F732066757475726F73}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Conclusiones y trabajos futuros}{43}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\BKM@entry{id=30,dest={73656374696F6E2E342E31},srcline={57}}{54726162616A6F732066757475726F73}
\@writefile{toc}{\contentsline {section}{\numberline {4.1}Trabajos futuros}{44}{section.4.1}\protected@file@percent }
\BKM@entry{id=31,dest={706172742E32},srcline={248}}{4C6F63616C697A6163695C3336336E206465206C616E646D61726B7320636566616C6F6D5C333531747269636F7320706F72206D6564696F20646520745C333531636E69636173206465206665772D73686F74206C6561726E696E67}
\@writefile{toc}{\contentsline {part}{\numberline {II}Localización de landmarks cefalométricos por medio de técnicas de few-shot learning}{45}{part.2}\protected@file@percent }
\BKM@entry{id=32,dest={636861707465722E35},srcline={4}}{496E74726F64756363695C3336336E}
\citation{norvig2002modern}
\BKM@entry{id=33,dest={73656374696F6E2E352E31},srcline={22}}{4465736372697063695C3336336E2064656C2070726F626C656D612079204D6F7469766163695C3336336E}
\citation{Huete2015PastPA}
\citation{article}
\citation{article}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Introducción}{47}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:Introduccion_informatica}{{5}{47}{Introducción}{chapter.5}{}}
\@writefile{brf}{\backcite{norvig2002modern}{{47}{5}{chapter.5}}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Descripción del problema y Motivación}{47}{section.5.1}\protected@file@percent }
\citation{damas2020handbook}
\citation{damas2020handbook}
\@writefile{brf}{\backcite{Huete2015PastPA}{{48}{5.1}{section.5.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Etapas del proceso de superposición craneofacial. En primer lugar se realiza la recogida de imágenes ante-mortem (AM) y muestras post-mortem (PM) junto con el marcado de landmarks y escaneo $3D$ del cráneo candidato. Tras esto comienza el experto comienza el proceso iterativo en el que trata de hacer coincidir los landmarks cefalométricos y craneométricos. Finalmente se realiza una toma de decisiones en función de los resultados obtenidos. Imagen extraída de \cite  {article}.}}{48}{figure.5.1}\protected@file@percent }
\@writefile{brf}{\backcite{article}{{48}{5.1}{figure.5.1}}}
\newlabel{fig:procesoSCF}{{5.1}{48}{Etapas del proceso de superposición craneofacial. En primer lugar se realiza la recogida de imágenes ante-mortem (AM) y muestras post-mortem (PM) junto con el marcado de landmarks y escaneo $3D$ del cráneo candidato. Tras esto comienza el experto comienza el proceso iterativo en el que trata de hacer coincidir los landmarks cefalométricos y craneométricos. Finalmente se realiza una toma de decisiones en función de los resultados obtenidos. Imagen extraída de \cite {article}}{figure.5.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces En esta imagen podemos ver la correspondencia entre landmarks craneométricos y cefalométricos. Algunos de los landmarks que aparecen en la imagen serán estudiados en este trabajo. Imagen extraída de \cite  {damas2020handbook}.}}{48}{figure.5.2}\protected@file@percent }
\@writefile{brf}{\backcite{damas2020handbook}{{48}{5.2}{figure.5.2}}}
\newlabel{fig:landmarks_marcados}{{5.2}{48}{En esta imagen podemos ver la correspondencia entre landmarks craneométricos y cefalométricos. Algunos de los landmarks que aparecen en la imagen serán estudiados en este trabajo. Imagen extraída de \cite {damas2020handbook}}{figure.5.2}{}}
\citation{browatzki20203fabrec}
\BKM@entry{id=34,dest={73756273656374696F6E2E352E312E31},srcline={99}}{42617365206465206461746F732070726F706F7263696F6E616461}
\@writefile{brf}{\backcite{browatzki20203fabrec}{{49}{5.1}{figure.5.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1.1}Base de datos proporcionada}{49}{subsection.5.1.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5.1}{\ignorespaces Landmarks que se intentarán predecir.}}{50}{table.5.1}\protected@file@percent }
\newlabel{table:tabla_landmarks}{{5.1}{50}{Landmarks que se intentarán predecir}{table.5.1}{}}
\BKM@entry{id=35,dest={73656374696F6E2E352E32},srcline={130}}{52657175697369746F73206D5C3335356E696D6F732064656C20616C676F7269746D6F}
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Imágenes de ejemplo del dataset proporcionado. Como puede observarse hay gran variedad de tamaños, poses, condiciones de iluminación diferentes que añaden dificultad al problema.}}{51}{figure.5.3}\protected@file@percent }
\newlabel{fig:Imagenes_dataset}{{5.3}{51}{Imágenes de ejemplo del dataset proporcionado. Como puede observarse hay gran variedad de tamaños, poses, condiciones de iluminación diferentes que añaden dificultad al problema}{figure.5.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Requisitos mínimos del algoritmo}{51}{section.5.2}\protected@file@percent }
\BKM@entry{id=36,dest={73656374696F6E2E352E33},srcline={145}}{4F626A657469766F73}
\BKM@entry{id=37,dest={73656374696F6E2E352E34},srcline={156}}{506C616E696669636163695C3336336E}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Histograma con la aparición de cada tipo de landmark en las imágenes del dataset.}}{52}{figure.5.4}\protected@file@percent }
\newlabel{fig:Histograma}{{5.4}{52}{Histograma con la aparición de cada tipo de landmark en las imágenes del dataset}{figure.5.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Objetivos}{52}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Planificación}{53}{section.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Diseño en cascada retroalimentado empleado.}}{53}{figure.5.5}\protected@file@percent }
\newlabel{Fig::Ciclo de vida}{{5.5}{53}{Diseño en cascada retroalimentado empleado}{figure.5.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.6}{\ignorespaces Planificación original.}}{54}{figure.5.6}\protected@file@percent }
\newlabel{Fig::Planificacion original}{{5.6}{54}{Planificación original}{figure.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.7}{\ignorespaces Planificación final.}}{55}{figure.5.7}\protected@file@percent }
\newlabel{Fig::Planificacion final}{{5.7}{55}{Planificación final}{figure.5.7}{}}
\BKM@entry{id=38,dest={636861707465722E36},srcline={2}}{46756E64616D656E746F732054655C3336337269636F732079204D5C333531746F646F73}
\BKM@entry{id=39,dest={73656374696F6E2E362E31},srcline={6}}{417072656E64697A616A65204175746F6D5C3334317469636F}
\BKM@entry{id=40,dest={73756273656374696F6E2E362E312E31},srcline={34}}{417072656E64697A616A6520537570657276697361646F}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Fundamentos Teóricos y Métodos}{57}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Aprendizaje Automático}{57}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Aprendizaje Supervisado}{58}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.1}Regresión}{58}{subsubsection.6.1.1.1}\protected@file@percent }
\newlabel{section::Regresion}{{6.1.1.1}{58}{Regresión}{subsubsection.6.1.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.2}Clasificación}{59}{subsubsection.6.1.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.3}Gradiente Descendente}{59}{subsubsection.6.1.1.3}\protected@file@percent }
\citation{StanfordCourse}
\citation{StanfordCourse}
\BKM@entry{id=41,dest={73756273656374696F6E2E362E312E32},srcline={164}}{417072656E64697A616A65206E6F20537570657276697361646F}
\BKM@entry{id=42,dest={73756273656374696F6E2E362E312E33},srcline={167}}{417072656E64697A616A65204175746F6D5C3334317469636F20656E20657374652054726162616A6F}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.4}Gradiente Descendente Estocástico}{60}{subsubsection.6.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Aprendizaje no Supervisado}{60}{subsection.6.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Aprendizaje Automático en este Trabajo}{60}{subsection.6.1.3}\protected@file@percent }
\citation{savvides2004eigenphases}
\BKM@entry{id=43,dest={73756273656374696F6E2E362E312E34},srcline={182}}{566973695C3336336E20706F7220436F6D70757461646F72}
\citation{rosenfeld1988computer}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Pretendemos alcanzar el mínimo de la función representada en las imágenes de la primera fila. Podemos ver el impacto de la elección del learning rate, si es muy pequeño, harán falta muchas iteraciones hasta la convergencia (primera imagen), si tiene un tamaño adecuado, converge rápidamente a la solución (segunda imagen), si es grande, puede quedar \emph  {``atrapado''} el algoritmo (tercera imagen), y si es demasiado grande podría incluso diverger. Imagen extraída de \cite  {StanfordCourse}.}}{61}{figure.6.1}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{61}{6.1}{figure.6.1}}}
\newlabel{fig:learning_rate}{{6.1}{61}{Pretendemos alcanzar el mínimo de la función representada en las imágenes de la primera fila. Podemos ver el impacto de la elección del learning rate, si es muy pequeño, harán falta muchas iteraciones hasta la convergencia (primera imagen), si tiene un tamaño adecuado, converge rápidamente a la solución (segunda imagen), si es grande, puede quedar \entrecomillado {atrapado} el algoritmo (tercera imagen), y si es demasiado grande podría incluso diverger. Imagen extraída de \cite {StanfordCourse}}{figure.6.1}{}}
\@writefile{brf}{\backcite{savvides2004eigenphases}{{61}{6.1.3}{subsection.6.1.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.4}Visión por Computador}{61}{subsection.6.1.4}\protected@file@percent }
\@writefile{brf}{\backcite{rosenfeld1988computer}{{61}{6.1.4}{subsection.6.1.4}}}
\BKM@entry{id=44,dest={73756273656374696F6E2E362E312E35},srcline={193}}{44656570204C6561726E696E67}
\citation{Goodfellow-et-al-2016}
\citation{sharma2017activation}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.5}Deep Learning}{62}{subsection.6.1.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.5.1}Redes Neuronales}{62}{subsubsection.6.1.5.1}\protected@file@percent }
\newlabel{sub:redes_neuronales}{{6.1.5.1}{62}{Redes Neuronales}{subsubsection.6.1.5.1}{}}
\@writefile{brf}{\backcite{Goodfellow-et-al-2016}{{62}{6.1.5.1}{subsubsection.6.1.5.1}}}
\@writefile{brf}{\backcite{sharma2017activation}{{62}{6.1.5.1}{figure.6.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Red neuronal con una capa oculta. Formalmente podría describirse como $f'(x)=(f_2(f_1(x)))$, donde $f_2$ hace referencia a la transformación de los datos de entrada a la capa oculta y $f_3$ de la capa oculta a la de salida.}}{63}{figure.6.2}\protected@file@percent }
\newlabel{fig:red_neuronal_capa_oculta}{{6.2}{63}{Red neuronal con una capa oculta. Formalmente podría describirse como $f'(x)=(f_2(f_1(x)))$, donde $f_2$ hace referencia a la transformación de los datos de entrada a la capa oculta y $f_3$ de la capa oculta a la de salida}{figure.6.2}{}}
\citation{sharma2017activation}
\citation{sharma2017activation}
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Representación gráfica de las funciones de activación más empleadas. La imagen ha sido extraída de \cite  {sharma2017activation}.}}{64}{figure.6.3}\protected@file@percent }
\@writefile{brf}{\backcite{sharma2017activation}{{64}{6.3}{figure.6.3}}}
\newlabel{fig:GrafoComputacional}{{6.3}{64}{Representación gráfica de las funciones de activación más empleadas. La imagen ha sido extraída de \cite {sharma2017activation}}{figure.6.3}{}}
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{StanfordCourse}
\BKM@entry{id=45,dest={73656374696F6E2E362E32},srcline={307}}{5265646573204E6575726F6E616C657320436F6E766F6C7563696F6E616C6573}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.5.2}Backpropagation}{65}{subsubsection.6.1.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Ejemplo de Grafo computacional junto con la salida para una entrada concreta $x=-2$,$y=5$, $z=-4$. La imagen ha sido extraída del curso \cite  {StanfordCourse}.}}{65}{figure.6.4}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{65}{6.4}{figure.6.4}}}
\newlabel{fig:GrafoComputacional}{{6.4}{65}{Ejemplo de Grafo computacional junto con la salida para una entrada concreta $x=-2$,$y=5$, $z=-4$. La imagen ha sido extraída del curso \cite {StanfordCourse}}{figure.6.4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Redes Neuronales Convolucionales}{65}{section.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Como podemos ver en la imagen superior, en primer lugar se renombra la salida de la operación $x+y$ por $q$, de manera que $f=qz$. Tras esto se empiezan a calcular las derivadas parciales correspondientes desde el final hacia la entrada, aplicando cuando sea necesario la regla de la cadena hasta obtener la derivada de cada nodo en la imagen de abajo. Las imágenes han sido extraídas de \cite  {StanfordCourse}}}{66}{figure.6.5}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{66}{6.5}{figure.6.5}}}
\newlabel{fig:Ejemplo BP}{{6.5}{66}{Como podemos ver en la imagen superior, en primer lugar se renombra la salida de la operación $x+y$ por $q$, de manera que $f=qz$. Tras esto se empiezan a calcular las derivadas parciales correspondientes desde el final hacia la entrada, aplicando cuando sea necesario la regla de la cadena hasta obtener la derivada de cada nodo en la imagen de abajo. Las imágenes han sido extraídas de \cite {StanfordCourse}}{figure.6.5}{}}
\BKM@entry{id=46,dest={73756273656374696F6E2E362E322E31},srcline={359}}{4361706120436F6E766F6C7563696F6E616C}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Capa Convolucional}{67}{subsection.6.2.1}\protected@file@percent }
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{StanfordCourse}
\BKM@entry{id=47,dest={73756273656374696F6E2E362E322E32},srcline={392}}{4361706120646520506F6F6C696E67}
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Ejemplo de cálculo de mapa de activación en una capa convolucional para un determinado volumen de entrada. El parámetro depth nos dice la cantidad de mapas de activación generamos para el volumen de entrada, o dicho de otro modo, el número de filtros que aplicamos. La imagen ha sido extraída de \cite  {StanfordCourse}}}{68}{figure.6.6}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{68}{6.6}{figure.6.6}}}
\newlabel{fig:mapa_activacion}{{6.6}{68}{Ejemplo de cálculo de mapa de activación en una capa convolucional para un determinado volumen de entrada. El parámetro depth nos dice la cantidad de mapas de activación generamos para el volumen de entrada, o dicho de otro modo, el número de filtros que aplicamos. La imagen ha sido extraída de \cite {StanfordCourse}}{figure.6.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Sucesión de varias capas convolucionales + ReLU que describen la estructura básica de una CNN. Cabe destacar como la produndidad de los filtros es siempre la misma que la del volumen de entrada, de acuerdo a lo que hemos dicho anteriormente. La imagen han sido extraída de \cite  {StanfordCourse}}}{68}{figure.6.7}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{68}{6.7}{figure.6.7}}}
\newlabel{fig:estructura_convnet}{{6.7}{68}{Sucesión de varias capas convolucionales + ReLU que describen la estructura básica de una CNN. Cabe destacar como la produndidad de los filtros es siempre la misma que la del volumen de entrada, de acuerdo a lo que hemos dicho anteriormente. La imagen han sido extraída de \cite {StanfordCourse}}{figure.6.7}{}}
\citation{StanfordCourse}
\citation{StanfordCourse}
\BKM@entry{id=48,dest={73756273656374696F6E2E362E322E33},srcline={413}}{4361706120546F74616C6D656E746520436F6E656374616461205C2846756C6C7920436F6E65637465645C29}
\BKM@entry{id=49,dest={73756273656374696F6E2E362E322E34},srcline={420}}{4261746368204E6F726D616C697A6174696F6E}
\BKM@entry{id=50,dest={73756273656374696F6E2E362E322E35},srcline={423}}{4F7074696D697A61646F72204164616D}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Capa de Pooling}{69}{subsection.6.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Ejemplo de capa de pooling usando la operación del máximo. La imagen han sido extraída de \cite  {StanfordCourse}}}{69}{figure.6.8}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{69}{6.8}{figure.6.8}}}
\newlabel{fig:pooling}{{6.8}{69}{Ejemplo de capa de pooling usando la operación del máximo. La imagen han sido extraída de \cite {StanfordCourse}}{figure.6.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Capa Totalmente Conectada (Fully Conected)}{69}{subsection.6.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Batch Normalization}{69}{subsection.6.2.4}\protected@file@percent }
\BKM@entry{id=51,dest={73756273656374696F6E2E362E322E36},srcline={426}}{50726F6365736F20646520656E7472656E616D69656E746F20646520756E6120434E4E}
\BKM@entry{id=52,dest={73656374696F6E2E362E33},srcline={553}}{4175746F656E636F64657273}
\BKM@entry{id=53,dest={73756273656374696F6E2E362E332E31},srcline={556}}{496E74726F64756363695C3336336E}
\citation{autoencoders2017}
\citation{autoencoders2017}
\citation{autoencoders2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.5}Optimizador Adam}{70}{subsection.6.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.6}Proceso de entrenamiento de una CNN}{70}{subsection.6.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Autoencoders}{70}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Introducción}{70}{subsection.6.3.1}\protected@file@percent }
\@writefile{brf}{\backcite{autoencoders2017}{{70}{6.3.1}{subsection.6.3.1}}}
\BKM@entry{id=54,dest={73756273656374696F6E2E362E332E32},srcline={582}}{45766F6C7563695C3336336E206465206C6F73204175746F656E636F64657273}
\citation{GAN}
\citation{autoencoders2017}
\citation{autoencoders2017}
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces Esquema de un Autoencoder básico. Imagen extraída de \cite  {autoencoders2017}.}}{71}{figure.6.9}\protected@file@percent }
\@writefile{brf}{\backcite{autoencoders2017}{{71}{6.9}{figure.6.9}}}
\newlabel{fig:Autoencoder}{{6.9}{71}{Esquema de un Autoencoder básico. Imagen extraída de \cite {autoencoders2017}}{figure.6.9}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Evolución de los Autoencoders}{71}{subsection.6.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2.1}Generative Adversarial Networks (GANs)}{71}{subsubsection.6.3.2.1}\protected@file@percent }
\@writefile{brf}{\backcite{GAN}{{71}{6.3.2.1}{subsubsection.6.3.2.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces Ejemplo de una Generative Network que pretende aprender la distribución de probabilidad de un conjunto de imágenes de perros. Imagen extraída de \cite  {autoencoders2017}.}}{71}{figure.6.10}\protected@file@percent }
\@writefile{brf}{\backcite{autoencoders2017}{{71}{6.10}{figure.6.10}}}
\newlabel{fig:Generative Network}{{6.10}{71}{Ejemplo de una Generative Network que pretende aprender la distribución de probabilidad de un conjunto de imágenes de perros. Imagen extraída de \cite {autoencoders2017}}{figure.6.10}{}}
\citation{autoencoders2017}
\citation{autoencoders2017}
\citation{AAE}
\citation{AAE}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces Resumen del proceso de entrenamiento de una GAN. Imagen extraída de \cite  {autoencoders2017}.}}{72}{figure.6.11}\protected@file@percent }
\@writefile{brf}{\backcite{autoencoders2017}{{72}{6.11}{figure.6.11}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces Ejemplo de la arquitectura de una GAN para generar imágenes de dígitos manuscritos. Imagen extraída de \cite  {AAE}}}{72}{figure.6.12}\protected@file@percent }
\@writefile{brf}{\backcite{AAE}{{72}{6.12}{figure.6.12}}}
\newlabel{fig:GAN}{{6.12}{72}{Ejemplo de la arquitectura de una GAN para generar imágenes de dígitos manuscritos. Imagen extraída de \cite {AAE}}{figure.6.12}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2.2}Variational Autoencoder (VAE)}{72}{subsubsection.6.3.2.2}\protected@file@percent }
\citation{VAE}
\citation{VAE}
\citation{VAE}
\citation{VAE}
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces Diferencia en el tratamiento de los datos por parte del encoder en una VAE y un Autoencoder clásico. Imagen extraída de \cite  {VAE}.}}{73}{figure.6.13}\protected@file@percent }
\@writefile{brf}{\backcite{VAE}{{73}{6.13}{figure.6.13}}}
\newlabel{fig:VAE_1}{{6.13}{73}{Diferencia en el tratamiento de los datos por parte del encoder en una VAE y un Autoencoder clásico. Imagen extraída de \cite {VAE}}{figure.6.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2.3}Adversarial Autoencoder(AAE)}{73}{subsubsection.6.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces Diferencia en la función de pérdida de un Autoencoder clásico (imagen superior) y una VAE (imagen inferior). Destacamos el término KL regularizante que pretende que las distribuciones de los datos sigan una normal estándar. Imagen extraída de \cite  {VAE}.}}{74}{figure.6.14}\protected@file@percent }
\@writefile{brf}{\backcite{VAE}{{74}{6.14}{figure.6.14}}}
\newlabel{fig:VAE_2}{{6.14}{74}{Diferencia en la función de pérdida de un Autoencoder clásico (imagen superior) y una VAE (imagen inferior). Destacamos el término KL regularizante que pretende que las distribuciones de los datos sigan una normal estándar. Imagen extraída de \cite {VAE}}{figure.6.14}{}}
\citation{AAE}
\citation{AAE}
\BKM@entry{id=55,dest={73656374696F6E2E362E34},srcline={674}}{545C333531636E6963617320656D706C6561646173}
\BKM@entry{id=56,dest={73756273656374696F6E2E362E342E31},srcline={677}}{4665772D73686F74204C6561726E696E6720792044617461204175676D656E746174696F6E}
\@writefile{lof}{\contentsline {figure}{\numberline {6.15}{\ignorespaces Esquema de la arquitectura de un AAE. El Encoder sería la red a la que entra la imagen $x$, el vector $z$ sería el vector latente, que sirve de entrada al Discriminador $D_{gauss}$ y finalmente el vector $z$ es la entrada del Decoder que reconstruye la imagen. Imagen extraída de \cite  {AAE}.}}{75}{figure.6.15}\protected@file@percent }
\@writefile{brf}{\backcite{AAE}{{75}{6.15}{figure.6.15}}}
\newlabel{fig:AAE}{{6.15}{75}{Esquema de la arquitectura de un AAE. El Encoder sería la red a la que entra la imagen $x$, el vector $z$ sería el vector latente, que sirve de entrada al Discriminador $D_{gauss}$ y finalmente el vector $z$ es la entrada del Decoder que reconstruye la imagen. Imagen extraída de \cite {AAE}}{figure.6.15}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Técnicas empleadas}{75}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Few-shot Learning y Data Augmentation}{75}{subsection.6.4.1}\protected@file@percent }
\newlabel{sub:data_augmentation}{{6.4.1}{75}{Few-shot Learning y Data Augmentation}{subsection.6.4.1}{}}
\BKM@entry{id=57,dest={636861707465722E37},srcline={2}}{45737461646F2064656C2041727465}
\BKM@entry{id=58,dest={73656374696F6E2E372E31},srcline={6}}{4C6F63616C697A6163695C3336336E206465206C616E646D61726B7320636566616C6F6D5C333531747269636F7320656E20696D5C33343167656E6573}
\BKM@entry{id=59,dest={73756273656374696F6E2E372E312E31},srcline={39}}{45766F6C7563695C3336336E20656E206C61206964656E74696669636163695C3336336E20666F72656E7365206465206C616E646D61726B7320636566616C6F6D5C333531747269636F73}
\citation{asi2014automatic}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Estado del Arte}{77}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Localización de landmarks cefalométricos en imágenes}{77}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Evolución en la identificación forense de landmarks cefalométricos}{77}{subsection.7.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Arriba podemos ver la gráfica de publicaciones por año obtenida con la primera \textit  {keyword} el $26$ de Octubre de $2022$, en total se encontraron $1,251$ artículos. Destaca el notable incremento de papers a partir de 2012, año en que aparece la red AlexNet y comienza a ganar popularidad el Deep Learning en el tratamiento de imágenes. Abajo tenemos la gráfica de publicaciones por año obtenida con la segunda \textit  {keyword} el $26$ de Octubre de $2022$, en total se obtuvieron $13$ artículos. Como vemos, existe una gran diferencia entre ambas a nivel de artículos publicados por año.}}{78}{figure.7.1}\protected@file@percent }
\newlabel{fig:SCOPUS}{{7.1}{78}{Arriba podemos ver la gráfica de publicaciones por año obtenida con la primera \textit {keyword} el $26$ de Octubre de $2022$, en total se encontraron $1,251$ artículos. Destaca el notable incremento de papers a partir de 2012, año en que aparece la red AlexNet y comienza a ganar popularidad el Deep Learning en el tratamiento de imágenes. Abajo tenemos la gráfica de publicaciones por año obtenida con la segunda \textit {keyword} el $26$ de Octubre de $2022$, en total se obtuvieron $13$ artículos. Como vemos, existe una gran diferencia entre ambas a nivel de artículos publicados por año}{figure.7.1}{}}
\citation{galvanek2015automated}
\citation{galvanek2015automated}
\citation{galvanek2015automated}
\@writefile{lot}{\contentsline {table}{\numberline {7.1}{\ignorespaces Taxonomía de los artículos publicados que componen el estado del arte en el campo actualmente. A modo de aclaración, por dataset controlado nos referimos al uso de datasets de imágenes tomadas en entornos controlados.}}{79}{table.7.1}\protected@file@percent }
\newlabel{table:taxonomy}{{7.1}{79}{Taxonomía de los artículos publicados que componen el estado del arte en el campo actualmente. A modo de aclaración, por dataset controlado nos referimos al uso de datasets de imágenes tomadas en entornos controlados}{table.7.1}{}}
\@writefile{brf}{\backcite{asi2014automatic}{{79}{7.1.1}{section*.10}}}
\@writefile{brf}{\backcite{galvanek2015automated}{{79}{7.1.1}{section*.11}}}
\citation{porto2019automatic}
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Cara alineada con el plano horizontal de Frankfort. Imagen extraida de \url  {https://www.slideshare.net/NiharikaSupriya/cephalometrics-landmarkslines-and-planes-93890774 }}}{80}{figure.7.2}\protected@file@percent }
\newlabel{fig:Frankfort}{{7.2}{80}{Cara alineada con el plano horizontal de Frankfort. Imagen extraida de \url {https://www.slideshare.net/NiharikaSupriya/cephalometrics-landmarkslines-and-planes-93890774 }}{figure.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Comparativa entre los landmarks marcados por el algoritmo desarrollado en el artículo (izquierda) y los marcados por un experto (derecha). Imagen extraida de \cite  {galvanek2015automated}.}}{80}{figure.7.3}\protected@file@percent }
\@writefile{brf}{\backcite{galvanek2015automated}{{80}{7.3}{figure.7.3}}}
\newlabel{fig:landmarks_comparativa}{{7.3}{80}{Comparativa entre los landmarks marcados por el algoritmo desarrollado en el artículo (izquierda) y los marcados por un experto (derecha). Imagen extraida de \cite {galvanek2015automated}}{figure.7.3}{}}
\citation{ImprovedfasterRCNN}
\@writefile{brf}{\backcite{porto2019automatic}{{81}{7.1.1}{section*.12}}}
\@writefile{brf}{\backcite{ImprovedfasterRCNN}{{81}{7.1.1}{section*.13}}}
\BKM@entry{id=60,dest={636861707465722E38},srcline={1}}{496D706C656D656E746163695C3336336E}
\BKM@entry{id=61,dest={73656374696F6E2E382E31},srcline={3}}{446973655C3336316F2064656C20536F6677617265}
\citation{browatzki20203fabrec}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Implementación}{83}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Diseño del Sofware}{83}{section.8.1}\protected@file@percent }
\@writefile{brf}{\backcite{browatzki20203fabrec}{{83}{8.1}{figure.8.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Diagrama de paquetes del proyecto generado por \textit  {pyreverse}, herramienta incluida en el paquete Pylint}}{84}{figure.8.1}\protected@file@percent }
\newlabel{fig:Diagrama_paquetes}{{8.1}{84}{Diagrama de paquetes del proyecto generado por \textit {pyreverse}, herramienta incluida en el paquete Pylint}{figure.8.1}{}}
\BKM@entry{id=62,dest={73656374696F6E2E382E32},srcline={88}}{456E746F726E6F20646520656A65637563695C3336336E}
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Diagrama de clases con las principales clases del proyecto.}}{85}{figure.8.2}\protected@file@percent }
\newlabel{fig:Diagrama_clases}{{8.2}{85}{Diagrama de clases con las principales clases del proyecto}{figure.8.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Entorno de ejecución}{85}{section.8.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{\ignorespaces Argumentos con los que se ha experimentado en la ejecución del fichero train-aae-landmarks.py}}{86}{table.8.1}\protected@file@percent }
\newlabel{table:Params}{{8.1}{86}{Argumentos con los que se ha experimentado en la ejecución del fichero train-aae-landmarks.py}{table.8.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {8.3}{\ignorespaces Diagrama de secuencia del software empleado.}}{86}{figure.8.3}\protected@file@percent }
\newlabel{fig:Diagrama_secuencia}{{8.3}{86}{Diagrama de secuencia del software empleado}{figure.8.3}{}}
\BKM@entry{id=63,dest={636861707465722E39},srcline={1}}{536F6C7563695C3336336E2070726F7075657374612079206578706572696D656E746F73207265616C697A61646F73}
\citation{300W}
\citation{300W}
\citation{300W}
\citation{AFLW}
\citation{AFLW}
\citation{AFLW}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Solución propuesta y experimentos realizados}{89}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{brf}{\backcite{300W}{{89}{9}{chapter.9}}}
\@writefile{brf}{\backcite{AFLW}{{89}{9}{figure.9.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces Conjunto de landmarks anotados sobre un modelo $3$D que emplea el dataset AFLW. Imagen extraida de \cite  {AFLW}.}}{89}{figure.9.2}\protected@file@percent }
\@writefile{brf}{\backcite{AFLW}{{89}{9.2}{figure.9.2}}}
\newlabel{fig:AFLW}{{9.2}{89}{Conjunto de landmarks anotados sobre un modelo $3$D que emplea el dataset AFLW. Imagen extraida de \cite {AFLW}}{figure.9.2}{}}
\BKM@entry{id=64,dest={73656374696F6E2E392E31},srcline={29}}{4672616D65776F726B20656D706C6561646F3A2033466162526563}
\citation{browatzki20203fabrec}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Conjunto de landmarks anotados en el dataset 300W, en la imagen \textit  {a} contando el contorno del rostro son un total de 68 landmarks, en la imagen \textit  {b} son 51 en total. Imagen extraida de \cite  {300W}.}}{90}{figure.9.1}\protected@file@percent }
\@writefile{brf}{\backcite{300W}{{90}{9.1}{figure.9.1}}}
\newlabel{fig:300W}{{9.1}{90}{Conjunto de landmarks anotados en el dataset 300W, en la imagen \textit {a} contando el contorno del rostro son un total de 68 landmarks, en la imagen \textit {b} son 51 en total. Imagen extraida de \cite {300W}}{figure.9.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Framework empleado: 3FabRec}{90}{section.9.1}\protected@file@percent }
\@writefile{brf}{\backcite{browatzki20203fabrec}{{90}{9.1}{section.9.1}}}
\citation{browatzki20203fabrec}
\citation{browatzki20203fabrec}
\BKM@entry{id=65,dest={73756273656374696F6E2E392E312E31},srcline={49}}{41727175697465637475726120416476657273617269616C204175746F656E636F646572}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces Imagen resumen del framework 3FabRec. En ella podemos ver la estructura del \textit  {Adversarial Autoencoder}, dividido en un Encoder (región bajo la \textit  {E}) y un Generator (región bajo la \textit  {G}). En rojo podemos ver las ITLs que se intercalan entre cada capa del Generador y dan como resultado un conjunto de mapas de calor. Imagen extraída de \cite  {browatzki20203fabrec}.}}{91}{figure.9.3}\protected@file@percent }
\@writefile{brf}{\backcite{browatzki20203fabrec}{{91}{9.3}{figure.9.3}}}
\newlabel{fig:3FabRec Resumen}{{9.3}{91}{Imagen resumen del framework 3FabRec. En ella podemos ver la estructura del \textit {Adversarial Autoencoder}, dividido en un Encoder (región bajo la \textit {E}) y un Generator (región bajo la \textit {G}). En rojo podemos ver las ITLs que se intercalan entre cada capa del Generador y dan como resultado un conjunto de mapas de calor. Imagen extraída de \cite {browatzki20203fabrec}}{figure.9.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.1}Arquitectura Adversarial Autoencoder}{91}{subsection.9.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.1.1}Interleaved Transfer Layer (ITL)}{92}{subsubsection.9.1.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.4}{\ignorespaces Bloques básicos que utilza la red ResNet-$18$ en sus capas. Se trata de una sucesión clásica de Convolución 3x3 + Batch Normalization + ReLU que se repite dos veces. En el primer caso los filtros de convolución no reducen las dimensiones del tensor añadiendo un padding de 1. En el segundo caso se reduce la dimensión del tensor a la mitad tras la primera convolución y se manteiene la dimensionalidad en la segunda. En el primer caso, la suma residual puede realizarse con el tensor x sin problema, en el segundo caso el tensor debe reducirse para que casen las dimensiones.}}{92}{figure.9.4}\protected@file@percent }
\newlabel{fig:bloque_encoder}{{9.4}{92}{Bloques básicos que utilza la red ResNet-$18$ en sus capas. Se trata de una sucesión clásica de Convolución 3x3 + Batch Normalization + ReLU que se repite dos veces. En el primer caso los filtros de convolución no reducen las dimensiones del tensor añadiendo un padding de 1. En el segundo caso se reduce la dimensión del tensor a la mitad tras la primera convolución y se manteiene la dimensionalidad en la segunda. En el primer caso, la suma residual puede realizarse con el tensor x sin problema, en el segundo caso el tensor debe reducirse para que casen las dimensiones}{figure.9.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.5}{\ignorespaces Ejemplo de paso de una imagen a través del Encoder. Cabe destacar que a partir de la Layer 1, todos los bloques tienen downsample.}}{93}{figure.9.5}\protected@file@percent }
\newlabel{fig:Paso_encoder}{{9.5}{93}{Ejemplo de paso de una imagen a través del Encoder. Cabe destacar que a partir de la Layer 1, todos los bloques tienen downsample}{figure.9.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.6}{\ignorespaces En primer lugar se aplica una convolución transpuesta que duplica las dimensiones del tensor de entrada y tras esto se sigue la misma estructura que en el bloque básico de la ResNet-$18$, la segunda convolución $3\times 3$ mantiene las dimensiones. Como consecuencia, para sumar el tensor de entrada con la salida del bloque se aumentan las dimensiones de este.}}{94}{figure.9.6}\protected@file@percent }
\newlabel{fig:Bloque_Decoder}{{9.6}{94}{En primer lugar se aplica una convolución transpuesta que duplica las dimensiones del tensor de entrada y tras esto se sigue la misma estructura que en el bloque básico de la ResNet-$18$, la segunda convolución $3\times 3$ mantiene las dimensiones. Como consecuencia, para sumar el tensor de entrada con la salida del bloque se aumentan las dimensiones de este}{figure.9.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.7}{\ignorespaces Ejemplo del paso de un vector de $99$ dimensiones por el generador hasta reconstruirse la imagen de dimensiones $256 \times 256 \times 3$. La parte correspondiente al aprendizaje supervisado es la de los cuadrados azules, los cuadrados rojos corresponden a las \textit  {ITLS} de la parte supervisada que se intercalan entre cada dos capas y dan como resultado los mapas de calor de los landmarks predichos.}}{94}{figure.9.7}\protected@file@percent }
\newlabel{fig:Paso_Generator}{{9.7}{94}{Ejemplo del paso de un vector de $99$ dimensiones por el generador hasta reconstruirse la imagen de dimensiones $256 \times 256 \times 3$. La parte correspondiente al aprendizaje supervisado es la de los cuadrados azules, los cuadrados rojos corresponden a las \textit {ITLS} de la parte supervisada que se intercalan entre cada dos capas y dan como resultado los mapas de calor de los landmarks predichos}{figure.9.7}{}}
\BKM@entry{id=66,dest={73756273656374696F6E2E392E312E32},srcline={107}}{46756E63695C3336336E20646520705C3335317264696461}
\@writefile{lof}{\contentsline {figure}{\numberline {9.8}{\ignorespaces En la imagen superior vemos el discriminante que se emplea para los vectores producidos por el Encoder y en la imagen inferior vemos el discriminante que se emplea para las imágenes generadas por el Generador. En ambos casos se da como salida un valor entre $0$ y $1$ que hace referencia a la probabilidad de pertenecer a la distribución deseada en el primer caso o a seguir la distribución de los píxeles de las imágenes en el segundo caso.}}{95}{figure.9.8}\protected@file@percent }
\newlabel{fig:DGaussian}{{9.8}{95}{En la imagen superior vemos el discriminante que se emplea para los vectores producidos por el Encoder y en la imagen inferior vemos el discriminante que se emplea para las imágenes generadas por el Generador. En ambos casos se da como salida un valor entre $0$ y $1$ que hace referencia a la probabilidad de pertenecer a la distribución deseada en el primer caso o a seguir la distribución de los píxeles de las imágenes en el segundo caso}{figure.9.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.2}Función de pérdida}{95}{subsection.9.1.2}\protected@file@percent }
\newlabel{eq::L2}{{9.1.2}{96}{Función de pérdida}{subsection.9.1.2}{}}
\BKM@entry{id=67,dest={73756273656374696F6E2E392E312E33},srcline={188}}{50726F6365736F20646520656E7472656E616D69656E746F206465206C6120726564}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.2.1}Modificación de la función de pérdida}{97}{subsubsection.9.1.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.3}Proceso de entrenamiento de la red}{97}{subsection.9.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.3.1}Entrenamiento no-supervisado}{97}{subsubsection.9.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.3.2}Entrenamiento supervisado}{97}{subsubsection.9.1.3.2}\protected@file@percent }
\BKM@entry{id=68,dest={73756273656374696F6E2E392E312E34},srcline={212}}{4261736573206465206461746F732075736164617320706F7220656C206672616D65776F726B}
\BKM@entry{id=69,dest={73656374696F6E2E392E32},srcline={235}}{4D5C333531747269636173}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.4}Bases de datos usadas por el framework}{98}{subsection.9.1.4}\protected@file@percent }
\BKM@entry{id=70,dest={73756273656374696F6E2E392E322E31},srcline={239}}{4D5C3335317472696361732075736164617320656E20656C20656E7472656E616D69656E746F}
\BKM@entry{id=71,dest={73756273656374696F6E2E392E322E32},srcline={255}}{4D5C33353174726963617320656D706C656164617320656E2076616C69646163695C3336336E20792074657374696E67}
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Métricas}{99}{section.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Métricas usadas en el entrenamiento}{99}{subsection.9.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.1.1}MSE}{99}{subsubsection.9.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Métricas empleadas en validación y testing}{99}{subsection.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2.1}Error de reconstrucción}{99}{subsubsection.9.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2.2}Normalized Mean Error}{99}{subsubsection.9.2.2.2}\protected@file@percent }
\citation{wang2004image}
\BKM@entry{id=72,dest={73656374696F6E2E392E33},srcline={327}}{50726570726F636573616D69656E746F206465206C6F73206461746F73}
\BKM@entry{id=73,dest={73756273656374696F6E2E392E332E31},srcline={329}}{4964656E74696669636163695C3336336E20646520636172617320656E206C617320696D5C33343167656E6573}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2.3}SSIM}{100}{subsubsection.9.2.2.3}\protected@file@percent }
\@writefile{brf}{\backcite{wang2004image}{{100}{9.2.2.3}{subsubsection.9.2.2.3}}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Preprocesamiento de los datos}{101}{section.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.1}Identificación de caras en las imágenes}{101}{subsection.9.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.9}{\ignorespaces Imágenes de ejemplo del dataset con los \textit  {bounding boxes} marcados por \textit  {Facenet}. Como podemos observar, aunque son correctos, los \textit  {bounding boxes} marcados recortan excesivamente los límites del rostro, pudiendo incluso eliminar partes en las que hay landmarks marcados. Las imágenes han sido generadas con \textit  {matplotlib}.}}{102}{figure.9.9}\protected@file@percent }
\newlabel{fig:Ejemplo_bb}{{9.9}{102}{Imágenes de ejemplo del dataset con los \textit {bounding boxes} marcados por \textit {Facenet}. Como podemos observar, aunque son correctos, los \textit {bounding boxes} marcados recortan excesivamente los límites del rostro, pudiendo incluso eliminar partes en las que hay landmarks marcados. Las imágenes han sido generadas con \textit {matplotlib}}{figure.9.9}{}}
\BKM@entry{id=74,dest={73756273656374696F6E2E392E332E32},srcline={377}}{4372656163695C3336336E2064656C206669636865726F20616E6E6F746174696F6E7320656E20656C2064617461736574}
\BKM@entry{id=75,dest={73756273656374696F6E2E392E332E33},srcline={389}}{5265616A75737465206465206C6F7320626F756E64696E6720626F786573}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.2}Creación del fichero annotations en el dataset}{103}{subsection.9.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.3}Reajuste de los bounding boxes}{103}{subsection.9.3.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.10}{\ignorespaces Proceso seguido para la transformación.}}{104}{figure.9.10}\protected@file@percent }
\newlabel{fig:Transformacion_BB}{{9.10}{104}{Proceso seguido para la transformación}{figure.9.10}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.11}{\ignorespaces Recorte de las caras tras el reajuste del \textit  {bounding box}.}}{104}{figure.9.11}\protected@file@percent }
\newlabel{fig:Reajuste_bb}{{9.11}{104}{Recorte de las caras tras el reajuste del \textit {bounding box}}{figure.9.11}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.12}{\ignorespaces Error estructural y de reconstrucción de las imágenes con el bounding box reajustado. El error de reconstrucción se encuentra en la esquina inferior izquierda, y el estructural encima del anterior. Como podemos observar, en todos los casos son muy elevados y la imagen reconstruida apenas guarda relación con la original.}}{105}{figure.9.12}\protected@file@percent }
\newlabel{fig:bb_custom}{{9.12}{105}{Error estructural y de reconstrucción de las imágenes con el bounding box reajustado. El error de reconstrucción se encuentra en la esquina inferior izquierda, y el estructural encima del anterior. Como podemos observar, en todos los casos son muy elevados y la imagen reconstruida apenas guarda relación con la original}{figure.9.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.13}{\ignorespaces Error estructural y de reconstrucción de las imágenes con el reajuste del bounding box de 3FabRec. Como podemos ver, sigue habiendo grandes errores de reconstrucción y estructurales, pero se consigue un mejor resultado de la estructura facial. No obstante, el vertex no se aprecia correctamente en las imágenes.}}{105}{figure.9.13}\protected@file@percent }
\newlabel{fig:bb_3fabrec}{{9.13}{105}{Error estructural y de reconstrucción de las imágenes con el reajuste del bounding box de 3FabRec. Como podemos ver, sigue habiendo grandes errores de reconstrucción y estructurales, pero se consigue un mejor resultado de la estructura facial. No obstante, el vertex no se aprecia correctamente en las imágenes}{figure.9.13}{}}
\BKM@entry{id=76,dest={73756273656374696F6E2E392E332E34},srcline={454}}{53657061726163695C3336336E20656E20636F6E6A756E746F7320646520656E7472656E616D69656E746F20792076616C69646163695C3336336E}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.4}Separación en conjuntos de entrenamiento y validación}{106}{subsection.9.3.4}\protected@file@percent }
\BKM@entry{id=77,dest={73656374696F6E2E392E34},srcline={474}}{4578706572696D656E746163695C3336336E}
\BKM@entry{id=78,dest={73756273656374696F6E2E392E342E31},srcline={475}}{4869705C333633746573697320696E696369616C6573}
\citation{browatzki20203fabrec}
\BKM@entry{id=79,dest={73756273656374696F6E2E392E342E32},srcline={482}}{4D6F64656C6F2042617365}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Experimentación}{107}{section.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.1}Hipótesis iniciales}{107}{subsection.9.4.1}\protected@file@percent }
\@writefile{brf}{\backcite{browatzki20203fabrec}{{107}{9.4.1}{subsection.9.4.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.2}Modelo Base}{107}{subsection.9.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.1}{\ignorespaces Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo base.}}{108}{table.9.1}\protected@file@percent }
\newlabel{table:ModelBase_images_results}{{9.1}{108}{Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo base}{table.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.14}{\ignorespaces Diagramas de cajas de los resultados de NME y error de validación en el conjunto de las imágenes de entrenamiento en el Modelo Base. Se han omitido los valores atípicos para una correcta visualización.}}{109}{figure.9.14}\protected@file@percent }
\newlabel{fig:boxplot_ModeloBase_NME}{{9.14}{109}{Diagramas de cajas de los resultados de NME y error de validación en el conjunto de las imágenes de entrenamiento en el Modelo Base. Se han omitido los valores atípicos para una correcta visualización}{figure.9.14}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9.2}{\ignorespaces Media del error NME obtenido por landmark entre todas las particiones de cross-validation. Marcamos en amarillo el vertex pues no está correctamente marcado en todas las imágenes.}}{110}{table.9.2}\protected@file@percent }
\newlabel{table:ModelBase_landmarkresume}{{9.2}{110}{Media del error NME obtenido por landmark entre todas las particiones de cross-validation. Marcamos en amarillo el vertex pues no está correctamente marcado en todas las imágenes}{table.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.15}{\ignorespaces Curvas de aprendizaje en cada partición del modelo base.}}{110}{figure.9.15}\protected@file@percent }
\newlabel{fig:Curvas_modelbase}{{9.15}{110}{Curvas de aprendizaje en cada partición del modelo base}{figure.9.15}{}}
\BKM@entry{id=80,dest={73756273656374696F6E2E392E342E33},srcline={597}}{4D6F64656C6F20636F6E207265656E7472656E616D69656E746F2064656C20656E636F646572}
\@writefile{lof}{\contentsline {figure}{\numberline {9.16}{\ignorespaces Imágenes pertenecientes a distintos conjuntos de validación para el \textbf  {modelo base}. Las imágenes de la fila superior son las imágenes reales, y las de la fila inferior las reconstruidas por la red. Podemos apreciar en verde los landmarks reales y en azul los predichos. El valor que aparece en la esquina inferior derecha es el NME global de la imagen (la media de los NMEs de cada landmark) y en la esquina inferior izquierda aparece el error de reconstrucción y encima el SSIM.}}{111}{figure.9.16}\protected@file@percent }
\newlabel{fig:Ejemplo_ModelBase}{{9.16}{111}{Imágenes pertenecientes a distintos conjuntos de validación para el \textbf {modelo base}. Las imágenes de la fila superior son las imágenes reales, y las de la fila inferior las reconstruidas por la red. Podemos apreciar en verde los landmarks reales y en azul los predichos. El valor que aparece en la esquina inferior derecha es el NME global de la imagen (la media de los NMEs de cada landmark) y en la esquina inferior izquierda aparece el error de reconstrucción y encima el SSIM}{figure.9.16}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.3}Modelo con reentrenamiento del encoder}{112}{subsection.9.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.3}{\ignorespaces Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo de ajuste fino del encoder.}}{112}{table.9.3}\protected@file@percent }
\newlabel{table:ModelEncoder_images_results}{{9.3}{112}{Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo de ajuste fino del encoder}{table.9.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.17}{\ignorespaces Diagramas de cajas de los resultados de NME y error de validación en el conjunto de las imágenes de entrenamiento del modelo de ajuste fino del encoder. Se han omitido los Outliers para una correcta visualización.}}{113}{figure.9.17}\protected@file@percent }
\newlabel{fig:boxplot_ModeloEncoder_NME}{{9.17}{113}{Diagramas de cajas de los resultados de NME y error de validación en el conjunto de las imágenes de entrenamiento del modelo de ajuste fino del encoder. Se han omitido los Outliers para una correcta visualización}{figure.9.17}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9.4}{\ignorespaces Tabla comparativa entre los dos modelos explorados por ahora. Medimos el NME medio a nivel de landmark. En verde se resalta el mejor valor de marcado para cada landmark.}}{114}{table.9.4}\protected@file@percent }
\newlabel{table:Encode_landmarkresume}{{9.4}{114}{Tabla comparativa entre los dos modelos explorados por ahora. Medimos el NME medio a nivel de landmark. En verde se resalta el mejor valor de marcado para cada landmark}{table.9.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.18}{\ignorespaces Curvas de aprendizaje en cada partición del modelo de finetuning del encoder.}}{114}{figure.9.18}\protected@file@percent }
\newlabel{fig:curvas_encoder}{{9.18}{114}{Curvas de aprendizaje en cada partición del modelo de finetuning del encoder}{figure.9.18}{}}
\BKM@entry{id=81,dest={73756273656374696F6E2E392E342E34},srcline={706}}{4D6F64656C6F20636F6E207265656E7472656E616D69656E746F2064656C206465636F646572}
\@writefile{lof}{\contentsline {figure}{\numberline {9.19}{\ignorespaces Imágenes pertenecientes a distintos conjuntos de validación para el \textbf  {modelo de ajuste fino del encoder}.}}{115}{figure.9.19}\protected@file@percent }
\newlabel{fig:Ejemplo_encoder}{{9.19}{115}{Imágenes pertenecientes a distintos conjuntos de validación para el \textbf {modelo de ajuste fino del encoder}}{figure.9.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.4}Modelo con reentrenamiento del decoder}{115}{subsection.9.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.5}{\ignorespaces Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo de ajuste fino del decoder.}}{116}{table.9.5}\protected@file@percent }
\newlabel{table:ModelDecoder_images_results}{{9.5}{116}{Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo de ajuste fino del decoder}{table.9.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.20}{\ignorespaces Diagramas de cajas de los resultados de NME y error de validación en el conjunto de las imágenes de entrenamiento del modelo de ajuste fino del decoder. Se han omitido los Outliers para una correcta visualización.}}{116}{figure.9.20}\protected@file@percent }
\newlabel{fig:boxplot_ModeloDecoder_NME}{{9.20}{116}{Diagramas de cajas de los resultados de NME y error de validación en el conjunto de las imágenes de entrenamiento del modelo de ajuste fino del decoder. Se han omitido los Outliers para una correcta visualización}{figure.9.20}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9.6}{\ignorespaces Tabla comparativa entre los tres modelos probados. En este caso no se aprecia ninguna mejora considerable con respecto a las introducidas por el modelo de ajuste fino del encoder.}}{117}{table.9.6}\protected@file@percent }
\newlabel{table:Decoder_landmarksresume}{{9.6}{117}{Tabla comparativa entre los tres modelos probados. En este caso no se aprecia ninguna mejora considerable con respecto a las introducidas por el modelo de ajuste fino del encoder}{table.9.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.21}{\ignorespaces Curvas de aprendizaje en cada partición del modelo de finetuning del encoder.}}{117}{figure.9.21}\protected@file@percent }
\newlabel{fig:curvas_decoder}{{9.21}{117}{Curvas de aprendizaje en cada partición del modelo de finetuning del encoder}{figure.9.21}{}}
\BKM@entry{id=82,dest={73756273656374696F6E2E392E342E35},srcline={801}}{4D6F64656C6F20636F6E2044617461204175676D656E746174696F6E}
\@writefile{lof}{\contentsline {figure}{\numberline {9.22}{\ignorespaces Imágenes pertenecientes a distintos conjuntos de validación para el \textbf  {modelo de ajuste fino del decoder}.}}{118}{figure.9.22}\protected@file@percent }
\newlabel{fig:Ejemplo_decoder}{{9.22}{118}{Imágenes pertenecientes a distintos conjuntos de validación para el \textbf {modelo de ajuste fino del decoder}}{figure.9.22}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.5}Modelo con Data Augmentation}{118}{subsection.9.4.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.7}{\ignorespaces Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo de data augmentation.}}{119}{table.9.7}\protected@file@percent }
\newlabel{table:ModelDaug_images_results}{{9.7}{119}{Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo de data augmentation}{table.9.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.23}{\ignorespaces Diagramas de cajas de los resultados de NME y error de validación en el conjunto de las imágenes de entrenamiento del modelo de data augmentation. Se han omitido los Outliers para una correcta visualización.}}{119}{figure.9.23}\protected@file@percent }
\newlabel{fig:boxplot_ModeloDaug_NME}{{9.23}{119}{Diagramas de cajas de los resultados de NME y error de validación en el conjunto de las imágenes de entrenamiento del modelo de data augmentation. Se han omitido los Outliers para una correcta visualización}{figure.9.23}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9.8}{\ignorespaces Tabla comparativa entre todos los modelos probados.}}{120}{table.9.8}\protected@file@percent }
\newlabel{table:Daugmentation_landmarksresume}{{9.8}{120}{Tabla comparativa entre todos los modelos probados}{table.9.8}{}}
\BKM@entry{id=83,dest={73756273656374696F6E2E392E342E36},srcline={899}}{456C656363695C3336336E206465206D6F64656C6F2079206F6274656E63695C3336336E20646520726573756C7461646F73}
\@writefile{lof}{\contentsline {figure}{\numberline {9.24}{\ignorespaces Curvas de aprendizaje en cada partición del modelo de data augmentation.}}{121}{figure.9.24}\protected@file@percent }
\newlabel{fig:curvas_daugmentation}{{9.24}{121}{Curvas de aprendizaje en cada partición del modelo de data augmentation}{figure.9.24}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.25}{\ignorespaces Imágenes pertenecientes a distintos conjuntos de validación para el \textbf  {modelo data augmentation}.}}{121}{figure.9.25}\protected@file@percent }
\newlabel{fig:Ejemplo_daug}{{9.25}{121}{Imágenes pertenecientes a distintos conjuntos de validación para el \textbf {modelo data augmentation}}{figure.9.25}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.6}Elección de modelo y obtención de resultados}{121}{subsection.9.4.6}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.26}{\ignorespaces Diagramas de cajas de todos los modelos probados concatenados. Para una correcta visualización se eliminan los outliers del gráfico.}}{122}{figure.9.26}\protected@file@percent }
\newlabel{fig:boxplot_summary}{{9.26}{122}{Diagramas de cajas de todos los modelos probados concatenados. Para una correcta visualización se eliminan los outliers del gráfico}{figure.9.26}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9.9}{\ignorespaces Tabla comparativa entre los resultados del modelo de data augmentation en el conjunto de validación y test.}}{123}{table.9.9}\protected@file@percent }
\newlabel{table:FinalModel_landmarks}{{9.9}{123}{Tabla comparativa entre los resultados del modelo de data augmentation en el conjunto de validación y test}{table.9.9}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.27}{\ignorespaces Curvas de aprendizaje durante el entrenamiento del modelo de data augmentation validado en el conjunto de test.}}{124}{figure.9.27}\protected@file@percent }
\newlabel{fig:curvas_FinalModel}{{9.27}{124}{Curvas de aprendizaje durante el entrenamiento del modelo de data augmentation validado en el conjunto de test}{figure.9.27}{}}
\BKM@entry{id=84,dest={73656374696F6E2E392E35},srcline={1007}}{436F6D706172617469766120656E74726520334661625265632079204879706572466163652D5265734E6574313031}
\@writefile{lof}{\contentsline {figure}{\numberline {9.28}{\ignorespaces Rendimiento del modelo final elegido con data augmentation en imágenes del conjunto de test.}}{125}{figure.9.28}\protected@file@percent }
\newlabel{fig:Ejemplo_finalmodel}{{9.28}{125}{Rendimiento del modelo final elegido con data augmentation en imágenes del conjunto de test}{figure.9.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Comparativa entre 3FabRec y HyperFace-ResNet101}{125}{section.9.5}\protected@file@percent }
\BKM@entry{id=85,dest={73756273656374696F6E2E392E352E31},srcline={1010}}{50726570726F636573616D69656E746F20792062617365206465206461746F7320656D706C65616461}
\BKM@entry{id=86,dest={73756273656374696F6E2E392E352E32},srcline={1017}}{4D5C33353174726963617320656D706C6561646173}
\BKM@entry{id=87,dest={73756273656374696F6E2E392E352E33},srcline={1030}}{436F6D7061726163695C3336336E20646520726573756C7461646F73}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.1}Preprocesamiento y base de datos empleada}{126}{subsection.9.5.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.2}Métricas empleadas}{126}{subsection.9.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.3}Comparación de resultados}{126}{subsection.9.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.10}{\ignorespaces Tabla comparativa a nivel global entre los dos modelos. Como podemos observar, el modelo basado en \textbf  {HyperFace-Resnet101} obtiene mejores resultados en global en todos los campos.}}{126}{table.9.10}\protected@file@percent }
\newlabel{table:comparativa-global}{{9.10}{126}{Tabla comparativa a nivel global entre los dos modelos. Como podemos observar, el modelo basado en \textbf {HyperFace-Resnet101} obtiene mejores resultados en global en todos los campos}{table.9.10}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9.11}{\ignorespaces Tabla comparativa a nivel de landmarks entre el modelo final basado en 3FabRec y el de HyperFace-REsNet101.}}{127}{table.9.11}\protected@file@percent }
\newlabel{table:comparativa-Landmarks}{{9.11}{127}{Tabla comparativa a nivel de landmarks entre el modelo final basado en 3FabRec y el de HyperFace-REsNet101}{table.9.11}{}}
\BKM@entry{id=88,dest={73756273656374696F6E2E392E352E34},srcline={1115}}{436F6E636C7573696F6E65732065787472615C333535646173}
\@writefile{lof}{\contentsline {figure}{\numberline {9.29}{\ignorespaces A la izquierda podemos ver las imágenes obtenidas con el modelo basado en \textit  {3FabRec}, a la derecha las extraidas del TFG de Guillermo Gómez utilizando \textit  {HF-ResNet}.}}{129}{figure.9.29}\protected@file@percent }
\newlabel{fig:comparativa_estado_arte}{{9.29}{129}{A la izquierda podemos ver las imágenes obtenidas con el modelo basado en \textit {3FabRec}, a la derecha las extraidas del TFG de Guillermo Gómez utilizando \textit {HF-ResNet}}{figure.9.29}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.4}Conclusiones extraídas}{129}{subsection.9.5.4}\protected@file@percent }
\BKM@entry{id=89,dest={636861707465722E3130},srcline={1}}{436F6E636C7573696F6E657320792054726162616A6F732046757475726F73}
\BKM@entry{id=90,dest={73656374696F6E2E31302E31},srcline={17}}{4F626A657469766F73205361746973666563686F73}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Conclusiones y Trabajos Futuros}{131}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\BKM@entry{id=91,dest={73656374696F6E2E31302E32},srcline={29}}{54726162616A6F732046757475726F73207920636F6D656E746172696F73}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Objetivos Satisfechos}{132}{section.10.1}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Trabajos Futuros y comentarios}{132}{section.10.2}\protected@file@percent }
\BKM@entry{id=92,dest={424D2D5265666572656E636961732E2D31},srcline={267}}{5265666572656E636961732065205C3335356E6469636573}
\bibstyle{alpha}
\bibdata{library.bib}
\BKM@entry{id=93,dest={636861707465722A2E3236},srcline={2}}{4269626C696F677261665C33353561}
\bibcite{asi2014automatic}{AIA{$^{+}$}14}
\bibcite{bruna2013invariant}{BM13}
\bibcite{browatzki20203fabrec}{BW20}
\bibcite{damas2020handbook}{DCI20}
\bibcite{autoencoders2017}{Der17}
\bibcite{StanfordCourse}{{Fei}17}
\bibcite{Goodfellow-et-al-2016}{GBC16}
\bibcite{galvanek2015automated}{GFCS15}
\bibcite{DigitalImageProcessing}{Gon17}
\bibcite{Huete2015PastPA}{HIWK15}
\bibcite{ImprovedfasterRCNN}{HNATT22}
\bibcite{JBrunaOperatorsCommutingDiff}{J.B12}
\bibcite{AFLW}{KWRB11}
\bibcite{lecun2015deep}{LBH15}
\bibcite{DistinctiveImageFeatures}{Low04}
\bibcite{MallatWavelets}{Mal00}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Bibliograf\'{\i }a}{135}{chapter*.26}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{GroupInvariantScattering}{Mal12}
\bibcite{article}{MMi{$^{+}$}20}
\bibcite{norvig2002modern}{NI02}
\bibcite{HaarBasis}{PJDoM06}
\bibcite{porto2019automatic}{PLF{$^{+}$}19}
\bibcite{AAE}{Ras20}
\bibcite{GAN}{Roc19a}
\bibcite{VAE}{Roc19b}
\bibcite{rosenfeld1988computer}{Ros88}
\bibcite{savvides2004eigenphases}{SKK04}
\bibcite{sharma2017activation}{SSA17}
\bibcite{300W}{STZP13}
\bibcite{Daisy}{TLF10}
\bibcite{wang2004image}{WBSS04}
\bibcite{WAVELETS}{Wor}
\BKM@entry{id=94,dest={617070656E6469782E2D31},srcline={284}}{41705C3335316E6469636573}
\BKM@entry{id=95,dest={636861707465722A2E3237},srcline={4}}{41705C3335316E646963652041}
\BKM@entry{id=96,dest={73656374696F6E2E416C7068302E31},srcline={6}}{526573756C7461646F7320706F7220696D6167656E20647572616E746520656C20656E7472656E616D69656E746F2064656C206D6F64656C6F2062617365}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Apéndice A}{137}{chapter*.27}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ap:apendiceA}{{10.2}{137}{Apéndice A}{chapter*.27}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Resultados por imagen durante el entrenamiento del modelo base}{137}{section.Alph0.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Predicciones cross-validation modelo base. Primera partición.}}{137}{table.Alph0.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Predicciones cross-validation modelo base. Segunda partición.}}{138}{table.Alph0.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Predicciones cross-validation modelo base. Tercera partición.}}{139}{table.Alph0.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Predicciones cross-validation modelo base. Cuarta partición.}}{140}{table.Alph0.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Predicciones cross-validation modelo base. Cuarta partición.}}{141}{table.Alph0.5}\protected@file@percent }
\BKM@entry{id=97,dest={636861707465722A2E3238},srcline={4}}{41705C3335316E646963652042}
\BKM@entry{id=98,dest={73656374696F6E2E416C7068302E31},srcline={6}}{526573756C7461646F7320706F7220696D6167656E20647572616E746520656C20656E7472656E616D69656E746F2064656C206D6F64656C6F20646520656E7472656E616D69656E746F2064656C20656E636F646572}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Apéndice B}{143}{chapter*.28}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ap:apendiceB}{{1}{143}{Apéndice B}{chapter*.28}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Resultados por imagen durante el entrenamiento del modelo de entrenamiento del encoder}{143}{section.Alph0.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Primera partición.}}{143}{table.Alph0.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Segunda partición.}}{144}{table.Alph0.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Tercera partición.}}{145}{table.Alph0.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Cuarta partición.}}{146}{table.Alph0.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Quinta partición.}}{147}{table.Alph0.5}\protected@file@percent }
\BKM@entry{id=99,dest={636861707465722A2E3239},srcline={4}}{41705C3335316E646963652043}
\BKM@entry{id=100,dest={73656374696F6E2E416C7068302E31},srcline={6}}{526573756C7461646F7320706F7220696D6167656E20647572616E746520656C20656E7472656E616D69656E746F2064656C206D6F64656C6F20646520656E7472656E616D69656E746F2064656C206465636F646572}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Apéndice C}{149}{chapter*.29}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ap:apendiceC}{{1}{149}{Apéndice C}{chapter*.29}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Resultados por imagen durante el entrenamiento del modelo de entrenamiento del decoder}{149}{section.Alph0.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Primera partición.}}{149}{table.Alph0.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Segunda partición.}}{150}{table.Alph0.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Tercera partición.}}{151}{table.Alph0.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Cuarta partición.}}{152}{table.Alph0.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Quinta partición.}}{153}{table.Alph0.5}\protected@file@percent }
\BKM@entry{id=101,dest={636861707465722A2E3330},srcline={4}}{41705C3335316E646963652044}
\BKM@entry{id=102,dest={73656374696F6E2E416C7068302E31},srcline={6}}{526573756C7461646F7320706F7220696D6167656E20647572616E746520656C20656E7472656E616D69656E746F2064656C206D6F64656C6F20636F6E2064617461206175676D656E746174696F6E}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Apéndice D}{155}{chapter*.30}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ap:apendiceD}{{1}{155}{Apéndice D}{chapter*.30}{}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Resultados por imagen durante el entrenamiento del modelo con data augmentation}{155}{section.Alph0.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Primera partición.}}{155}{table.Alph0.1}\protected@file@percent }
\newlabel{table:Daugmentation_images_1}{{1}{155}{Predicciones cross-validation modelo de ajuste fino del decoder. Primera partición}{table.Alph0.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Segunda partición.}}{156}{table.Alph0.2}\protected@file@percent }
\newlabel{table:Daugmentation_images_2}{{2}{156}{Predicciones cross-validation modelo de ajuste fino del decoder. Segunda partición}{table.Alph0.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Tercera partición.}}{157}{table.Alph0.3}\protected@file@percent }
\newlabel{table:Daugmentation_images_3}{{3}{157}{Predicciones cross-validation modelo de ajuste fino del decoder. Tercera partición}{table.Alph0.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Cuarta partición.}}{158}{table.Alph0.4}\protected@file@percent }
\newlabel{table:Daugmentation_images_4}{{4}{158}{Predicciones cross-validation modelo de ajuste fino del decoder. Cuarta partición}{table.Alph0.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Quinta partición.}}{159}{table.Alph0.5}\protected@file@percent }
\newlabel{table:Daugmentation_images_5}{{5}{159}{Predicciones cross-validation modelo de ajuste fino del decoder. Quinta partición}{table.Alph0.5}{}}
\global\csname @altsecnumformattrue\endcsname
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{16.01686pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{23.99994pt}
\global\@namedef{scr@dte@part@lastmaxnumwidth}{13.52026pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{26.49994pt}
