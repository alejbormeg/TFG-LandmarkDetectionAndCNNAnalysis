\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand*\new@tpo@label[2]{}
\@nameuse{bbl@beforestart}
\catcode `"\active 
\catcode `<\active 
\catcode `>\active 
\@nameuse{es@quoting}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\providecommand\BKM@entry[2]{}
\BKM@entry{id=1,dest={7469746C652E31},srcline={10}}{545C33353574756C6F}
\babel@aux{spanish}{}
\BKM@entry{id=2,dest={636861707465722A2E32},srcline={8}}{41677261646563696D69656E746F73}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Agradecimientos}{\es@scroman  {vii}}{chapter*.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\BKM@entry{id=3,dest={746F632E30},srcline={8}}{5C3331356E646963652067656E6572616C}
\BKM@entry{id=4,dest={636861707465722A2E37},srcline={9}}{4162737472616374}
\babel@aux{english}{}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Abstract}{\es@scroman  {xiii}}{chapter*.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\babel@aux{spanish}{}
\BKM@entry{id=5,dest={636861707465722A2E38},srcline={11}}{526573756D656E}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Resumen}{\es@scroman  {xv}}{chapter*.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\BKM@entry{id=6,dest={706172742E31},srcline={235}}{416E5C3334316C6973697320646520526564657320436F6E766F6C7563696F6E616C6573}
\@writefile{toc}{\contentsline {part}{\numberline {I}Análisis de Redes Convolucionales}{1}{part.1}\protected@file@percent }
\BKM@entry{id=7,dest={636861707465722E31},srcline={5}}{496E74726F64756363695C3336336E}
\@writefile{toc}{\contentsline {chapter}{\numberline {1}Introducción}{3}{chapter.1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{lof}{\contentsline {figure}{\numberline {1.1}{\ignorespaces Los tres coches deben identificarse como iguales, aunque se ecuentren desplazados.}}{3}{figure.1.1}\protected@file@percent }
\newlabel{fig:invarianza_traslaciones}{{1.1}{3}{Los tres coches deben identificarse como iguales, aunque se ecuentren desplazados}{figure.1.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.2}{\ignorespaces Acción de un difeomorfismo en una rejilla.}}{4}{figure.1.2}\protected@file@percent }
\newlabel{fig:difeomorfismo}{{1.2}{4}{Acción de un difeomorfismo en una rejilla}{figure.1.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.3}{\ignorespaces Todas las imágenes deberían clasificarse como 5, pese a las deformaciones.}}{4}{figure.1.3}\protected@file@percent }
\newlabel{fig:deformaciones_5}{{1.3}{4}{Todas las imágenes deberían clasificarse como 5, pese a las deformaciones}{figure.1.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {1.4}{\ignorespaces Deformación excesiva que permite confundir el 1 con el 2 cuando se le aplica el difeomorfismo. Por eso nos centramos en \emph  {``pequeñas''} deformaciones, para no alterar la identidad del objeto en la imagen.}}{4}{figure.1.4}\protected@file@percent }
\newlabel{fig:deformaciones_1}{{1.4}{4}{Deformación excesiva que permite confundir el 1 con el 2 cuando se le aplica el difeomorfismo. Por eso nos centramos en \entrecomillado {pequeñas} deformaciones, para no alterar la identidad del objeto en la imagen}{figure.1.4}{}}
\newlabel{eq::distancia}{{1.1}{5}{}{equation.1.0.1}{}}
\citation{doi:10.1137/S0036141002404838}
\newlabel{def::Lipschitz_cont}{{1.0.7}{6}{}{teorema.1.0.7}{}}
\newlabel{eq::Lipschitz_condition}{{1.2}{6}{}{equation.1.0.2}{}}
\@writefile{brf}{\backcite{doi:10.1137/S0036141002404838}{{6}{1.0.7}{equation.1.0.2}}}
\MT@newlabel{eq::distancia}
\MT@newlabel{eq::Lipschitz_condition}
\MT@newlabel{eq::Lipschitz_condition}
\BKM@entry{id=8,dest={636861707465722E32},srcline={4}}{4D6F64656C697A6163695C3336336E204D6174656D5C3334317469636120646520756E6120526564204E6575726F6E616C20436F6E766F6C7563696F6E616C}
\citation{GroupInvariantScattering}
\BKM@entry{id=9,dest={73656374696F6E2E322E31},srcline={21}}{446520466F75726965722061206C6173206F6E64656C65746173206465204C6974746C65776F6F642D50616C6579}
\BKM@entry{id=10,dest={73756273656374696F6E2E322E312E31},srcline={23}}{456C206D5C33363364756C6F206465206C61205472616E73666F726D61646120646520466F7572696572}
\citation{DigitalImageProcessing}
\@writefile{toc}{\contentsline {chapter}{\numberline {2}Modelización Matemática de una Red Neuronal Convolucional}{7}{chapter.2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{brf}{\backcite{GroupInvariantScattering}{{7}{2}{chapter.2}}}
\@writefile{toc}{\contentsline {section}{\numberline {2.1}De Fourier a las ondeletas de Littlewood-Paley}{7}{section.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.1}El módulo de la Transformada de Fourier}{7}{subsection.2.1.1}\protected@file@percent }
\@writefile{brf}{\backcite{DigitalImageProcessing}{{7}{2.1.1}{subsection.2.1.1}}}
\newlabel{lema::invarianza_traslaciones}{{2.1.2}{8}{}{teorema.2.1.2}{}}
\newlabel{lemma:TF_inestable_difeomorfismos}{{2.1.3}{8}{}{teorema.2.1.3}{}}
\newlabel{eq::lipschitz_condition}{{2.1}{8}{}{equation.2.1.1}{}}
\newlabel{eq:res_auxiliar_1}{{2.2}{9}{}{equation.2.1.2}{}}
\newlabel{eq:res_auxiliar_2}{{2.3}{9}{}{equation.2.1.3}{}}
\MT@newlabel{eq:res_auxiliar_1}
\MT@newlabel{eq:res_auxiliar_2}
\newlabel{eq::1.1}{{2.1.3}{11}{}{equation.2.1.3}{}}
\newlabel{eq::Plancharel}{{2.4}{11}{}{equation.2.1.4}{}}
\MT@newlabel{eq::lipschitz_condition}
\BKM@entry{id=11,dest={73756273656374696F6E2E322E312E32},srcline={217}}{416C7465726E61746976613A204C6173206F6E64656C65746173}
\citation{MallatWavelets}
\@writefile{lof}{\contentsline {figure}{\numberline {2.1}{\ignorespaces Como podemos ver en la imagen, para los valores $\epsilon =0.1$, $\xi =100$ y $M=5$ ambas funciones tienen soporte casi disjunto de manera que la diferencia entre ellas en el intervalo $[-5,5]$ coincide prácticamente con $g_1(t)$.}}{12}{figure.2.1}\protected@file@percent }
\newlabel{fig:Grafica_funciones}{{2.1}{12}{Como podemos ver en la imagen, para los valores $\epsilon =0.1$, $\xi =100$ y $M=5$ ambas funciones tienen soporte casi disjunto de manera que la diferencia entre ellas en el intervalo $[-5,5]$ coincide prácticamente con $g_1(t)$}{figure.2.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.2}Alternativa: Las ondeletas}{12}{subsection.2.1.2}\protected@file@percent }
\@writefile{brf}{\backcite{MallatWavelets}{{12}{2.1.2}{subsection.2.1.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.2}{\ignorespaces Representación gráfica de la ondeleta de Haar.}}{13}{figure.2.2}\protected@file@percent }
\newlabel{fig:Ondeleta_de_Haar}{{2.2}{13}{Representación gráfica de la ondeleta de Haar}{figure.2.2}{}}
\citation{MallatWavelets}
\citation{HaarBasis}
\citation{HaarBasis}
\@writefile{lof}{\contentsline {figure}{\numberline {2.3}{\ignorespaces En el ejemplo $1)$ podemos ver un ejemplo de filtro generado por el soporte de una ondeleta para la detección de líneas bordes verticales, en la imagen $2)$ podemos ver un ejemplo de filtro generado por el soporte de una ondeleta para la detección de bordes horizontales, y en el ejemplo $3)$ para las diagonales. Todas tienen soporte cuadrado.}}{14}{figure.2.3}\protected@file@percent }
\newlabel{fig:base_haar}{{2.3}{14}{En el ejemplo $1)$ podemos ver un ejemplo de filtro generado por el soporte de una ondeleta para la detección de líneas bordes verticales, en la imagen $2)$ podemos ver un ejemplo de filtro generado por el soporte de una ondeleta para la detección de bordes horizontales, y en el ejemplo $3)$ para las diagonales. Todas tienen soporte cuadrado}{figure.2.3}{}}
\@writefile{brf}{\backcite{MallatWavelets}{{14}{2}{Hfootnote.3}}}
\BKM@entry{id=12,dest={73756273656374696F6E2E322E312E33},srcline={338}}{4C61205472616E73666F726D616461206465204C6974746C65776F6F642D50616C6579}
\@writefile{lof}{\contentsline {figure}{\numberline {2.4}{\ignorespaces Ejemplos de aplicar la base de Haar a dos imágenes.Los filtros resaltan los bordes en tres direcciones, horizontal (derecha) vertical (abajo) y en diagonal (abajo derecha). Imagen extraida de \cite  {HaarBasis}.}}{15}{figure.2.4}\protected@file@percent }
\@writefile{brf}{\backcite{HaarBasis}{{15}{2.4}{figure.2.4}}}
\newlabel{fig:ejemplo_haar}{{2.4}{15}{Ejemplos de aplicar la base de Haar a dos imágenes.Los filtros resaltan los bordes en tres direcciones, horizontal (derecha) vertical (abajo) y en diagonal (abajo derecha). Imagen extraida de \cite {HaarBasis}}{figure.2.4}{}}
\citation{WAVELETS}
\citation{WAVELETS}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.3}La Transformada de Littlewood-Paley}{16}{subsection.2.1.3}\protected@file@percent }
\newlabel{ch:seccion12}{{2.1.3}{16}{La Transformada de Littlewood-Paley}{subsection.2.1.3}{}}
\newlabel{Teorema::Convolucion}{{2.1.5}{16}{}{teorema.2.1.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {2.5}{\ignorespaces Como podemos ver, en el caso de la izquierda la ondleta (en color morado) se ve afectada por una menor escala, lo que le permitirá detectar con mayores frecuencias los cambios que se producen en la señal al convolucionar con esta a lo largo del tiempo. En cambio, en el segundo caso, se ve afectada por una escala mayor, lo que le impedirá detectar con tanta precisión los cambios que se produzcan en la señal. Imagen extraida de \cite  {WAVELETS}.}}{17}{figure.2.5}\protected@file@percent }
\@writefile{brf}{\backcite{WAVELETS}{{17}{2.5}{figure.2.5}}}
\newlabel{fig:scattering_propagator}{{2.5}{17}{Como podemos ver, en el caso de la izquierda la ondleta (en color morado) se ve afectada por una menor escala, lo que le permitirá detectar con mayores frecuencias los cambios que se producen en la señal al convolucionar con esta a lo largo del tiempo. En cambio, en el segundo caso, se ve afectada por una escala mayor, lo que le impedirá detectar con tanta precisión los cambios que se produzcan en la señal. Imagen extraida de \cite {WAVELETS}}{figure.2.5}{}}
\newlabel{eq::norma}{{2.5}{17}{La Transformada de Littlewood-Paley}{equation.2.1.5}{}}
\newlabel{unitario}{{2.1.6}{18}{}{teorema.2.1.6}{}}
\newlabel{eq::1.2}{{2.6}{18}{}{equation.2.1.6}{}}
\MT@newlabel{eq::1.2}
\newlabel{eq::1.3}{{2.7}{18}{La Transformada de Littlewood-Paley}{equation.2.1.7}{}}
\MT@newlabel{eq::1.2}
\MT@newlabel{eq::1.2}
\MT@newlabel{eq::1.3}
\BKM@entry{id=13,dest={73756273656374696F6E2E322E312E34},srcline={516}}{436F6E76656E696F73207061726120667574757261732073656363696F6E6573}
\MT@newlabel{eq::1.2}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::Plancharel}
\MT@newlabel{eq::norma}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::1.3}
\MT@newlabel{eq::1.2}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1.4}Convenios para futuras secciones}{19}{subsection.2.1.4}\protected@file@percent }
\MT@newlabel{eq::1.2}
\BKM@entry{id=14,dest={73656374696F6E2E322E32},srcline={546}}{456C206F70657261646F722064652064697370657273695C3336336E20736F62726520756E2063616D696E6F206F7264656E61646F}
\@writefile{toc}{\contentsline {section}{\numberline {2.2}El operador de dispersión sobre un camino ordenado}{20}{section.2.2}\protected@file@percent }
\newlabel{lema:Invarianza_traslaciones_integral}{{2.2.1}{20}{}{teorema.2.2.1}{}}
\BKM@entry{id=15,dest={73756273656374696F6E2E322E322E31},srcline={599}}{456A656D706C6F2070617261206F6274656E657220636F6566696369656E74657320696E76617269616E74657320706F7220747261736C6163696F6E6573}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.1}Ejemplo para obtener coeficientes invariantes por traslaciones}{21}{subsection.2.2.1}\protected@file@percent }
\newlabel{eq::1.4}{{2.8}{21}{Ejemplo para obtener coeficientes invariantes por traslaciones}{equation.2.2.8}{}}
\BKM@entry{id=16,dest={73756273656374696F6E2E322E322E32},srcline={636}}{456C206F70657261646F72206D5C33363364756C6F}
\citation{JBrunaOperatorsCommutingDiff}
\citation{GroupInvariantScattering}
\citation{bruna2013invariant}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.2}El operador módulo}{22}{subsection.2.2.2}\protected@file@percent }
\@writefile{brf}{\backcite{JBrunaOperatorsCommutingDiff}{{22}{2.2.2}{subsection.2.2.2}}}
\@writefile{brf}{\backcite{GroupInvariantScattering}{{22}{2.2.2}{subsection.2.2.2}}}
\@writefile{brf}{\backcite{bruna2013invariant}{{22}{2.2.2}{subsection.2.2.2}}}
\MT@newlabel{eq::1.4}
\BKM@entry{id=17,dest={73756273656374696F6E2E322E322E33},srcline={717}}{50726F706965646164657320646520756E2063616D696E6F206465206672656375656E636961732E}
\BKM@entry{id=18,dest={73756273656374696F6E2E322E322E34},srcline={754}}{436F6E737472756363695C3336336E2064656C206F70657261646F722064652064697370657273695C3336336E2E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.3}Propiedades de un camino de frecuencias.}{24}{subsection.2.2.3}\protected@file@percent }
\newlabel{proposicionSumaCaminos}{{2.2.6}{24}{}{teorema.2.2.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2.4}Construcción del operador de dispersión.}{24}{subsection.2.2.4}\protected@file@percent }
\newlabel{def:S_barra}{{2.2.7}{24}{}{teorema.2.2.7}{}}
\BKM@entry{id=19,dest={73656374696F6E2E322E33},srcline={827}}{50726F70616761646F722064652064697370657273695C3336336E207920636F6E736572766163695C3336336E206465206C61204E6F726D61}
\BKM@entry{id=20,dest={73756273656374696F6E2E322E332E31},srcline={830}}{50726F6365736F2064652064697370657273695C3336336E2064656C2070726F70616761646F722E}
\citation{bruna2013invariant}
\citation{bruna2013invariant}
\BKM@entry{id=21,dest={73756273656374696F6E2E322E332E32},srcline={874}}{4469666572656E6369617320792073696D696C69747564657320636F6E20756E6120434E4E}
\citation{lecun2015deep}
\@writefile{toc}{\contentsline {section}{\numberline {2.3}Propagador de dispersión y conservación de la Norma}{26}{section.2.3}\protected@file@percent }
\newlabel{ch:seccion13}{{2.3}{26}{Propagador de dispersión y conservación de la Norma}{section.2.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.1}Proceso de dispersión del propagador.}{26}{subsection.2.3.1}\protected@file@percent }
\newlabel{eq::1.5}{{2.9}{26}{Proceso de dispersión del propagador}{equation.2.3.9}{}}
\BKM@entry{id=22,dest={73756273656374696F6E2E322E332E33},srcline={890}}{52656C6163695C3336336E20636F6E2068657272616D69656E74617320636C5C333431736963617320646520766973695C3336336E20706F7220636F6D70757461646F72}
\citation{DistinctiveImageFeatures}
\citation{Daisy}
\@writefile{lof}{\contentsline {figure}{\numberline {2.6}{\ignorespaces Un PD $U_J$ aplicado a un punto de una señal $f(x)$ calcula $U[\lambda _1]f(x)=|f(x)\ast \psi _{\lambda _1}|$ y como salida a la capa $m=0$ se promedian los coeficientes que han dado $0$ (por tener $2^j<2^{-J}$) obteniendo como salida $S_J[\emptyset ]f(x)=f(x)\ast \phi _{2^J}$ (como se puede ver en la flecha negra). Después se aplica de nuevo $U_J$ a cada coeficiente $U[\lambda _1]f(x)$ del paso anterior ($m=1$) $U[\lambda _1,\lambda 2]f(x)$ obteniendo como salida $S_J[\lambda _1]f(x)=U[\lambda _1]f(x) \ast \phi _{2^J}$. Se repite este proceso de manera recursiva para cada coeficiente $U[p]f(x)$ y obteniendo como resultado $S_J[p]f(x)=U[p]f(x) \ast \phi _{2^J}$. Imagen extraida de \cite  {bruna2013invariant}.}}{27}{figure.2.6}\protected@file@percent }
\@writefile{brf}{\backcite{bruna2013invariant}{{27}{2.6}{figure.2.6}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.2}Diferencias y similitudes con una CNN}{27}{subsection.2.3.2}\protected@file@percent }
\@writefile{brf}{\backcite{lecun2015deep}{{27}{2.3.2}{subsection.2.3.2}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.3}Relación con herramientas clásicas de visión por computador}{27}{subsection.2.3.3}\protected@file@percent }
\@writefile{brf}{\backcite{DistinctiveImageFeatures}{{27}{2.3.3}{subsection.2.3.3}}}
\BKM@entry{id=23,dest={73756273656374696F6E2E322E332E34},srcline={894}}{4F70657261646F72206E6F20657870616E7369766F2E}
\@writefile{brf}{\backcite{Daisy}{{28}{2.3.3}{subsection.2.3.3}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.4}Operador no expansivo.}{28}{subsection.2.3.4}\protected@file@percent }
\newlabel{proposicion::NoExpansiva}{{2.3.1}{28}{}{teorema.2.3.1}{}}
\MT@newlabel{eq::1.5}
\BKM@entry{id=24,dest={73756273656374696F6E2E322E332E35},srcline={965}}{436F6E736572766163695C3336336E206465206C61206E6F726D612E}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.5}Conservación de la norma.}{29}{subsection.2.3.5}\protected@file@percent }
\newlabel{lema::Cota_inferior}{{2.3.2}{29}{}{teorema.2.3.2}{}}
\citation{GroupInvariantScattering}
\newlabel{eq::1.6}{{2.10}{30}{}{equation.2.3.10}{}}
\newlabel{eq::1.7}{{2.11}{30}{}{equation.2.3.11}{}}
\newlabel{lema::Admisibilidad}{{2.3.4}{30}{}{teorema.2.3.4}{}}
\MT@newlabel{eq::1.7}
\newlabel{eq::1.9}{{2.12}{30}{}{equation.2.3.12}{}}
\@writefile{brf}{\backcite{GroupInvariantScattering}{{30}{2.3.5}{equation.2.3.12}}}
\newlabel{teoremaOndeletasAdmisibles}{{2.3.5}{30}{}{teorema.2.3.5}{}}
\MT@newlabel{eq::1.6}
\MT@newlabel{eq::1.9}
\newlabel{eq::1.8}{{2.13}{31}{Conservación de la norma}{equation.2.3.13}{}}
\MT@newlabel{eq::1.8}
\BKM@entry{id=25,dest={73756273656374696F6E2E322E332E36},srcline={1152}}{436F6E636C7573696F6E65732065787472615C3335356461732064656C2074656F72656D61}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3.6}Conclusiones extraídas del teorema}{33}{subsection.2.3.6}\protected@file@percent }
\BKM@entry{id=26,dest={636861707465722E33},srcline={3}}{496E76617269616E7A6120706F7220547261736C6163696F6E6573}
\BKM@entry{id=27,dest={73656374696F6E2E332E31},srcline={7}}{4E6F20657870616E736976696461642064656C206F70657261646F722064652076656E74616E6120656E20636F6E6A756E746F732064652063616D696E6F73}
\@writefile{toc}{\contentsline {chapter}{\numberline {3}Invarianza por Traslaciones}{35}{chapter.3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:seccion14}{{3}{35}{Invarianza por Traslaciones}{chapter.3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {3.1}No expansividad del operador de ventana en conjuntos de caminos}{35}{section.3.1}\protected@file@percent }
\newlabel{eq::1.10}{{3.1}{35}{}{equation.3.1.1}{}}
\MT@newlabel{eq::1.10}
\newlabel{eq::1.11}{{3.2}{35}{No expansividad del operador de ventana en conjuntos de caminos}{equation.3.1.2}{}}
\MT@newlabel{eq::1.11}
\MT@newlabel{eq::1.10}
\MT@newlabel{eq::1.11}
\BKM@entry{id=28,dest={73656374696F6E2E332E32},srcline={142}}{496E76617269616E7A6120706F7220747261736C6163696F6E6573}
\MT@newlabel{eq::1.11}
\citation{SchurLemma}
\@writefile{toc}{\contentsline {section}{\numberline {3.2}Invarianza por traslaciones}{38}{section.3.2}\protected@file@percent }
\MT@newlabel{eq::1.7}
\newlabel{lema::constante}{{3.2.1}{38}{}{teorema.3.2.1}{}}
\@writefile{brf}{\backcite{SchurLemma}{{38}{3.2}{teorema.3.2.1}}}
\newlabel{invarianzaTraslaciones}{{3.2.2}{40}{}{teorema.3.2.2}{}}
\MT@newlabel{eq::1.7}
\MT@newlabel{eq::1.9}
\BKM@entry{id=29,dest={636861707465722E34},srcline={3}}{436F6E636C7573696F6E657320792074726162616A6F732066757475726F73}
\@writefile{toc}{\contentsline {chapter}{\numberline {4}Conclusiones y trabajos futuros}{43}{chapter.4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\BKM@entry{id=30,dest={706172742E32},srcline={242}}{4C6F63616C697A6163695C3336336E206465206C616E646D61726B7320636566616C6F6D5C333531747269636F7320706F72206D6564696F20646520745C333531636E69636173206465206665772D73686F74206C6561726E696E67}
\@writefile{toc}{\contentsline {part}{\numberline {II}Localización de landmarks cefalométricos por medio de técnicas de few-shot learning}{45}{part.2}\protected@file@percent }
\BKM@entry{id=31,dest={636861707465722E35},srcline={4}}{496E74726F64756363695C3336336E}
\citation{norvig2002modern}
\BKM@entry{id=32,dest={73656374696F6E2E352E31},srcline={22}}{4465736372697063695C3336336E2064656C2070726F626C656D612079204D6F7469766163695C3336336E}
\citation{article}
\citation{article}
\citation{Huete2015PastPA}
\@writefile{toc}{\contentsline {chapter}{\numberline {5}Introducción}{47}{chapter.5}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ch:Introduccion_informatica}{{5}{47}{Introducción}{chapter.5}{}}
\@writefile{brf}{\backcite{norvig2002modern}{{47}{5}{chapter.5}}}
\@writefile{toc}{\contentsline {section}{\numberline {5.1}Descripción del problema y Motivación}{47}{section.5.1}\protected@file@percent }
\citation{damas2020handbook}
\citation{damas2020handbook}
\@writefile{lof}{\contentsline {figure}{\numberline {5.1}{\ignorespaces Etapas del proceso de superposición craneofacial. En primer lugar se realiza la recogida de imágenes ante-mortem (AM) y muestras post-mortem (PM) junto con el marcado de landmarks y escaneo $3D$ del cráneo candidato. Tras esto comienza el experto comienza el proceso iterativo en el que trata de hacer coincidir los landmarks cefalométricos y craneométricos. Finalmente se realiza una toma de decisiones en función de los resultados obtenidos. Imagen extraída de \cite  {article}.}}{48}{figure.5.1}\protected@file@percent }
\@writefile{brf}{\backcite{article}{{48}{5.1}{figure.5.1}}}
\newlabel{fig:procesoSCF}{{5.1}{48}{Etapas del proceso de superposición craneofacial. En primer lugar se realiza la recogida de imágenes ante-mortem (AM) y muestras post-mortem (PM) junto con el marcado de landmarks y escaneo $3D$ del cráneo candidato. Tras esto comienza el experto comienza el proceso iterativo en el que trata de hacer coincidir los landmarks cefalométricos y craneométricos. Finalmente se realiza una toma de decisiones en función de los resultados obtenidos. Imagen extraída de \cite {article}}{figure.5.1}{}}
\@writefile{brf}{\backcite{Huete2015PastPA}{{48}{5.1}{figure.5.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.2}{\ignorespaces En esta imagen podemos ver la correspondencia entre landmarks craneométricos y cefalométricos. Algunos de los landmarks que aparecen en la imagen serán estudiados en este trabajo. Imagen extraída de \cite  {damas2020handbook}.}}{48}{figure.5.2}\protected@file@percent }
\@writefile{brf}{\backcite{damas2020handbook}{{48}{5.2}{figure.5.2}}}
\newlabel{fig:landmarks_marcados}{{5.2}{48}{En esta imagen podemos ver la correspondencia entre landmarks craneométricos y cefalométricos. Algunos de los landmarks que aparecen en la imagen serán estudiados en este trabajo. Imagen extraída de \cite {damas2020handbook}}{figure.5.2}{}}
\citation{browatzki20203fabrec}
\@writefile{brf}{\backcite{browatzki20203fabrec}{{49}{5.1}{figure.5.2}}}
\BKM@entry{id=33,dest={73656374696F6E2E352E32},srcline={97}}{52657175697369746F73206D5C3335356E696D6F732064656C20616C676F7269746D6F}
\BKM@entry{id=34,dest={73656374696F6E2E352E33},srcline={112}}{4F626A657469766F73}
\BKM@entry{id=35,dest={73656374696F6E2E352E34},srcline={123}}{506C616E696669636163695C3336336E}
\@writefile{toc}{\contentsline {section}{\numberline {5.2}Requisitos mínimos del algoritmo}{50}{section.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.3}Objetivos}{50}{section.5.3}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {5.4}Planificación}{51}{section.5.4}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {5.3}{\ignorespaces Diseño en cascada retroalimentado empleado.}}{51}{figure.5.3}\protected@file@percent }
\newlabel{Fig::Ciclo de vida}{{5.3}{51}{Diseño en cascada retroalimentado empleado}{figure.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.4}{\ignorespaces Planificación original.}}{52}{figure.5.4}\protected@file@percent }
\newlabel{Fig::Planificacion original}{{5.4}{52}{Planificación original}{figure.5.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5.5}{\ignorespaces Planificación final.}}{53}{figure.5.5}\protected@file@percent }
\newlabel{Fig::Planificacion final}{{5.5}{53}{Planificación final}{figure.5.5}{}}
\BKM@entry{id=36,dest={636861707465722E36},srcline={2}}{46756E64616D656E746F732054655C3336337269636F732079204D5C333531746F646F73}
\BKM@entry{id=37,dest={73656374696F6E2E362E31},srcline={6}}{417072656E64697A616A65204175746F6D5C3334317469636F}
\BKM@entry{id=38,dest={73756273656374696F6E2E362E312E31},srcline={36}}{417072656E64697A616A6520537570657276697361646F}
\@writefile{toc}{\contentsline {chapter}{\numberline {6}Fundamentos Teóricos y Métodos}{55}{chapter.6}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {6.1}Aprendizaje Automático}{55}{section.6.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.1}Aprendizaje Supervisado}{56}{subsection.6.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.1}Regresión}{56}{subsubsection.6.1.1.1}\protected@file@percent }
\newlabel{section::Regresion}{{6.1.1.1}{56}{Regresión}{subsubsection.6.1.1.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.2}Gradiente Descendente}{57}{subsubsection.6.1.1.2}\protected@file@percent }
\BKM@entry{id=39,dest={73756273656374696F6E2E362E312E32},srcline={158}}{417072656E64697A616A65206E6F20537570657276697361646F}
\BKM@entry{id=40,dest={73756273656374696F6E2E362E312E33},srcline={161}}{417072656E64697A616A65204175746F6D5C3334317469636F20656E20657374652054726162616A6F}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.3}Gradiente Descendente Estocástico}{58}{subsubsection.6.1.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.1.4}Clasificación}{58}{subsubsection.6.1.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.2}Aprendizaje no Supervisado}{58}{subsection.6.1.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.3}Aprendizaje Automático en este Trabajo}{58}{subsection.6.1.3}\protected@file@percent }
\BKM@entry{id=41,dest={73756273656374696F6E2E362E312E34},srcline={172}}{566973695C3336336E20706F7220436F6D70757461646F72}
\citation{rosenfeld1988computer}
\BKM@entry{id=42,dest={73756273656374696F6E2E362E312E35},srcline={183}}{44656570204C6561726E696E67}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.4}Visión por Computador}{59}{subsection.6.1.4}\protected@file@percent }
\@writefile{brf}{\backcite{rosenfeld1988computer}{{59}{6.1.4}{subsection.6.1.4}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1.5}Deep Learning}{59}{subsection.6.1.5}\protected@file@percent }
\citation{sharma2017activation}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.5.1}Redes Neuronales}{60}{subsubsection.6.1.5.1}\protected@file@percent }
\newlabel{sub:redes_neuronales}{{6.1.5.1}{60}{Redes Neuronales}{subsubsection.6.1.5.1}{}}
\@writefile{brf}{\backcite{Goodfellow-et-al-2016}{{60}{6.1.5.1}{subsubsection.6.1.5.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.1}{\ignorespaces Red neuronal con una capa oculta. Formalmente podría describirse como $f'(x)=(f_3(f_2(f_1(x))))$, dónde $f_1$ hace referencia a la capa de entrada a la red, $f_2$ a la capa oculta y $f_3$ a la capa de salida.}}{60}{figure.6.1}\protected@file@percent }
\newlabel{fig:red_neuronal_capa_oculta}{{6.1}{60}{Red neuronal con una capa oculta. Formalmente podría describirse como $f'(x)=(f_3(f_2(f_1(x))))$, dónde $f_1$ hace referencia a la capa de entrada a la red, $f_2$ a la capa oculta y $f_3$ a la capa de salida}{figure.6.1}{}}
\@writefile{brf}{\backcite{sharma2017activation}{{60}{6.1.5.1}{figure.6.1}}}
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{StanfordCourse}
\BKM@entry{id=43,dest={73656374696F6E2E362E32},srcline={293}}{5265646573204E6575726F6E616C657320436F6E766F6C7563696F6E616C6573}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.1.5.2}Backpropagation}{62}{subsubsection.6.1.5.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.2}{\ignorespaces Ejemplo de Grafo computacional junto con la salida para una entrada concreta $x=-2$,$y=5$, $z=-4$. La imagen ha sido extraída del curso \cite  {StanfordCourse}.}}{62}{figure.6.2}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{62}{6.2}{figure.6.2}}}
\newlabel{fig:GrafoComputacional}{{6.2}{62}{Ejemplo de Grafo computacional junto con la salida para una entrada concreta $x=-2$,$y=5$, $z=-4$. La imagen ha sido extraída del curso \cite {StanfordCourse}}{figure.6.2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.2}Redes Neuronales Convolucionales}{62}{section.6.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.3}{\ignorespaces Como podemos ver en la imagen superior, en primer lugar se renombra la salida de la operación $x+y$ por $q$, de manera que $f=qz$. Tras esto se empiezan a calcular las derivadas parciales correspondientes desde el final hacia la entrada, aplicando cuando sea necesario la regla de la cadena hasta obtener la derivada de cada nodo en la imagen de abajo. Las imágenes han sido extraídas de \cite  {StanfordCourse}}}{63}{figure.6.3}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{63}{6.3}{figure.6.3}}}
\newlabel{fig:Ejemplo BP}{{6.3}{63}{Como podemos ver en la imagen superior, en primer lugar se renombra la salida de la operación $x+y$ por $q$, de manera que $f=qz$. Tras esto se empiezan a calcular las derivadas parciales correspondientes desde el final hacia la entrada, aplicando cuando sea necesario la regla de la cadena hasta obtener la derivada de cada nodo en la imagen de abajo. Las imágenes han sido extraídas de \cite {StanfordCourse}}{figure.6.3}{}}
\BKM@entry{id=44,dest={73756273656374696F6E2E362E322E31},srcline={345}}{4361706120436F6E766F6C7563696F6E616C}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.1}Capa Convolucional}{64}{subsection.6.2.1}\protected@file@percent }
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{StanfordCourse}
\BKM@entry{id=45,dest={73756273656374696F6E2E362E322E32},srcline={378}}{4361706120646520506F6F6C696E67}
\@writefile{lof}{\contentsline {figure}{\numberline {6.4}{\ignorespaces Ejemplo de cálculo de mapa de activación en una capa convolucional para un determinado volumen de entrada. El parámetro depth nos dice la cantidad de mapas de activación generamos para el volumen de entrada, o dicho de otro modo, el número de filtros que aplicamos. La imagen ha sido extraída de \cite  {StanfordCourse}}}{65}{figure.6.4}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{65}{6.4}{figure.6.4}}}
\newlabel{fig:mapa_activacion}{{6.4}{65}{Ejemplo de cálculo de mapa de activación en una capa convolucional para un determinado volumen de entrada. El parámetro depth nos dice la cantidad de mapas de activación generamos para el volumen de entrada, o dicho de otro modo, el número de filtros que aplicamos. La imagen ha sido extraída de \cite {StanfordCourse}}{figure.6.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.5}{\ignorespaces Sucesión de varias capas convolucionales + ReLU que describen la estructura básica de una CNN. Cabe destacar como la produndidad de los filtros es siemore la misma que la del volumen de entrada, de acuerdo a lo que hemos dicho anteriormente. La imagen han sido extraída de \cite  {StanfordCourse}}}{65}{figure.6.5}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{65}{6.5}{figure.6.5}}}
\newlabel{fig:estructura_convnet}{{6.5}{65}{Sucesión de varias capas convolucionales + ReLU que describen la estructura básica de una CNN. Cabe destacar como la produndidad de los filtros es siemore la misma que la del volumen de entrada, de acuerdo a lo que hemos dicho anteriormente. La imagen han sido extraída de \cite {StanfordCourse}}{figure.6.5}{}}
\citation{StanfordCourse}
\citation{StanfordCourse}
\BKM@entry{id=46,dest={73756273656374696F6E2E362E322E33},srcline={399}}{4361706120546F74616C6D656E746520436F6E656374616461205C2846756C6C7920436F6E65637465645C29}
\BKM@entry{id=47,dest={73756273656374696F6E2E362E322E34},srcline={406}}{4261746368204E6F726D616C697A6174696F6E}
\BKM@entry{id=48,dest={73756273656374696F6E2E362E322E35},srcline={409}}{4F7074696D697A61646F72204164616D}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.2}Capa de Pooling}{66}{subsection.6.2.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.6}{\ignorespaces Ejemplo de capa de pooling usando la operación del máximo. La imagen han sido extraída de \cite  {StanfordCourse}}}{66}{figure.6.6}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{66}{6.6}{figure.6.6}}}
\newlabel{fig:pooling}{{6.6}{66}{Ejemplo de capa de pooling usando la operación del máximo. La imagen han sido extraída de \cite {StanfordCourse}}{figure.6.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.3}Capa Totalmente Conectada (Fully Conected)}{66}{subsection.6.2.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.4}Batch Normalization}{66}{subsection.6.2.4}\protected@file@percent }
\BKM@entry{id=49,dest={73756273656374696F6E2E362E322E36},srcline={412}}{50726F6365736F20646520656E7472656E616D69656E746F20646520756E6120434E4E}
\BKM@entry{id=50,dest={73756273656374696F6E2E362E322E37},srcline={426}}{45766F6C7563695C3336336E206465206C617320434E4E}
\citation{EvolutionCNN}
\citation{lecun1998gradient}
\citation{lecun1998gradient}
\citation{lecun1998gradient}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.5}Optimizador Adam}{67}{subsection.6.2.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.6}Proceso de entrenamiento de una CNN}{67}{subsection.6.2.6}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2.7}Evolución de las CNN}{67}{subsection.6.2.7}\protected@file@percent }
\@writefile{brf}{\backcite{EvolutionCNN}{{67}{6.2.7}{subsection.6.2.7}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.7.1}LeNet-5}{67}{subsubsection.6.2.7.1}\protected@file@percent }
\@writefile{brf}{\backcite{lecun1998gradient}{{67}{6.2.7.1}{subsubsection.6.2.7.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.7}{\ignorespaces Arquitectura de la red LeNet. Como podemos observar tiene capas convolucionales, capas de average pooling y capas totalmente conectadas al final. Imagen extraída de \cite  {lecun1998gradient}.}}{67}{figure.6.7}\protected@file@percent }
\@writefile{brf}{\backcite{lecun1998gradient}{{67}{6.7}{figure.6.7}}}
\newlabel{fig:LeNet}{{6.7}{67}{Arquitectura de la red LeNet. Como podemos observar tiene capas convolucionales, capas de average pooling y capas totalmente conectadas al final. Imagen extraída de \cite {lecun1998gradient}}{figure.6.7}{}}
\citation{krizhevsky2012imagenet}
\citation{krizhevsky2012imagenet}
\citation{krizhevsky2012imagenet}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.7.2}AlexNet}{68}{subsubsection.6.2.7.2}\protected@file@percent }
\@writefile{brf}{\backcite{krizhevsky2012imagenet}{{68}{6.2.7.2}{subsubsection.6.2.7.2}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.8}{\ignorespaces Arquitectura de la red AlexNet. Destaca que parece estar \emph  {``partida''} en dos mitades, esto es porque por primera vez se usaron las GPUs para entrenar la red de manera que una GPU realizaba la parte superior de la arquitectura y otra la parte inferior. Imagen extraída de \cite  {krizhevsky2012imagenet}.}}{68}{figure.6.8}\protected@file@percent }
\@writefile{brf}{\backcite{krizhevsky2012imagenet}{{68}{6.8}{figure.6.8}}}
\newlabel{fig:AlexNet}{{6.8}{68}{Arquitectura de la red AlexNet. Destaca que parece estar \entrecomillado {partida} en dos mitades, esto es porque por primera vez se usaron las GPUs para entrenar la red de manera que una GPU realizaba la parte superior de la arquitectura y otra la parte inferior. Imagen extraída de \cite {krizhevsky2012imagenet}}{figure.6.8}{}}
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{szegedy2015going}
\citation{StanfordCourse}
\citation{StanfordCourse}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.7.3}GoogLeNet}{69}{subsubsection.6.2.7.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {6.9}{\ignorespaces Ejemplos de módulos Inception. Imágenes extraídas de \cite  {StanfordCourse}.}}{69}{figure.6.9}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{69}{6.9}{figure.6.9}}}
\newlabel{fig:inception}{{6.9}{69}{Ejemplos de módulos Inception. Imágenes extraídas de \cite {StanfordCourse}}{figure.6.9}{}}
\@writefile{brf}{\backcite{szegedy2015going}{{69}{6.2.7.3}{figure.6.9}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.10}{\ignorespaces Arquitectura de GoogLeNet usando módulos Inception.Imagen extraída de \cite  {StanfordCourse}}}{69}{figure.6.10}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{69}{6.10}{figure.6.10}}}
\newlabel{fig:GoogLeNet}{{6.10}{69}{Arquitectura de GoogLeNet usando módulos Inception.Imagen extraída de \cite {StanfordCourse}}{figure.6.10}{}}
\citation{simonyan2014very}
\citation{StanfordCourse}
\citation{StanfordCourse}
\citation{he2016deep}
\citation{he2016deep}
\citation{he2016deep}
\citation{StanfordCourse}
\citation{StanfordCourse}
\BKM@entry{id=51,dest={73656374696F6E2E362E33},srcline={539}}{4175746F656E636F64657273}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.7.4}VGG-16}{70}{subsubsection.6.2.7.4}\protected@file@percent }
\@writefile{brf}{\backcite{simonyan2014very}{{70}{6.2.7.4}{subsubsection.6.2.7.4}}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.11}{\ignorespaces Arquitectura de VGG-16.Imagen extraída de \cite  {StanfordCourse}.}}{70}{figure.6.11}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{70}{6.11}{figure.6.11}}}
\newlabel{fig:VGG}{{6.11}{70}{Arquitectura de VGG-16.Imagen extraída de \cite {StanfordCourse}}{figure.6.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.7.5}ResNet}{70}{subsubsection.6.2.7.5}\protected@file@percent }
\@writefile{brf}{\backcite{he2016deep}{{70}{6.2.7.5}{subsubsection.6.2.7.5}}}
\BKM@entry{id=52,dest={73756273656374696F6E2E362E332E31},srcline={542}}{496E74726F64756363695C3336336E}
\citation{autoencoders2017}
\@writefile{lof}{\contentsline {figure}{\numberline {6.12}{\ignorespaces Bloque residual de una ResNet. Como vemos, se suma el tensor $x$ con el tensor $\mathcal  {F}(x)$ que surge unas etapas después. Imagen extraída de \cite  {he2016deep}.}}{71}{figure.6.12}\protected@file@percent }
\@writefile{brf}{\backcite{he2016deep}{{71}{6.12}{figure.6.12}}}
\newlabel{fig:Resnet}{{6.12}{71}{Bloque residual de una ResNet. Como vemos, se suma el tensor $x$ con el tensor $\mathcal {F}(x)$ que surge unas etapas después. Imagen extraída de \cite {he2016deep}}{figure.6.12}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.13}{\ignorespaces Resumen de los ganadores del concurso ILSVRC hasta 2015 con la aparición de Resnet. Imagen extraída de \cite  {StanfordCourse}.}}{71}{figure.6.13}\protected@file@percent }
\@writefile{brf}{\backcite{StanfordCourse}{{71}{6.13}{figure.6.13}}}
\newlabel{fig:ImageNet}{{6.13}{71}{Resumen de los ganadores del concurso ILSVRC hasta 2015 con la aparición de Resnet. Imagen extraída de \cite {StanfordCourse}}{figure.6.13}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.3}Autoencoders}{71}{section.6.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.1}Introducción}{71}{subsection.6.3.1}\protected@file@percent }
\@writefile{brf}{\backcite{autoencoders2017}{{71}{6.3.1}{subsection.6.3.1}}}
\citation{autoencoders2017}
\citation{autoencoders2017}
\BKM@entry{id=53,dest={73756273656374696F6E2E362E332E32},srcline={568}}{45766F6C7563695C3336336E206465206C6F73204175746F656E636F64657273}
\citation{GAN}
\citation{autoencoders2017}
\citation{autoencoders2017}
\citation{autoencoders2017}
\citation{autoencoders2017}
\citation{AAE}
\citation{AAE}
\@writefile{lof}{\contentsline {figure}{\numberline {6.14}{\ignorespaces Esquema de un Autoencoder básico. Imagen extraída de \cite  {autoencoders2017}.}}{72}{figure.6.14}\protected@file@percent }
\@writefile{brf}{\backcite{autoencoders2017}{{72}{6.14}{figure.6.14}}}
\newlabel{fig:Autoencoder}{{6.14}{72}{Esquema de un Autoencoder básico. Imagen extraída de \cite {autoencoders2017}}{figure.6.14}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3.2}Evolución de los Autoencoders}{72}{subsection.6.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2.1}Generative Adversarial Networks (GANs)}{72}{subsubsection.6.3.2.1}\protected@file@percent }
\@writefile{brf}{\backcite{GAN}{{72}{6.3.2.1}{subsubsection.6.3.2.1}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2.2}Variational Autoencoder (VAE)}{72}{subsubsection.6.3.2.2}\protected@file@percent }
\citation{VAE}
\citation{VAE}
\@writefile{lof}{\contentsline {figure}{\numberline {6.15}{\ignorespaces Ejemplo de una Generative Network que pretende aprender la distribución de probabilidad de un conjunto de imágenes de perros. Imagen extraída de \cite  {autoencoders2017}.}}{73}{figure.6.15}\protected@file@percent }
\@writefile{brf}{\backcite{autoencoders2017}{{73}{6.15}{figure.6.15}}}
\newlabel{fig:Generative Network}{{6.15}{73}{Ejemplo de una Generative Network que pretende aprender la distribución de probabilidad de un conjunto de imágenes de perros. Imagen extraída de \cite {autoencoders2017}}{figure.6.15}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.16}{\ignorespaces Resumen del proceso de entrenamiento de una GAN. Imagen extraída de \cite  {autoencoders2017}.}}{73}{figure.6.16}\protected@file@percent }
\@writefile{brf}{\backcite{autoencoders2017}{{73}{6.16}{figure.6.16}}}
\citation{VAE}
\citation{VAE}
\@writefile{lof}{\contentsline {figure}{\numberline {6.17}{\ignorespaces Ejemplo de la arquitectura de una GAN para generar imágenes de dígitos manuscritos. Imagen extraída de \cite  {AAE}}}{74}{figure.6.17}\protected@file@percent }
\@writefile{brf}{\backcite{AAE}{{74}{6.17}{figure.6.17}}}
\newlabel{fig:GAN}{{6.17}{74}{Ejemplo de la arquitectura de una GAN para generar imágenes de dígitos manuscritos. Imagen extraída de \cite {AAE}}{figure.6.17}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6.18}{\ignorespaces Diferencia en el tratamiento de los datos por parte del encoder en una VAE y un Autoencoder clásico. Imagen extraída de \cite  {VAE}.}}{74}{figure.6.18}\protected@file@percent }
\@writefile{brf}{\backcite{VAE}{{74}{6.18}{figure.6.18}}}
\newlabel{fig:VAE_1}{{6.18}{74}{Diferencia en el tratamiento de los datos por parte del encoder en una VAE y un Autoencoder clásico. Imagen extraída de \cite {VAE}}{figure.6.18}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.3.2.3}Adversarial Autoencoder(AAE)}{74}{subsubsection.6.3.2.3}\protected@file@percent }
\citation{AAE}
\citation{AAE}
\@writefile{lof}{\contentsline {figure}{\numberline {6.19}{\ignorespaces Diferencia en la función de pérdida de un Autoencoder clásico (imagen superior) y una VAE (imagen inferior). Destacamos el término KL regularizante que pretende que las distribuciones de los datos sigan una normal estándar. Imagen extraída de \cite  {VAE}.}}{75}{figure.6.19}\protected@file@percent }
\@writefile{brf}{\backcite{VAE}{{75}{6.19}{figure.6.19}}}
\newlabel{fig:VAE_2}{{6.19}{75}{Diferencia en la función de pérdida de un Autoencoder clásico (imagen superior) y una VAE (imagen inferior). Destacamos el término KL regularizante que pretende que las distribuciones de los datos sigan una normal estándar. Imagen extraída de \cite {VAE}}{figure.6.19}{}}
\BKM@entry{id=54,dest={73656374696F6E2E362E34},srcline={656}}{545C333531636E6963617320656D706C6561646173}
\BKM@entry{id=55,dest={73756273656374696F6E2E362E342E31},srcline={659}}{4665772D73686F74204C6561726E696E6720792044617461204175676D656E746174696F6E}
\@writefile{lof}{\contentsline {figure}{\numberline {6.20}{\ignorespaces Esquema de la arquitectura de un AAE. El Encoder sería la red a la que entra la imagen $x$, el vector $z$ sería el vector latente, que sirve de entrada al Discriminador $D_{gauss}$ y finalmente el vector $z$ es la entrada del Decoder que reconstruye la imagen. Imagen extraída de \cite  {AAE}.}}{76}{figure.6.20}\protected@file@percent }
\@writefile{brf}{\backcite{AAE}{{76}{6.20}{figure.6.20}}}
\newlabel{fig:AAE}{{6.20}{76}{Esquema de la arquitectura de un AAE. El Encoder sería la red a la que entra la imagen $x$, el vector $z$ sería el vector latente, que sirve de entrada al Discriminador $D_{gauss}$ y finalmente el vector $z$ es la entrada del Decoder que reconstruye la imagen. Imagen extraída de \cite {AAE}}{figure.6.20}{}}
\@writefile{toc}{\contentsline {section}{\numberline {6.4}Técnicas empleadas}{76}{section.6.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {6.4.1}Few-shot Learning y Data Augmentation}{76}{subsection.6.4.1}\protected@file@percent }
\newlabel{sub:data_augmentation}{{6.4.1}{76}{Few-shot Learning y Data Augmentation}{subsection.6.4.1}{}}
\BKM@entry{id=56,dest={636861707465722E37},srcline={2}}{45737461646F2064656C2041727465}
\BKM@entry{id=57,dest={73656374696F6E2E372E31},srcline={6}}{4C6F63616C697A6163695C3336336E206465206C616E646D61726B7320636566616C6F6D5C333531747269636F7320656E20696D5C33343167656E6573}
\BKM@entry{id=58,dest={73756273656374696F6E2E372E312E31},srcline={39}}{45766F6C7563695C3336336E20656E206C61206964656E74696669636163695C3336336E20666F72656E7365206465206C616E646D61726B7320636566616C6F6D5C333531747269636F73}
\citation{asi2014automatic}
\@writefile{toc}{\contentsline {chapter}{\numberline {7}Estado del Arte}{77}{chapter.7}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {7.1}Localización de landmarks cefalométricos en imágenes}{77}{section.7.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1.1}Evolución en la identificación forense de landmarks cefalométricos}{77}{subsection.7.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.1}{\ignorespaces Arriba podemos ver la gráfica de publicaciones por año obtenida con la primera \textit  {keyword} el $26$ de Octubre de $2022$, en total se encontraron $1,251$ artículos. Destaca el notable incremento de papers a partir de 2012, año en que aparece la red AlexNet y comienza a ganar popularidad el Deep Learning en el tratamiento de imágenes. Abajo tenemos la gráfica de publicaciones por año obtenida con la segunda \textit  {keyword} el $26$ de Octubre de $2022$, en total se obtuvieron $13$ artículos. Como vemos, existe una gran diferencia entre ambas a nivel de artículos publicados por año.}}{78}{figure.7.1}\protected@file@percent }
\newlabel{fig:SCOPUS}{{7.1}{78}{Arriba podemos ver la gráfica de publicaciones por año obtenida con la primera \textit {keyword} el $26$ de Octubre de $2022$, en total se encontraron $1,251$ artículos. Destaca el notable incremento de papers a partir de 2012, año en que aparece la red AlexNet y comienza a ganar popularidad el Deep Learning en el tratamiento de imágenes. Abajo tenemos la gráfica de publicaciones por año obtenida con la segunda \textit {keyword} el $26$ de Octubre de $2022$, en total se obtuvieron $13$ artículos. Como vemos, existe una gran diferencia entre ambas a nivel de artículos publicados por año}{figure.7.1}{}}
\citation{galvanek2015automated}
\citation{galvanek2015automated}
\citation{galvanek2015automated}
\citation{porto2019automatic}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1.1}Automatic craniofacial anthropometry landmarks detection and measurements for the orbital region}{79}{subsubsection.7.1.1.1}\protected@file@percent }
\@writefile{brf}{\backcite{asi2014automatic}{{79}{7.1.1.1}{subsubsection.7.1.1.1}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1.2}Automated facial landmark detection, comparison and visualization}{79}{subsubsection.7.1.1.2}\protected@file@percent }
\@writefile{brf}{\backcite{galvanek2015automated}{{79}{7.1.1.2}{subsubsection.7.1.1.2}}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1.3}Automatic cephalometric landmarks detection on frontal faces: An approach based on supervised learning techniques}{79}{subsubsection.7.1.1.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {7.2}{\ignorespaces Cara alineada con el plano horizontal de Frankfort. Imagen extraida de \url  {https://www.slideshare.net/NiharikaSupriya/cephalometrics-landmarkslines-and-planes-93890774 }}}{80}{figure.7.2}\protected@file@percent }
\newlabel{fig:Frankfort}{{7.2}{80}{Cara alineada con el plano horizontal de Frankfort. Imagen extraida de \url {https://www.slideshare.net/NiharikaSupriya/cephalometrics-landmarkslines-and-planes-93890774 }}{figure.7.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7.3}{\ignorespaces Comparativa entre los landmarks marcados por el algoritmo (izquierda) y los marcados por un experto (derecha). Imagen extraida de \cite  {galvanek2015automated}.}}{80}{figure.7.3}\protected@file@percent }
\@writefile{brf}{\backcite{galvanek2015automated}{{80}{7.3}{figure.7.3}}}
\newlabel{fig:landmarks_comparativa}{{7.3}{80}{Comparativa entre los landmarks marcados por el algoritmo (izquierda) y los marcados por un experto (derecha). Imagen extraida de \cite {galvanek2015automated}}{figure.7.3}{}}
\@writefile{brf}{\backcite{porto2019automatic}{{80}{7.1.1.3}{subsubsection.7.1.1.3}}}
\citation{ImprovedfasterRCNN}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {7.1.1.4}The Improved Faster R-CNN for Detecting Small Facial Landmarks on Vietnamese Human Face Based on Clinical Diagnosis}{81}{subsubsection.7.1.1.4}\protected@file@percent }
\@writefile{brf}{\backcite{ImprovedfasterRCNN}{{81}{7.1.1.4}{subsubsection.7.1.1.4}}}
\BKM@entry{id=59,dest={636861707465722E38},srcline={1}}{496D706C656D656E746163695C3336336E}
\BKM@entry{id=60,dest={73656374696F6E2E382E31},srcline={3}}{446973655C3336316F2064656C20536F6677617265}
\@writefile{toc}{\contentsline {chapter}{\numberline {8}Implementación}{83}{chapter.8}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {8.1}Diseño del Sofware}{83}{section.8.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.1}{\ignorespaces Diagrama de paquetes del proyecto generado por \textit  {pyreverse}, herramienta incluida en el paquete Pylint}}{83}{figure.8.1}\protected@file@percent }
\newlabel{fig:Diagrama_paquetes}{{8.1}{83}{Diagrama de paquetes del proyecto generado por \textit {pyreverse}, herramienta incluida en el paquete Pylint}{figure.8.1}{}}
\BKM@entry{id=61,dest={73656374696F6E2E382E32},srcline={69}}{456E746F726E6F20646520656A65637563695C3336336E}
\@writefile{lot}{\contentsline {table}{\numberline {8.1}{\ignorespaces Argumentos con los que se ha experimentado en la ejecución del fichero train-aae-landmarks.py}}{84}{table.8.1}\protected@file@percent }
\newlabel{table:Params}{{8.1}{84}{Argumentos con los que se ha experimentado en la ejecución del fichero train-aae-landmarks.py}{table.8.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {8.2}Entorno de ejecución}{84}{section.8.2}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {8.2}{\ignorespaces Diagrama de clases con las principales clases del proyecto.}}{85}{figure.8.2}\protected@file@percent }
\newlabel{fig:Diagrama_clases}{{8.2}{85}{Diagrama de clases con las principales clases del proyecto}{figure.8.2}{}}
\BKM@entry{id=62,dest={636861707465722E39},srcline={1}}{536F6C7563695C3336336E2070726F7075657374612079206578706572696D656E746F73207265616C697A61646F73}
\citation{300W}
\citation{300W}
\citation{300W}
\citation{AFLW}
\citation{AFLW}
\citation{AFLW}
\@writefile{toc}{\contentsline {chapter}{\numberline {9}Solución propuesta y experimentos realizados}{87}{chapter.9}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{brf}{\backcite{300W}{{87}{9}{chapter.9}}}
\@writefile{brf}{\backcite{AFLW}{{87}{9}{figure.9.1}}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.2}{\ignorespaces Conjunto de landmarks anotados sobre un modelo $3$D que emplea el dataset AFLW. Imagen extraida de \cite  {AFLW}.}}{87}{figure.9.2}\protected@file@percent }
\@writefile{brf}{\backcite{AFLW}{{87}{9.2}{figure.9.2}}}
\newlabel{fig:AFLW}{{9.2}{87}{Conjunto de landmarks anotados sobre un modelo $3$D que emplea el dataset AFLW. Imagen extraida de \cite {AFLW}}{figure.9.2}{}}
\BKM@entry{id=63,dest={73656374696F6E2E392E31},srcline={29}}{4672616D65776F726B20656D706C6561646F3A2033466162526563}
\citation{browatzki20203fabrec}
\@writefile{lof}{\contentsline {figure}{\numberline {9.1}{\ignorespaces Conjunto de landmarks anotados en el dataset 300W, en la imagen \textit  {a} contando el contorno del rostro son un total de 68 landmarks, en la imagen \textit  {b} son 51 en total. Imagen extraida de \cite  {300W}.}}{88}{figure.9.1}\protected@file@percent }
\@writefile{brf}{\backcite{300W}{{88}{9.1}{figure.9.1}}}
\newlabel{fig:300W}{{9.1}{88}{Conjunto de landmarks anotados en el dataset 300W, en la imagen \textit {a} contando el contorno del rostro son un total de 68 landmarks, en la imagen \textit {b} son 51 en total. Imagen extraida de \cite {300W}}{figure.9.1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.1}Framework empleado: 3FabRec}{88}{section.9.1}\protected@file@percent }
\@writefile{brf}{\backcite{browatzki20203fabrec}{{88}{9.1}{section.9.1}}}
\citation{browatzki20203fabrec}
\citation{browatzki20203fabrec}
\BKM@entry{id=64,dest={73756273656374696F6E2E392E312E31},srcline={49}}{41727175697465637475726120416476657273617269616C204175746F656E636F646572}
\@writefile{lof}{\contentsline {figure}{\numberline {9.3}{\ignorespaces Imagen resumen del framework 3FabRec. En ella podemos ver la estructura del \textit  {Adversarial Autoencoder}, dividido en un Encoder (región bajo la \textit  {E}) y un Generator (región bajo la \textit  {G}). En rojo podemos ver las ITLs que se intercalan entre cada capa del Generador y dan como resultado un conjunto de mapas de calor. Imagen extraída de \cite  {browatzki20203fabrec}.}}{89}{figure.9.3}\protected@file@percent }
\@writefile{brf}{\backcite{browatzki20203fabrec}{{89}{9.3}{figure.9.3}}}
\newlabel{fig:3FabRec Resumen}{{9.3}{89}{Imagen resumen del framework 3FabRec. En ella podemos ver la estructura del \textit {Adversarial Autoencoder}, dividido en un Encoder (región bajo la \textit {E}) y un Generator (región bajo la \textit {G}). En rojo podemos ver las ITLs que se intercalan entre cada capa del Generador y dan como resultado un conjunto de mapas de calor. Imagen extraída de \cite {browatzki20203fabrec}}{figure.9.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.1}Arquitectura Adversarial Autoencoder}{89}{subsection.9.1.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.4}{\ignorespaces Bloques básicos que utilza la red ResNet-$18$ en sus capas. Se trata de una sucesión clásica de Convolución 3x3 + Batch Normalization + ReLU que se repite dos veces. En el primer caso los filtros de convolución no reducen las dimensiones del tensor añadiendo un padding de 1. En el segundo caso se reduce la dimensión del tensor a la mitad tras la primera convolución y se manteiene la dimensionalidad en la segunda. En el primer caso, la suma residual puede realizarse con el tensor x sin problema, en el segundo caso el tensor debe reducirse para que casen las dimensiones.}}{90}{figure.9.4}\protected@file@percent }
\newlabel{fig:bloque_encoder}{{9.4}{90}{Bloques básicos que utilza la red ResNet-$18$ en sus capas. Se trata de una sucesión clásica de Convolución 3x3 + Batch Normalization + ReLU que se repite dos veces. En el primer caso los filtros de convolución no reducen las dimensiones del tensor añadiendo un padding de 1. En el segundo caso se reduce la dimensión del tensor a la mitad tras la primera convolución y se manteiene la dimensionalidad en la segunda. En el primer caso, la suma residual puede realizarse con el tensor x sin problema, en el segundo caso el tensor debe reducirse para que casen las dimensiones}{figure.9.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.5}{\ignorespaces Ejemplo de paso de una imagen a través del Encoder. Cabe destacar que a partir de la Layer 1, todos los bloques tienen downsample.}}{91}{figure.9.5}\protected@file@percent }
\newlabel{fig:Paso_encoder}{{9.5}{91}{Ejemplo de paso de una imagen a través del Encoder. Cabe destacar que a partir de la Layer 1, todos los bloques tienen downsample}{figure.9.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.6}{\ignorespaces En primer lugar se aplica una convolución transpuesta que duplica las dimensiones del tensor de entrada y tras esto se sigue la misma estructura que en el bloque básico de la ResNet-$50$, la segunda convolución $3\times 3$ mantiene las dimensiones. Como consecuencia, para sumar el tensor de entrada con la salida del bloque se aumentan las dimensiones de este.}}{92}{figure.9.6}\protected@file@percent }
\newlabel{fig:Bloque_Decoder}{{9.6}{92}{En primer lugar se aplica una convolución transpuesta que duplica las dimensiones del tensor de entrada y tras esto se sigue la misma estructura que en el bloque básico de la ResNet-$50$, la segunda convolución $3\times 3$ mantiene las dimensiones. Como consecuencia, para sumar el tensor de entrada con la salida del bloque se aumentan las dimensiones de este}{figure.9.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.7}{\ignorespaces Ejemplo del paso de un vector de $99$ dimensiones por el generador hasta reconstruirse la imagen de dimensiones $256 \times 256 \times 3$. La parte correspondiente al aprendizaje supervisado es la de los cuadrados azules, los cuadrados rojos corresponden a las \textit  {ITLS} de la parte supervisada que se intercalan entre cada dos capas y dan como resultado los mapas de calor de los landmarks predichos.}}{92}{figure.9.7}\protected@file@percent }
\newlabel{fig:Paso_Generator}{{9.7}{92}{Ejemplo del paso de un vector de $99$ dimensiones por el generador hasta reconstruirse la imagen de dimensiones $256 \times 256 \times 3$. La parte correspondiente al aprendizaje supervisado es la de los cuadrados azules, los cuadrados rojos corresponden a las \textit {ITLS} de la parte supervisada que se intercalan entre cada dos capas y dan como resultado los mapas de calor de los landmarks predichos}{figure.9.7}{}}
\BKM@entry{id=65,dest={73756273656374696F6E2E392E312E32},srcline={107}}{46756E63695C3336336E20646520705C3335317264696461}
\@writefile{lof}{\contentsline {figure}{\numberline {9.8}{\ignorespaces En la imagen superior vemos el discriminante que se emplea para los vectores producidos por el Encoder y en la imagen inferior vemos el discriminante que se emplea para las imágenes generadas por el Generador. En ambos casos se da como salida un valor entre $0$ y $1$ que hace referencia a la probabilidad de pertenecer a la distribución deseada en el primer caso o a seguir la distribución de los píxeles de las imágenes en el segundo caso.}}{93}{figure.9.8}\protected@file@percent }
\newlabel{fig:DGaussian}{{9.8}{93}{En la imagen superior vemos el discriminante que se emplea para los vectores producidos por el Encoder y en la imagen inferior vemos el discriminante que se emplea para las imágenes generadas por el Generador. En ambos casos se da como salida un valor entre $0$ y $1$ que hace referencia a la probabilidad de pertenecer a la distribución deseada en el primer caso o a seguir la distribución de los píxeles de las imágenes en el segundo caso}{figure.9.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.1.1}Interleaved Transfer Layer (ITL)}{93}{subsubsection.9.1.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.2}Función de pérdida}{93}{subsection.9.1.2}\protected@file@percent }
\newlabel{eq::L2}{{9.1.2}{94}{Función de pérdida}{subsection.9.1.2}{}}
\BKM@entry{id=66,dest={73756273656374696F6E2E392E312E33},srcline={171}}{50726F6365736F20646520656E7472656E616D69656E746F206465206C6120726564}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.3}Proceso de entrenamiento de la red}{95}{subsection.9.1.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.3.1}Entrenamiento no-supervisado}{95}{subsubsection.9.1.3.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.1.3.2}Entrenamiento supervisado}{95}{subsubsection.9.1.3.2}\protected@file@percent }
\BKM@entry{id=67,dest={73756273656374696F6E2E392E312E34},srcline={195}}{4261736573206465206461746F732075736164617320706F7220656C206672616D65776F726B}
\BKM@entry{id=68,dest={73656374696F6E2E392E32},srcline={218}}{4D5C333531747269636173}
\BKM@entry{id=69,dest={73756273656374696F6E2E392E322E31},srcline={222}}{4D5C3335317472696361732075736164617320656E20656C20656E7472656E616D69656E746F}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.1.4}Bases de datos usadas por el framework}{96}{subsection.9.1.4}\protected@file@percent }
\@writefile{toc}{\contentsline {section}{\numberline {9.2}Métricas}{96}{section.9.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.1}Métricas usadas en el entrenamiento}{96}{subsection.9.2.1}\protected@file@percent }
\BKM@entry{id=70,dest={73756273656374696F6E2E392E322E32},srcline={238}}{4D5C33353174726963617320656D706C656164617320656E2076616C69646163695C3336336E20792074657374696E67}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.1.1}MSE}{97}{subsubsection.9.2.1.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.2.2}Métricas empleadas en validación y testing}{97}{subsection.9.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2.1}Error de reconstrucción}{97}{subsubsection.9.2.2.1}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2.2}Normalized Mean Error}{97}{subsubsection.9.2.2.2}\protected@file@percent }
\citation{wang2004image}
\BKM@entry{id=71,dest={73656374696F6E2E392E33},srcline={310}}{416E5C3334316C69736973206465206C612062617365206465204461746F73}
\BKM@entry{id=72,dest={73756273656374696F6E2E392E332E31},srcline={313}}{42617365206465206461746F732070726F706F7263696F6E616461}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.2.2.3}SSIM}{98}{subsubsection.9.2.2.3}\protected@file@percent }
\@writefile{brf}{\backcite{wang2004image}{{98}{9.2.2.3}{subsubsection.9.2.2.3}}}
\@writefile{toc}{\contentsline {section}{\numberline {9.3}Análisis de la base de Datos}{98}{section.9.3}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.1}Base de datos proporcionada}{98}{subsection.9.3.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.9}{\ignorespaces Imágenes de ejemplo del dataset proporcionado. Como puede observarse hay gran variedad de tamaños, poses, condiciones de iluminación diferentes que añaden dificultad al problema.}}{99}{figure.9.9}\protected@file@percent }
\newlabel{fig:Imagenes_dataset}{{9.9}{99}{Imágenes de ejemplo del dataset proporcionado. Como puede observarse hay gran variedad de tamaños, poses, condiciones de iluminación diferentes que añaden dificultad al problema}{figure.9.9}{}}
\BKM@entry{id=73,dest={73756273656374696F6E2E392E332E32},srcline={345}}{50726570726F636573616D69656E746F}
\@writefile{lof}{\contentsline {figure}{\numberline {9.10}{\ignorespaces Histograma con la aparición de cada tipo de landmark en las imágenes del dataset.}}{100}{figure.9.10}\protected@file@percent }
\newlabel{fig:Histograma}{{9.10}{100}{Histograma con la aparición de cada tipo de landmark en las imágenes del dataset}{figure.9.10}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.2}Preprocesamiento}{100}{subsection.9.3.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.2.1}Identificación de caras en las imágenes}{100}{subsubsection.9.3.2.1}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.11}{\ignorespaces Imágenes de ejemplo del dataset con los \textit  {bounding boxes} marcados por \textit  {Facenet}. Como podemos observar, aunque son correctos, los \textit  {bounding boxes} marcados recortan excesivamente los límites del rostro, pudiendo incluso eliminar partes en las que hay landmarks marcados. Las imágenes han sido generadas con \textit  {matplotlib}.}}{102}{figure.9.11}\protected@file@percent }
\newlabel{fig:Ejemplo_bb}{{9.11}{102}{Imágenes de ejemplo del dataset con los \textit {bounding boxes} marcados por \textit {Facenet}. Como podemos observar, aunque son correctos, los \textit {bounding boxes} marcados recortan excesivamente los límites del rostro, pudiendo incluso eliminar partes en las que hay landmarks marcados. Las imágenes han sido generadas con \textit {matplotlib}}{figure.9.11}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.2.2}Creación del fichero annotations en el dataset}{102}{subsubsection.9.3.2.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsubsection}{\numberline {9.3.2.3}Reajuste de los bounding boxes}{103}{subsubsection.9.3.2.3}\protected@file@percent }
\@writefile{lof}{\contentsline {figure}{\numberline {9.12}{\ignorespaces Proceso seguido para la transformación.}}{103}{figure.9.12}\protected@file@percent }
\newlabel{fig:Transformacion_BB}{{9.12}{103}{Proceso seguido para la transformación}{figure.9.12}{}}
\BKM@entry{id=74,dest={73756273656374696F6E2E392E332E33},srcline={425}}{53657061726163695C3336336E20656E20636F6E6A756E746F7320646520656E7472656E616D69656E746F20792076616C69646163695C3336336E}
\@writefile{lof}{\contentsline {figure}{\numberline {9.13}{\ignorespaces Recorte de las caras tras el reajuste del \textit  {bounding box}.}}{104}{figure.9.13}\protected@file@percent }
\newlabel{fig:Reajuste_bb}{{9.13}{104}{Recorte de las caras tras el reajuste del \textit {bounding box}}{figure.9.13}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.3.3}Separación en conjuntos de entrenamiento y validación}{104}{subsection.9.3.3}\protected@file@percent }
\BKM@entry{id=75,dest={73656374696F6E2E392E34},srcline={444}}{4578706572696D656E746163695C3336336E}
\BKM@entry{id=76,dest={73756273656374696F6E2E392E342E31},srcline={445}}{4869705C333633746573697320696E696369616C6573}
\citation{browatzki20203fabrec}
\BKM@entry{id=77,dest={73756273656374696F6E2E392E342E32},srcline={452}}{4D6F64656C6F2042617365}
\@writefile{toc}{\contentsline {section}{\numberline {9.4}Experimentación}{105}{section.9.4}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.1}Hipótesis iniciales}{105}{subsection.9.4.1}\protected@file@percent }
\@writefile{brf}{\backcite{browatzki20203fabrec}{{105}{9.4.1}{subsection.9.4.1}}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.2}Modelo Base}{105}{subsection.9.4.2}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.1}{\ignorespaces Media del error NME obtenido por landmark entre todas las particiones de cross-validation.}}{106}{table.9.1}\protected@file@percent }
\newlabel{table:ModelBase_landmarkresume}{{9.1}{106}{Media del error NME obtenido por landmark entre todas las particiones de cross-validation}{table.9.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.14}{\ignorespaces Curvas de aprendizaje en cada partición del modelo base.}}{107}{figure.9.14}\protected@file@percent }
\newlabel{fig:Curvas_modelbase}{{9.14}{107}{Curvas de aprendizaje en cada partición del modelo base}{figure.9.14}{}}
\BKM@entry{id=78,dest={73756273656374696F6E2E392E342E33},srcline={535}}{4D6F64656C6F20636F6E207265656E7472656E616D69656E746F2064656C20656E636F646572}
\@writefile{lof}{\contentsline {figure}{\numberline {9.15}{\ignorespaces Imágenes pertenecientes a distintos conjuntos de validación para el \textbf  {modelo base}. Las imágenes de la fila superior son las imágenes reales, y las de la fila inferior las reconstruidas por la red. El marcado se realiza sobre las reconstruidas y luego se lleva a las superiores. Podemos apreciar en verde los landmarks reales y en azul los predichos. El valor que aparece en la esquina inferior derecha es el NME global de la imagen (la media de los NMEs de cada landmark) y en la esquina inferior izquierda aparece el error de reconstrucción y encima el SSIM.}}{108}{figure.9.15}\protected@file@percent }
\newlabel{fig:Ejemplo_ModelBase}{{9.15}{108}{Imágenes pertenecientes a distintos conjuntos de validación para el \textbf {modelo base}. Las imágenes de la fila superior son las imágenes reales, y las de la fila inferior las reconstruidas por la red. El marcado se realiza sobre las reconstruidas y luego se lleva a las superiores. Podemos apreciar en verde los landmarks reales y en azul los predichos. El valor que aparece en la esquina inferior derecha es el NME global de la imagen (la media de los NMEs de cada landmark) y en la esquina inferior izquierda aparece el error de reconstrucción y encima el SSIM}{figure.9.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.3}Modelo con reentrenamiento del encoder}{108}{subsection.9.4.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.2}{\ignorespaces Tabla comparativa entre los dos modelos explorados por ahora. Medimos el NME medio a nivel de landmark. En verde se resalta el mejor valor de marcado para cada landmark, en un verde más intenso las mejoras más considerables.}}{109}{table.9.2}\protected@file@percent }
\newlabel{table:Encode_landmarkresume}{{9.2}{109}{Tabla comparativa entre los dos modelos explorados por ahora. Medimos el NME medio a nivel de landmark. En verde se resalta el mejor valor de marcado para cada landmark, en un verde más intenso las mejoras más considerables}{table.9.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.16}{\ignorespaces Curvas de aprendizaje en cada partición del modelo de finetuning del encoder.}}{110}{figure.9.16}\protected@file@percent }
\newlabel{fig:curvas_encoder}{{9.16}{110}{Curvas de aprendizaje en cada partición del modelo de finetuning del encoder}{figure.9.16}{}}
\BKM@entry{id=79,dest={73756273656374696F6E2E392E342E34},srcline={610}}{4D6F64656C6F20636F6E207265656E7472656E616D69656E746F2064656C206465636F646572}
\@writefile{lof}{\contentsline {figure}{\numberline {9.17}{\ignorespaces Imágenes pertenecientes a distintos conjuntos de validación para el \textbf  {modelo de ajuste fino del encoder}.}}{111}{figure.9.17}\protected@file@percent }
\newlabel{fig:Ejemplo_encoder}{{9.17}{111}{Imágenes pertenecientes a distintos conjuntos de validación para el \textbf {modelo de ajuste fino del encoder}}{figure.9.17}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.4}Modelo con reentrenamiento del decoder}{111}{subsection.9.4.4}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.3}{\ignorespaces Tabla comparativa entre los tres modelos probados. En este caso no se aprecia ninguna mejora considerable con respecto a las introducidas por el modelo de ajuste fino del encoder}}{112}{table.9.3}\protected@file@percent }
\newlabel{table:Decoder_landmarksresume}{{9.3}{112}{Tabla comparativa entre los tres modelos probados. En este caso no se aprecia ninguna mejora considerable con respecto a las introducidas por el modelo de ajuste fino del encoder}{table.9.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.18}{\ignorespaces Curvas de aprendizaje en cada partición del modelo de finetuning del encoder.}}{112}{figure.9.18}\protected@file@percent }
\newlabel{fig:curvas_decoder}{{9.18}{112}{Curvas de aprendizaje en cada partición del modelo de finetuning del encoder}{figure.9.18}{}}
\BKM@entry{id=80,dest={73756273656374696F6E2E392E342E35},srcline={682}}{4D6F64656C6F20636F6E2044617461204175676D656E746174696F6E}
\@writefile{lof}{\contentsline {figure}{\numberline {9.19}{\ignorespaces Imágenes pertenecientes a distintos conjuntos de validación para el \textbf  {modelo de ajuste fino del decoder}.}}{113}{figure.9.19}\protected@file@percent }
\newlabel{fig:Ejemplo_decoder}{{9.19}{113}{Imágenes pertenecientes a distintos conjuntos de validación para el \textbf {modelo de ajuste fino del decoder}}{figure.9.19}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.5}Modelo con Data Augmentation}{113}{subsection.9.4.5}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.4}{\ignorespaces Tabla comparativa entre todos los modelos probados.}}{114}{table.9.4}\protected@file@percent }
\newlabel{table:Daugmentation_landmarksresume}{{9.4}{114}{Tabla comparativa entre todos los modelos probados}{table.9.4}{}}
\BKM@entry{id=81,dest={73756273656374696F6E2E392E342E36},srcline={760}}{456C656363695C3336336E206465206D6F64656C6F2079206F6274656E63695C3336336E20646520726573756C7461646F73}
\@writefile{lof}{\contentsline {figure}{\numberline {9.20}{\ignorespaces Curvas de aprendizaje en cada partición del modelo de data augmentation.}}{115}{figure.9.20}\protected@file@percent }
\newlabel{fig:curvas_daugmentation}{{9.20}{115}{Curvas de aprendizaje en cada partición del modelo de data augmentation}{figure.9.20}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.21}{\ignorespaces Imágenes pertenecientes a distintos conjuntos de validación para el \textbf  {modelo data augmentation}.}}{115}{figure.9.21}\protected@file@percent }
\newlabel{fig:Ejemplo_daug}{{9.21}{115}{Imágenes pertenecientes a distintos conjuntos de validación para el \textbf {modelo data augmentation}}{figure.9.21}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.4.6}Elección de modelo y obtención de resultados}{115}{subsection.9.4.6}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.5}{\ignorespaces Tabla comparativa entre los resultados del modelo de data augmentation en el conjunto de validación y test}}{116}{table.9.5}\protected@file@percent }
\newlabel{table:FinalModel_landmarks}{{9.5}{116}{Tabla comparativa entre los resultados del modelo de data augmentation en el conjunto de validación y test}{table.9.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {9.22}{\ignorespaces Curvas de aprendizaje durante el entrenamiento del modelo de data augmentation validado en el conjunto de test.}}{117}{figure.9.22}\protected@file@percent }
\newlabel{fig:curvas_FinalModel}{{9.22}{117}{Curvas de aprendizaje durante el entrenamiento del modelo de data augmentation validado en el conjunto de test}{figure.9.22}{}}
\BKM@entry{id=82,dest={73656374696F6E2E392E35},srcline={836}}{436F6D706172617469766120656E74726520334661625265632079204879706572466163652D5265734E6574313031}
\BKM@entry{id=83,dest={73756273656374696F6E2E392E352E31},srcline={839}}{50726570726F636573616D69656E746F20792062617365206465206461746F7320656D706C65616461}
\BKM@entry{id=84,dest={73756273656374696F6E2E392E352E32},srcline={846}}{4D5C33353174726963617320656D706C6561646173}
\@writefile{lof}{\contentsline {figure}{\numberline {9.23}{\ignorespaces Rendimiento del modelo final elegido con data augmentation en imágenes del conjunto de test.}}{118}{figure.9.23}\protected@file@percent }
\newlabel{fig:Ejemplo_finalmodel}{{9.23}{118}{Rendimiento del modelo final elegido con data augmentation en imágenes del conjunto de test}{figure.9.23}{}}
\@writefile{toc}{\contentsline {section}{\numberline {9.5}Comparativa entre 3FabRec y HyperFace-ResNet101}{118}{section.9.5}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.1}Preprocesamiento y base de datos empleada}{118}{subsection.9.5.1}\protected@file@percent }
\BKM@entry{id=85,dest={73756273656374696F6E2E392E352E33},srcline={859}}{436F6D7061726163695C3336336E20646520726573756C7461646F73}
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.2}Métricas empleadas}{119}{subsection.9.5.2}\protected@file@percent }
\@writefile{toc}{\contentsline {subsection}{\numberline {9.5.3}Comparación de resultados}{119}{subsection.9.5.3}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {9.6}{\ignorespaces Tabla comparativa a nivel global entre los dos modelos. Como podemos observar, el modelo basado en \textbf  {HyperFace-Resnet101} obtiene mejores resultados en global en todos los campos.}}{119}{table.9.6}\protected@file@percent }
\newlabel{table:comparativa-global}{{9.6}{119}{Tabla comparativa a nivel global entre los dos modelos. Como podemos observar, el modelo basado en \textbf {HyperFace-Resnet101} obtiene mejores resultados en global en todos los campos}{table.9.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {9.7}{\ignorespaces Tabla comparativa a nivel de landmarks entre el modelo final basado en 3FabRec y el de HyperFace-REsNet101.}}{120}{table.9.7}\protected@file@percent }
\newlabel{table:comparativa-Landmarks}{{9.7}{120}{Tabla comparativa a nivel de landmarks entre el modelo final basado en 3FabRec y el de HyperFace-REsNet101}{table.9.7}{}}
\BKM@entry{id=86,dest={636861707465722E3130},srcline={1}}{436F6E636C7573696F6E657320792054726162616A6F732046757475726F73}
\BKM@entry{id=87,dest={73656374696F6E2E31302E31},srcline={9}}{4F626A657469766F73205361746973666563686F73}
\@writefile{toc}{\contentsline {chapter}{\numberline {10}Conclusiones y Trabajos Futuros}{121}{chapter.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\@writefile{toc}{\contentsline {section}{\numberline {10.1}Objetivos Satisfechos}{121}{section.10.1}\protected@file@percent }
\BKM@entry{id=88,dest={73656374696F6E2E31302E32},srcline={21}}{54726162616A6F732046757475726F73207920636F6D656E746172696F73}
\@writefile{toc}{\contentsline {section}{\numberline {10.2}Trabajos Futuros y comentarios}{122}{section.10.2}\protected@file@percent }
\BKM@entry{id=89,dest={617070656E6469782E2D31},srcline={255}}{41705C3335316E6469636573}
\BKM@entry{id=90,dest={617070656E6469782E416C706831},srcline={4}}{41705C3335316E646963652041}
\BKM@entry{id=91,dest={73656374696F6E2E416C7068312E31},srcline={6}}{526573756C7461646F7320706F7220696D6167656E20647572616E746520656C20656E7472656E616D69656E746F2064656C206D6F64656C6F2062617365}
\@writefile{toc}{\contentsline {chapter}{\numberline {A}Apéndice A}{125}{appendix.Alph1}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ap:apendiceA}{{A}{125}{Apéndice A}{appendix.Alph1}{}}
\@writefile{toc}{\contentsline {section}{\numberline {A.1}Resultados por imagen durante el entrenamiento del modelo base}{125}{section.Alph1.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {A.1}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la primera partición de cross validation en la última validación.}}{125}{table.Alph1.1}\protected@file@percent }
\newlabel{table:ModelBase_Partition1}{{A.1}{125}{Tabla con los resultados por imagen obtenidos en validación para la primera partición de cross validation en la última validación}{table.Alph1.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.2}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación.}}{126}{table.Alph1.2}\protected@file@percent }
\newlabel{table::ModelBase_Partition2}{{A.2}{126}{Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación}{table.Alph1.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.3}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la tercera partición de cross validation en la última validación.}}{127}{table.Alph1.3}\protected@file@percent }
\newlabel{table::ModelBase_Partition3}{{A.3}{127}{Tabla con los resultados por imagen obtenidos en validación para la tercera partición de cross validation en la última validación}{table.Alph1.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.4}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación.}}{128}{table.Alph1.4}\protected@file@percent }
\newlabel{table::ModelBase_Partition4}{{A.4}{128}{Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación}{table.Alph1.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {A.5}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la quinta partición de cross validation en la última validación.}}{129}{table.Alph1.5}\protected@file@percent }
\newlabel{table::ModelBase_Partition5}{{A.5}{129}{Tabla con los resultados por imagen obtenidos en validación para la quinta partición de cross validation en la última validación}{table.Alph1.5}{}}
\BKM@entry{id=92,dest={617070656E6469782E416C706832},srcline={4}}{41705C3335316E646963652042}
\BKM@entry{id=93,dest={73656374696F6E2E416C7068322E31},srcline={6}}{526573756C7461646F7320706F7220696D6167656E20647572616E746520656C20656E7472656E616D69656E746F2064656C206D6F64656C6F20646520656E7472656E616D69656E746F2064656C20656E636F646572}
\@writefile{toc}{\contentsline {chapter}{\numberline {B}Apéndice B}{131}{appendix.Alph2}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ap:apendiceB}{{B}{131}{Apéndice B}{appendix.Alph2}{}}
\@writefile{toc}{\contentsline {section}{\numberline {B.1}Resultados por imagen durante el entrenamiento del modelo de entrenamiento del encoder}{131}{section.Alph2.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {B.1}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la primera partición de cross validation en la última validación.}}{131}{table.Alph2.1}\protected@file@percent }
\newlabel{table:Encoder_images_1}{{B.1}{131}{Tabla con los resultados por imagen obtenidos en validación para la primera partición de cross validation en la última validación}{table.Alph2.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {B.2}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación.}}{132}{table.Alph2.2}\protected@file@percent }
\newlabel{table:Encode_images_2}{{B.2}{132}{Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación}{table.Alph2.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {B.3}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la tercera partición de cross validation en la última validación.}}{133}{table.Alph2.3}\protected@file@percent }
\newlabel{table:Encode_images_3}{{B.3}{133}{Tabla con los resultados por imagen obtenidos en validación para la tercera partición de cross validation en la última validación}{table.Alph2.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {B.4}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la cuarta partición de cross validation en la última validación.}}{134}{table.Alph2.4}\protected@file@percent }
\newlabel{table:Encode_images_4}{{B.4}{134}{Tabla con los resultados por imagen obtenidos en validación para la cuarta partición de cross validation en la última validación}{table.Alph2.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {B.5}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la quinta partición de cross validation en la última validación.}}{135}{table.Alph2.5}\protected@file@percent }
\newlabel{table:Encode_images_5}{{B.5}{135}{Tabla con los resultados por imagen obtenidos en validación para la quinta partición de cross validation en la última validación}{table.Alph2.5}{}}
\BKM@entry{id=94,dest={617070656E6469782E416C706833},srcline={4}}{41705C3335316E646963652043}
\BKM@entry{id=95,dest={73656374696F6E2E416C7068332E31},srcline={6}}{526573756C7461646F7320706F7220696D6167656E20647572616E746520656C20656E7472656E616D69656E746F2064656C206D6F64656C6F20646520656E7472656E616D69656E746F2064656C206465636F646572}
\@writefile{toc}{\contentsline {chapter}{\numberline {C}Apéndice C}{137}{appendix.Alph3}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ap:apendiceC}{{C}{137}{Apéndice C}{appendix.Alph3}{}}
\@writefile{toc}{\contentsline {section}{\numberline {C.1}Resultados por imagen durante el entrenamiento del modelo de entrenamiento del decoder}{137}{section.Alph3.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {C.1}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la primera partición de cross validation en la última validación.}}{137}{table.Alph3.1}\protected@file@percent }
\newlabel{table:Decoder_images_1}{{C.1}{137}{Tabla con los resultados por imagen obtenidos en validación para la primera partición de cross validation en la última validación}{table.Alph3.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {C.2}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación.}}{138}{table.Alph3.2}\protected@file@percent }
\newlabel{table:Decoder_images_2}{{C.2}{138}{Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación}{table.Alph3.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {C.3}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la tercera partición de cross validation en la última validación.}}{139}{table.Alph3.3}\protected@file@percent }
\newlabel{table:Decoder_images_3}{{C.3}{139}{Tabla con los resultados por imagen obtenidos en validación para la tercera partición de cross validation en la última validación}{table.Alph3.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {C.4}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la cuarta partición de cross validation en la última validación.}}{140}{table.Alph3.4}\protected@file@percent }
\newlabel{table:Decoder_images_4}{{C.4}{140}{Tabla con los resultados por imagen obtenidos en validación para la cuarta partición de cross validation en la última validación}{table.Alph3.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {C.5}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la quinta partición de cross validation en la última validación.}}{141}{table.Alph3.5}\protected@file@percent }
\newlabel{table:Decoder_images_5}{{C.5}{141}{Tabla con los resultados por imagen obtenidos en validación para la quinta partición de cross validation en la última validación}{table.Alph3.5}{}}
\BKM@entry{id=96,dest={617070656E6469782E416C706834},srcline={4}}{41705C3335316E646963652044}
\BKM@entry{id=97,dest={73656374696F6E2E416C7068342E31},srcline={6}}{526573756C7461646F7320706F7220696D6167656E20647572616E746520656C20656E7472656E616D69656E746F2064656C206D6F64656C6F20636F6E2064617461206175676D656E746174696F6E}
\@writefile{toc}{\contentsline {chapter}{\numberline {D}Apéndice D}{143}{appendix.Alph4}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\newlabel{ap:apendiceD}{{D}{143}{Apéndice D}{appendix.Alph4}{}}
\@writefile{toc}{\contentsline {section}{\numberline {D.1}Resultados por imagen durante el entrenamiento del modelo con data augmentation}{143}{section.Alph4.1}\protected@file@percent }
\@writefile{lot}{\contentsline {table}{\numberline {D.1}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la primera partición de cross validation en la última validación.}}{143}{table.Alph4.1}\protected@file@percent }
\newlabel{table:Daugmentation_images_1}{{D.1}{143}{Tabla con los resultados por imagen obtenidos en validación para la primera partición de cross validation en la última validación}{table.Alph4.1}{}}
\@writefile{lot}{\contentsline {table}{\numberline {D.2}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación.}}{144}{table.Alph4.2}\protected@file@percent }
\newlabel{table:Daugmentation_images_2}{{D.2}{144}{Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación}{table.Alph4.2}{}}
\@writefile{lot}{\contentsline {table}{\numberline {D.3}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación.}}{145}{table.Alph4.3}\protected@file@percent }
\newlabel{table:Daugmentation_images_3}{{D.3}{145}{Tabla con los resultados por imagen obtenidos en validación para la segunda partición de cross validation en la última validación}{table.Alph4.3}{}}
\@writefile{lot}{\contentsline {table}{\numberline {D.4}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la cuarta partición de cross validation en la última validación.}}{146}{table.Alph4.4}\protected@file@percent }
\newlabel{table:Daugmentation_images_4}{{D.4}{146}{Tabla con los resultados por imagen obtenidos en validación para la cuarta partición de cross validation en la última validación}{table.Alph4.4}{}}
\@writefile{lot}{\contentsline {table}{\numberline {D.5}{\ignorespaces Tabla con los resultados por imagen obtenidos en validación para la quinta partición de cross validation en la última validación.}}{147}{table.Alph4.5}\protected@file@percent }
\newlabel{table:Daugmentation_images_5}{{D.5}{147}{Tabla con los resultados por imagen obtenidos en validación para la quinta partición de cross validation en la última validación}{table.Alph4.5}{}}
\BKM@entry{id=98,dest={424D2D5265666572656E636961732E2D31},srcline={274}}{5265666572656E636961732065205C3335356E6469636573}
\bibstyle{alpha}
\bibdata{library.bib}
\BKM@entry{id=99,dest={636861707465722A2E3130},srcline={2}}{4269626C696F677261665C33353561}
\bibcite{asi2014automatic}{AIA{$^{+}$}14}
\bibcite{bruna2013invariant}{BM13}
\bibcite{browatzki20203fabrec}{BW20}
\bibcite{damas2020handbook}{DCI20}
\bibcite{autoencoders2017}{Der17}
\bibcite{StanfordCourse}{{Fei}17}
\bibcite{Goodfellow-et-al-2016}{GBC16}
\bibcite{galvanek2015automated}{GFCS15}
\bibcite{DigitalImageProcessing}{Gon17}
\bibcite{EvolutionCNN}{Gup20}
\bibcite{Huete2015PastPA}{HIWK15}
\bibcite{ImprovedfasterRCNN}{HNATT22}
\bibcite{he2016deep}{HZRS16}
\bibcite{JBrunaOperatorsCommutingDiff}{J.B12}
\bibcite{krizhevsky2012imagenet}{KSH12}
\@writefile{toc}{\contentsline {chapter}{\nonumberline Bibliograf\'{\i }a}{149}{chapter*.10}\protected@file@percent }
\@writefile{lof}{\addvspace {10\p@ }}
\@writefile{lot}{\addvspace {10\p@ }}
\bibcite{AFLW}{KWRB11}
\bibcite{lecun1998gradient}{LBBH98}
\bibcite{lecun2015deep}{LBH15}
\bibcite{DistinctiveImageFeatures}{Low04}
\bibcite{MallatWavelets}{Mal00}
\bibcite{GroupInvariantScattering}{Mal12}
\bibcite{article}{MMi{$^{+}$}20}
\bibcite{norvig2002modern}{NI02}
\bibcite{HaarBasis}{PJDoM06}
\bibcite{porto2019automatic}{PLF{$^{+}$}19}
\bibcite{SchurLemma}{QV18}
\bibcite{AAE}{Ras20}
\bibcite{GAN}{Roc19a}
\bibcite{VAE}{Roc19b}
\bibcite{rosenfeld1988computer}{Ros88}
\bibcite{szegedy2015going}{SLJ{$^{+}$}15}
\bibcite{sharma2017activation}{SSA17}
\bibcite{300W}{STZP13}
\bibcite{simonyan2014very}{SZ14}
\bibcite{Daisy}{TLF10}
\bibcite{doi:10.1137/S0036141002404838}{TY05}
\bibcite{wang2004image}{WBSS04}
\bibcite{WAVELETS}{Wor}
\global\csname @altsecnumformattrue\endcsname
\global\@namedef{scr@dte@chapter@lastmaxnumwidth}{16.01686pt}
\global\@namedef{scr@dte@section@lastmaxnumwidth}{23.99994pt}
\global\@namedef{scr@dte@part@lastmaxnumwidth}{13.52026pt}
\global\@namedef{scr@dte@subsection@lastmaxnumwidth}{26.49994pt}
