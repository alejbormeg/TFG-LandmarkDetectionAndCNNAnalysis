\babel@toc {spanish}{}
\contentsline {chapter}{\nonumberline Agradecimientos}{\es@scroman {xiii}}{chapter*.7}%
\babel@toc {english}{}
\contentsline {chapter}{\nonumberline Abstract}{\es@scroman {xv}}{chapter*.8}%
\babel@toc {spanish}{}
\contentsline {chapter}{\nonumberline Resumen}{\es@scroman {xvii}}{chapter*.9}%
\contentsline {part}{\numberline {I}Análisis de Redes Convolucionales}{1}{part.1}%
\contentsline {chapter}{\numberline {1}Introducción}{3}{chapter.1}%
\contentsline {chapter}{\numberline {2}Modelización Matemática de una Red Neuronal Convolucional}{7}{chapter.2}%
\contentsline {section}{\numberline {2.1}De Fourier a las ondeletas de Littlewood-Paley}{7}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}El módulo de la Transformada de Fourier}{7}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Alternativa: Las ondeletas}{12}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}La Transformada de Littlewood-Paley}{16}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}Convenios para futuras secciones}{19}{subsection.2.1.4}%
\contentsline {section}{\numberline {2.2}El operador de dispersión sobre un camino ordenado}{20}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Ejemplo para obtener coeficientes invariantes por traslaciones}{21}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}El operador módulo.}{22}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Propiedades de un camino de frecuencias.}{24}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Construcción del operador de dispersión.}{24}{subsection.2.2.4}%
\contentsline {section}{\numberline {2.3}Propagador de dispersión y conservación de la Norma}{26}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Proceso de dispersión del propagador.}{26}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Diferencias y similitudes con una CNN}{27}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Relación con herramientas clásicas de visión por computador}{27}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Operador no expansivo.}{28}{subsection.2.3.4}%
\contentsline {subsection}{\numberline {2.3.5}Conservación de la norma.}{29}{subsection.2.3.5}%
\contentsline {subsection}{\numberline {2.3.6}Conclusiones extraidas del teorema}{33}{subsection.2.3.6}%
\contentsline {chapter}{\numberline {3}Invarianza por Traslaciones}{35}{chapter.3}%
\contentsline {section}{\numberline {3.1}No expansividad del operador de ventana en conjuntos de caminos}{35}{section.3.1}%
\contentsline {section}{\numberline {3.2}Invarianza por traslaciones}{38}{section.3.2}%
\contentsline {chapter}{\numberline {4}Conclusiones y Trabajos futuros}{43}{chapter.4}%
\contentsline {part}{\numberline {II}Localización de landmarks cefalométricos por medio de técnicas de few-shot learning}{45}{part.2}%
\contentsline {chapter}{\numberline {5}Introducción}{47}{chapter.5}%
\contentsline {section}{\numberline {5.1}Descripción del problema}{47}{section.5.1}%
\contentsline {section}{\numberline {5.2}Motivación}{50}{section.5.2}%
\contentsline {section}{\numberline {5.3}Objetivos}{51}{section.5.3}%
\contentsline {section}{\numberline {5.4}Planificación}{52}{section.5.4}%
\contentsline {chapter}{\numberline {6}Fundamentos Teóricos y Métodos}{55}{chapter.6}%
\contentsline {section}{\numberline {6.1}Aprendizaje Automático}{55}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Aprendizaje Supervisado}{56}{subsection.6.1.1}%
\contentsline {subsubsection}{\numberline {6.1.1.1}Regresión}{56}{subsubsection.6.1.1.1}%
\contentsline {subsubsection}{\numberline {6.1.1.2}Gradiente Descendente}{57}{subsubsection.6.1.1.2}%
\contentsline {subsubsection}{\numberline {6.1.1.3}Gradiente Descendente Estocástico}{58}{subsubsection.6.1.1.3}%
\contentsline {subsubsection}{\numberline {6.1.1.4}Clasificación}{58}{subsubsection.6.1.1.4}%
\contentsline {subsection}{\numberline {6.1.2}Aprendizaje no Supervisado}{58}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Aprendizaje Automático en este Trabajo}{58}{subsection.6.1.3}%
\contentsline {section}{\numberline {6.2}Visión por Computador}{59}{section.6.2}%
\contentsline {section}{\numberline {6.3}Deep Learning}{59}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Redes Neuronales}{59}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Back Propagation}{61}{subsection.6.3.2}%
\contentsline {section}{\numberline {6.4}Redes Neuronales Convolucionales}{62}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Capa Convolucional}{64}{subsection.6.4.1}%
\contentsline {subsection}{\numberline {6.4.2}Capa de Pooling}{65}{subsection.6.4.2}%
\contentsline {subsection}{\numberline {6.4.3}Capa Totalmente Conectada (Fully Conected)}{66}{subsection.6.4.3}%
\contentsline {subsection}{\numberline {6.4.4}Batch Normalization}{66}{subsection.6.4.4}%
\contentsline {subsection}{\numberline {6.4.5}Optimizador Adam}{66}{subsection.6.4.5}%
\contentsline {subsection}{\numberline {6.4.6}Proceso de entrenamiento de una CNN}{67}{subsection.6.4.6}%
\contentsline {subsection}{\numberline {6.4.7}Evolución de las CNN}{67}{subsection.6.4.7}%
\contentsline {subsubsection}{\numberline {6.4.7.1}LeNet-5}{67}{subsubsection.6.4.7.1}%
\contentsline {subsubsection}{\numberline {6.4.7.2}AlexNet}{68}{subsubsection.6.4.7.2}%
\contentsline {subsubsection}{\numberline {6.4.7.3}GoogLeNet}{68}{subsubsection.6.4.7.3}%
\contentsline {subsubsection}{\numberline {6.4.7.4}VGG-16}{69}{subsubsection.6.4.7.4}%
\contentsline {subsubsection}{\numberline {6.4.7.5}ResNet}{70}{subsubsection.6.4.7.5}%
\contentsline {section}{\numberline {6.5}Autoencoders}{71}{section.6.5}%
\contentsline {subsection}{\numberline {6.5.1}Introducción}{71}{subsection.6.5.1}%
\contentsline {subsection}{\numberline {6.5.2}Evolución de los Autoencoders}{72}{subsection.6.5.2}%
\contentsline {subsubsection}{\numberline {6.5.2.1}Generative Adversarial Networks (GANs)}{72}{subsubsection.6.5.2.1}%
\contentsline {subsubsection}{\numberline {6.5.2.2}Variational Autoencoder (VAE)}{72}{subsubsection.6.5.2.2}%
\contentsline {subsubsection}{\numberline {6.5.2.3}Adversarial Autoencoder(AAE)}{74}{subsubsection.6.5.2.3}%
\contentsline {section}{\numberline {6.6}Técnicas empleadas}{75}{section.6.6}%
\contentsline {subsection}{\numberline {6.6.1}Few-shot Learning y Data Augmentation}{75}{subsection.6.6.1}%
\contentsline {chapter}{\numberline {7}Estado del Arte}{77}{chapter.7}%
\contentsline {section}{\numberline {7.1}Localización de landmarks cefalométricos en imágenes}{77}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Evolución en la identificación forense de landmarks cefalométricos}{78}{subsection.7.1.1}%
\contentsline {subsubsection}{\numberline {7.1.1.1}Two diﬀerent approaches to handle landmark location uncertainty in skull-face overlay: coevolution vs fuzzy landmarks}{78}{subsubsection.7.1.1.1}%
\contentsline {subsubsection}{\numberline {7.1.1.2}Automatic craniofacial anthropometry landmarks detection and measurements for the orbital region}{80}{subsubsection.7.1.1.2}%
\contentsline {subsubsection}{\numberline {7.1.1.3}Automated facial landmark detection, comparison and visualization}{80}{subsubsection.7.1.1.3}%
\contentsline {subsubsection}{\numberline {7.1.1.4}Automatic cephalometric landmarks detection on frontal faces: An approach based on supervised learning techniques}{81}{subsubsection.7.1.1.4}%
\contentsline {subsubsection}{\numberline {7.1.1.5}The Improved Faster R-CNN for Detecting Small Facial Landmarks on Vietnamese Human Face Based on Clinical Diagnosis}{83}{subsubsection.7.1.1.5}%
\contentsline {subsection}{\numberline {7.1.2}Nuestra propuesta}{83}{subsection.7.1.2}%
\contentsline {chapter}{\numberline {8}Datos y Métricas}{87}{chapter.8}%
\contentsline {section}{\numberline {8.1}Datos del problema y framework empleado}{87}{section.8.1}%
\contentsline {subsection}{\numberline {8.1.1}Base de datos proporcionada}{87}{subsection.8.1.1}%
\contentsline {subsection}{\numberline {8.1.2}Red empleada: 3FabRec}{88}{subsection.8.1.2}%
\contentsline {subsubsection}{\numberline {8.1.2.1}Arquitectura Adversarial Autoencoder}{89}{subsubsection.8.1.2.1}%
\contentsline {subsubsection}{\numberline {8.1.2.2}Interleaved Transfer Layer (ITL)}{90}{subsubsection.8.1.2.2}%
\contentsline {subsection}{\numberline {8.1.3}Función de pérdida}{90}{subsection.8.1.3}%
\contentsline {subsection}{\numberline {8.1.4}Proceso de entrenamiento de la red}{91}{subsection.8.1.4}%
\contentsline {subsection}{\numberline {8.1.5}Bases de datos usadas por el framework}{92}{subsection.8.1.5}%
\contentsline {section}{\numberline {8.2}Metricas}{92}{section.8.2}%
\contentsline {subsection}{\numberline {8.2.1}SSIM}{92}{subsection.8.2.1}%
\contentsline {subsection}{\numberline {8.2.2}Average pixel error}{93}{subsection.8.2.2}%
\contentsline {subsection}{\numberline {8.2.3}MSE}{93}{subsection.8.2.3}%
\contentsline {chapter}{\numberline {9}Planificación e implementación}{99}{chapter.9}%
\contentsline {chapter}{\numberline {10}Experimentación}{101}{chapter.10}%
\contentsline {chapter}{\numberline {11}Conclusiones y Trabajos Futuros}{103}{chapter.11}%
\contentsline {chapter}{\numberline {A}Primer apéndice}{105}{appendix.Alph1}%
\contentsline {chapter}{Glosario}{107}{chapter*.13}%
\contentsline {chapter}{\nonumberline Bibliograf\'{\i }a}{109}{chapter*.14}%
