\babel@toc {spanish}{}
\contentsline {chapter}{\nonumberline Agradecimientos}{\es@scroman {vii}}{chapter*.2}%
\babel@toc {english}{}
\contentsline {chapter}{\nonumberline Abstract}{\es@scroman {xiii}}{chapter*.7}%
\babel@toc {spanish}{}
\contentsline {chapter}{\nonumberline Resumen}{\es@scroman {xv}}{chapter*.8}%
\contentsline {part}{\numberline {I}Análisis de Redes Convolucionales}{1}{part.1}%
\contentsline {chapter}{\numberline {1}Introducción}{3}{chapter.1}%
\contentsline {chapter}{\numberline {2}Modelización Matemática de una Red Neuronal Convolucional}{7}{chapter.2}%
\contentsline {section}{\numberline {2.1}De Fourier a las ondeletas de Littlewood-Paley}{7}{section.2.1}%
\contentsline {subsection}{\numberline {2.1.1}El módulo de la Transformada de Fourier}{7}{subsection.2.1.1}%
\contentsline {subsection}{\numberline {2.1.2}Alternativa: Las ondeletas}{12}{subsection.2.1.2}%
\contentsline {subsection}{\numberline {2.1.3}La Transformada de Littlewood-Paley}{16}{subsection.2.1.3}%
\contentsline {subsection}{\numberline {2.1.4}Convenios para futuras secciones}{19}{subsection.2.1.4}%
\contentsline {section}{\numberline {2.2}El operador de dispersión sobre un camino ordenado}{20}{section.2.2}%
\contentsline {subsection}{\numberline {2.2.1}Ejemplo para obtener coeficientes invariantes por traslaciones}{21}{subsection.2.2.1}%
\contentsline {subsection}{\numberline {2.2.2}El operador módulo}{22}{subsection.2.2.2}%
\contentsline {subsection}{\numberline {2.2.3}Definición de camino de frecuencias y propiedades.}{23}{subsection.2.2.3}%
\contentsline {subsection}{\numberline {2.2.4}Construcción del operador de dispersión.}{24}{subsection.2.2.4}%
\contentsline {section}{\numberline {2.3}Propagador de dispersión y conservación de la Norma}{26}{section.2.3}%
\contentsline {subsection}{\numberline {2.3.1}Proceso de dispersión del propagador.}{26}{subsection.2.3.1}%
\contentsline {subsection}{\numberline {2.3.2}Diferencias y similitudes con una CNN}{27}{subsection.2.3.2}%
\contentsline {subsection}{\numberline {2.3.3}Relación con herramientas clásicas de visión por computador}{28}{subsection.2.3.3}%
\contentsline {subsection}{\numberline {2.3.4}Operador no expansivo.}{28}{subsection.2.3.4}%
\contentsline {subsection}{\numberline {2.3.5}Conservación de la norma.}{29}{subsection.2.3.5}%
\contentsline {subsection}{\numberline {2.3.6}Conclusiones extraídas del teorema}{33}{subsection.2.3.6}%
\contentsline {chapter}{\numberline {3}Invarianza por Traslaciones}{35}{chapter.3}%
\contentsline {section}{\numberline {3.1}No expansividad del operador de ventana en conjuntos de caminos}{35}{section.3.1}%
\contentsline {section}{\numberline {3.2}Invarianza por traslaciones}{38}{section.3.2}%
\contentsline {chapter}{\numberline {4}Conclusiones y trabajos futuros}{43}{chapter.4}%
\contentsline {section}{\numberline {4.1}Trabajos futuros}{44}{section.4.1}%
\contentsline {part}{\numberline {II}Localización de landmarks cefalométricos por medio de técnicas de few-shot learning}{45}{part.2}%
\contentsline {chapter}{\numberline {5}Introducción}{47}{chapter.5}%
\contentsline {section}{\numberline {5.1}Descripción del problema y Motivación}{47}{section.5.1}%
\contentsline {subsection}{\numberline {5.1.1}Base de datos proporcionada}{49}{subsection.5.1.1}%
\contentsline {section}{\numberline {5.2}Requisitos mínimos del algoritmo}{51}{section.5.2}%
\contentsline {section}{\numberline {5.3}Objetivos}{52}{section.5.3}%
\contentsline {section}{\numberline {5.4}Planificación}{53}{section.5.4}%
\contentsline {chapter}{\numberline {6}Fundamentos Teóricos y Métodos}{57}{chapter.6}%
\contentsline {section}{\numberline {6.1}Aprendizaje Automático}{57}{section.6.1}%
\contentsline {subsection}{\numberline {6.1.1}Aprendizaje Supervisado}{58}{subsection.6.1.1}%
\contentsline {subsubsection}{\numberline {6.1.1.1}Regresión}{58}{subsubsection.6.1.1.1}%
\contentsline {subsubsection}{\numberline {6.1.1.2}Clasificación}{59}{subsubsection.6.1.1.2}%
\contentsline {subsubsection}{\numberline {6.1.1.3}Gradiente Descendente}{59}{subsubsection.6.1.1.3}%
\contentsline {subsubsection}{\numberline {6.1.1.4}Gradiente Descendente Estocástico}{60}{subsubsection.6.1.1.4}%
\contentsline {subsection}{\numberline {6.1.2}Aprendizaje no Supervisado}{60}{subsection.6.1.2}%
\contentsline {subsection}{\numberline {6.1.3}Aprendizaje Automático en este Trabajo}{60}{subsection.6.1.3}%
\contentsline {subsection}{\numberline {6.1.4}Visión por Computador}{61}{subsection.6.1.4}%
\contentsline {subsection}{\numberline {6.1.5}Deep Learning}{62}{subsection.6.1.5}%
\contentsline {subsubsection}{\numberline {6.1.5.1}Redes Neuronales}{62}{subsubsection.6.1.5.1}%
\contentsline {subsubsection}{\numberline {6.1.5.2}Backpropagation}{65}{subsubsection.6.1.5.2}%
\contentsline {section}{\numberline {6.2}Redes Neuronales Convolucionales}{65}{section.6.2}%
\contentsline {subsection}{\numberline {6.2.1}Capa Convolucional}{67}{subsection.6.2.1}%
\contentsline {subsection}{\numberline {6.2.2}Capa de Pooling}{69}{subsection.6.2.2}%
\contentsline {subsection}{\numberline {6.2.3}Capa Totalmente Conectada (Fully Conected)}{69}{subsection.6.2.3}%
\contentsline {subsection}{\numberline {6.2.4}Batch Normalization}{69}{subsection.6.2.4}%
\contentsline {subsection}{\numberline {6.2.5}Optimizador Adam}{70}{subsection.6.2.5}%
\contentsline {subsection}{\numberline {6.2.6}Proceso de entrenamiento de una CNN}{70}{subsection.6.2.6}%
\contentsline {section}{\numberline {6.3}Autoencoders}{70}{section.6.3}%
\contentsline {subsection}{\numberline {6.3.1}Introducción}{70}{subsection.6.3.1}%
\contentsline {subsection}{\numberline {6.3.2}Evolución de los Autoencoders}{71}{subsection.6.3.2}%
\contentsline {subsubsection}{\numberline {6.3.2.1}Generative Adversarial Networks (GANs)}{71}{subsubsection.6.3.2.1}%
\contentsline {subsubsection}{\numberline {6.3.2.2}Variational Autoencoder (VAE)}{72}{subsubsection.6.3.2.2}%
\contentsline {subsubsection}{\numberline {6.3.2.3}Adversarial Autoencoder(AAE)}{73}{subsubsection.6.3.2.3}%
\contentsline {section}{\numberline {6.4}Técnicas empleadas}{75}{section.6.4}%
\contentsline {subsection}{\numberline {6.4.1}Few-shot Learning y Data Augmentation}{75}{subsection.6.4.1}%
\contentsline {chapter}{\numberline {7}Estado del Arte}{77}{chapter.7}%
\contentsline {section}{\numberline {7.1}Localización de landmarks cefalométricos en imágenes}{77}{section.7.1}%
\contentsline {subsection}{\numberline {7.1.1}Evolución en la identificación forense de landmarks cefalométricos}{77}{subsection.7.1.1}%
\contentsline {chapter}{\numberline {8}Implementación}{83}{chapter.8}%
\contentsline {section}{\numberline {8.1}Diseño del Sofware}{83}{section.8.1}%
\contentsline {section}{\numberline {8.2}Entorno de ejecución}{85}{section.8.2}%
\contentsline {chapter}{\numberline {9}Solución propuesta y experimentos realizados}{89}{chapter.9}%
\contentsline {section}{\numberline {9.1}Framework empleado: 3FabRec}{90}{section.9.1}%
\contentsline {subsection}{\numberline {9.1.1}Arquitectura Adversarial Autoencoder}{91}{subsection.9.1.1}%
\contentsline {subsubsection}{\numberline {9.1.1.1}Interleaved Transfer Layer (ITL)}{92}{subsubsection.9.1.1.1}%
\contentsline {subsection}{\numberline {9.1.2}Función de pérdida}{95}{subsection.9.1.2}%
\contentsline {subsubsection}{\numberline {9.1.2.1}Modificación de la función de pérdida}{97}{subsubsection.9.1.2.1}%
\contentsline {subsection}{\numberline {9.1.3}Proceso de entrenamiento de la red}{97}{subsection.9.1.3}%
\contentsline {subsubsection}{\numberline {9.1.3.1}Entrenamiento no-supervisado}{97}{subsubsection.9.1.3.1}%
\contentsline {subsubsection}{\numberline {9.1.3.2}Entrenamiento supervisado}{97}{subsubsection.9.1.3.2}%
\contentsline {subsection}{\numberline {9.1.4}Bases de datos usadas por el framework}{98}{subsection.9.1.4}%
\contentsline {section}{\numberline {9.2}Métricas}{99}{section.9.2}%
\contentsline {subsection}{\numberline {9.2.1}Métricas usadas en el entrenamiento}{99}{subsection.9.2.1}%
\contentsline {subsubsection}{\numberline {9.2.1.1}MSE}{99}{subsubsection.9.2.1.1}%
\contentsline {subsection}{\numberline {9.2.2}Métricas empleadas en validación y testing}{99}{subsection.9.2.2}%
\contentsline {subsubsection}{\numberline {9.2.2.1}Error de reconstrucción}{99}{subsubsection.9.2.2.1}%
\contentsline {subsubsection}{\numberline {9.2.2.2}Normalized Mean Error}{99}{subsubsection.9.2.2.2}%
\contentsline {subsubsection}{\numberline {9.2.2.3}SSIM}{100}{subsubsection.9.2.2.3}%
\contentsline {section}{\numberline {9.3}Preprocesamiento de los datos}{101}{section.9.3}%
\contentsline {subsection}{\numberline {9.3.1}Identificación de caras en las imágenes}{101}{subsection.9.3.1}%
\contentsline {subsection}{\numberline {9.3.2}Creación del fichero annotations en el dataset}{103}{subsection.9.3.2}%
\contentsline {subsection}{\numberline {9.3.3}Reajuste de los bounding boxes}{103}{subsection.9.3.3}%
\contentsline {subsection}{\numberline {9.3.4}Separación en conjuntos de entrenamiento y validación}{106}{subsection.9.3.4}%
\contentsline {section}{\numberline {9.4}Experimentación}{107}{section.9.4}%
\contentsline {subsection}{\numberline {9.4.1}Hipótesis iniciales}{107}{subsection.9.4.1}%
\contentsline {subsection}{\numberline {9.4.2}Modelo Base}{107}{subsection.9.4.2}%
\contentsline {subsection}{\numberline {9.4.3}Modelo con reentrenamiento del encoder}{112}{subsection.9.4.3}%
\contentsline {subsection}{\numberline {9.4.4}Modelo con reentrenamiento del decoder}{115}{subsection.9.4.4}%
\contentsline {subsection}{\numberline {9.4.5}Modelo con Data Augmentation}{118}{subsection.9.4.5}%
\contentsline {subsection}{\numberline {9.4.6}Elección de modelo y obtención de resultados}{121}{subsection.9.4.6}%
\contentsline {section}{\numberline {9.5}Comparativa entre 3FabRec y HyperFace-ResNet101}{125}{section.9.5}%
\contentsline {subsection}{\numberline {9.5.1}Preprocesamiento y base de datos empleada}{126}{subsection.9.5.1}%
\contentsline {subsection}{\numberline {9.5.2}Métricas empleadas}{126}{subsection.9.5.2}%
\contentsline {subsection}{\numberline {9.5.3}Comparación de resultados}{126}{subsection.9.5.3}%
\contentsline {subsection}{\numberline {9.5.4}Conclusiones extraídas}{129}{subsection.9.5.4}%
\contentsline {chapter}{\numberline {10}Conclusiones y Trabajos Futuros}{131}{chapter.10}%
\contentsline {section}{\numberline {10.1}Objetivos Satisfechos}{132}{section.10.1}%
\contentsline {section}{\numberline {10.2}Trabajos Futuros y comentarios}{132}{section.10.2}%
\contentsline {chapter}{\nonumberline Bibliograf\'{\i }a}{135}{chapter*.26}%
\contentsline {chapter}{\nonumberline Apéndice A}{137}{chapter*.27}%
\contentsline {section}{\numberline {1}Resultados por imagen durante el entrenamiento del modelo base}{137}{section.Alph0.1}%
\contentsline {chapter}{\nonumberline Apéndice B}{143}{chapter*.28}%
\contentsline {section}{\numberline {1}Resultados por imagen durante el entrenamiento del modelo de entrenamiento del encoder}{143}{section.Alph0.1}%
\contentsline {chapter}{\nonumberline Apéndice C}{149}{chapter*.29}%
\contentsline {section}{\numberline {1}Resultados por imagen durante el entrenamiento del modelo de entrenamiento del decoder}{149}{section.Alph0.1}%
\contentsline {chapter}{\nonumberline Apéndice D}{155}{chapter*.30}%
\contentsline {section}{\numberline {1}Resultados por imagen durante el entrenamiento del modelo con data augmentation}{155}{section.Alph0.1}%
