\babel@toc {spanish}{}
\addvspace {10\p@ }
\babel@toc {english}{}
\addvspace {10\p@ }
\babel@toc {spanish}{}
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {5.1}{\ignorespaces Landmarks que se intentarán predecir.}}{50}{table.5.1}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {7.1}{\ignorespaces Taxonomía de los artículos publicados que componen el estado del arte en el campo actualmente. A modo de aclaración, por dataset controlado nos referimos al uso de datasets de imágenes tomadas en entornos controlados.}}{79}{table.7.1}%
\addvspace {10\p@ }
\contentsline {table}{\numberline {8.1}{\ignorespaces Argumentos con los que se ha experimentado en la ejecución del fichero train-aae-landmarks.py}}{86}{table.8.1}%
\addvspace {10\p@ }
\contentsline {table}{\numberline {9.1}{\ignorespaces Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo base.}}{106}{table.9.1}%
\contentsline {table}{\numberline {9.2}{\ignorespaces Media del error NME obtenido por landmark entre todas las particiones de cross-validation. Marcamos en amarillo el vertex pues no está correctamente marcado en todas las imágenes.}}{108}{table.9.2}%
\contentsline {table}{\numberline {9.3}{\ignorespaces Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo de ajuste fino del encoder.}}{110}{table.9.3}%
\contentsline {table}{\numberline {9.4}{\ignorespaces Tabla comparativa entre los dos modelos explorados por ahora. Medimos el NME medio a nivel de landmark. En verde se resalta el mejor valor de marcado para cada landmark.}}{111}{table.9.4}%
\contentsline {table}{\numberline {9.5}{\ignorespaces Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo de ajuste fino del decoder.}}{112}{table.9.5}%
\contentsline {table}{\numberline {9.6}{\ignorespaces Tabla comparativa entre los tres modelos probados. En este caso no se aprecia ninguna mejora considerable con respecto a las introducidas por el modelo de ajuste fino del encoder.}}{114}{table.9.6}%
\contentsline {table}{\numberline {9.7}{\ignorespaces Métricas obtenidas de la distribución de los errores cometidos en el conjunto de entrenamiento con el modelo de data augmentation.}}{115}{table.9.7}%
\contentsline {table}{\numberline {9.8}{\ignorespaces Tabla comparativa entre todos los modelos probados.}}{117}{table.9.8}%
\contentsline {table}{\numberline {9.9}{\ignorespaces Tabla comparativa entre los resultados del modelo de data augmentation en el conjunto de validación y test.}}{119}{table.9.9}%
\contentsline {table}{\numberline {9.10}{\ignorespaces Tabla comparativa a nivel global entre los dos modelos. Como podemos observar, el modelo basado en \textbf {HyperFace-Resnet101} obtiene mejores resultados en global en todos los campos.}}{122}{table.9.10}%
\contentsline {table}{\numberline {9.11}{\ignorespaces Tabla comparativa a nivel de landmarks entre el modelo final basado en 3FabRec y el de HyperFace-REsNet101.}}{123}{table.9.11}%
\addvspace {10\p@ }
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {table}{\numberline {1}{\ignorespaces Predicciones cross-validation modelo base. Primera partición.}}{133}{table.Alph0.1}%
\contentsline {table}{\numberline {2}{\ignorespaces Predicciones cross-validation modelo base. Segunda partición.}}{134}{table.Alph0.2}%
\contentsline {table}{\numberline {3}{\ignorespaces Predicciones cross-validation modelo base. Tercera partición.}}{135}{table.Alph0.3}%
\contentsline {table}{\numberline {4}{\ignorespaces Predicciones cross-validation modelo base. Cuarta partición.}}{136}{table.Alph0.4}%
\contentsline {table}{\numberline {5}{\ignorespaces Predicciones cross-validation modelo base. Cuarta partición.}}{137}{table.Alph0.5}%
\addvspace {10\p@ }
\contentsline {table}{\numberline {1}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Primera partición.}}{139}{table.Alph0.1}%
\contentsline {table}{\numberline {2}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Segunda partición.}}{140}{table.Alph0.2}%
\contentsline {table}{\numberline {3}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Tercera partición.}}{141}{table.Alph0.3}%
\contentsline {table}{\numberline {4}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Cuarta partición.}}{142}{table.Alph0.4}%
\contentsline {table}{\numberline {5}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del encoder. Quinta partición.}}{143}{table.Alph0.5}%
\addvspace {10\p@ }
\contentsline {table}{\numberline {1}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Primera partición.}}{145}{table.Alph0.1}%
\contentsline {table}{\numberline {2}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Segunda partición.}}{146}{table.Alph0.2}%
\contentsline {table}{\numberline {3}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Tercera partición.}}{147}{table.Alph0.3}%
\contentsline {table}{\numberline {4}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Cuarta partición.}}{148}{table.Alph0.4}%
\contentsline {table}{\numberline {5}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Quinta partición.}}{149}{table.Alph0.5}%
\addvspace {10\p@ }
\contentsline {table}{\numberline {1}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Primera partición.}}{151}{table.Alph0.1}%
\contentsline {table}{\numberline {2}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Segunda partición.}}{152}{table.Alph0.2}%
\contentsline {table}{\numberline {3}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Tercera partición.}}{153}{table.Alph0.3}%
\contentsline {table}{\numberline {4}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Cuarta partición.}}{154}{table.Alph0.4}%
\contentsline {table}{\numberline {5}{\ignorespaces Predicciones cross-validation modelo de ajuste fino del decoder. Quinta partición.}}{155}{table.Alph0.5}%
\addvspace {10\p@ }
