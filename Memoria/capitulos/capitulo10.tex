\chapter{Conclusiones y Trabajos Futuros}

\noindent La elaboración de este TFG ha sido un proceso de constante cambio y aprendizaje. Al comienzo constó de un periodo de asimilación de conceptos clave, familiarización con las CNN y con la arquitectura de red que se emplearía: el Adversarial Autoencoder. Tras esto comenzó una etapa de estudio minucioso del artículo donde se presentaba 3FabRec, a fin de comprender su funcionamiento a la perfección. Durante este periodo también se investigó acerca de los \textit{landmarks} faciales y su utilización en la resolución de problemas actuales de identificación de personas. Después se profundizó en el problema del marcado de \textit{landmarks} cefalométricos, entendiendo la diferencia entre estos y los faciales, investigando el estado del arte y aprendiendo su utilidad en procedimientos forenses. Finalmente, se implementaron todas las técnicas presentes en las distintas etapas de la experimentación: el preprocesamiento de los datos, el entrenamiento usando \textit{cross-validation 5 fold}, las técnicas de data augmentation y el ajuste fino del encoder y decoder. Tras esto se obtuvo un modelo final que obtenía en validación un NME promedio de todos los landmarks de $1.77$ y en el conjunto de test de $2.65$.

\medskip

\noindent Los resultados obtenidos con el modelo presentado son prometedores y, aunque se encuentran por debajo en media con respecto al modelo de \textit{HF-ResNet}, cabe destacar el hecho de que el dataset empleado para esta tarea se ha ceñido únicamente a las $167$ proporcionadas, sin añadir ejemplos, como los modelos $3D$ que se emplearon en el otro trabajo para aumentar el dataset, a excepción de técnicas de \textit{data augmentation} que únicamente duplicaron el conjunto de datos de entrenamiento. La mediana del RMSE cometido por nuestro modelo es de $5.3862$ píxeles de error, frente a los $3.4106$ del modelo basado en \textit{HyperFace}. Podemos así concluir que esta alternativa de \textit{few-shot} learning es prometedora, pues con muchos menos ejemplos de entrenamiento se consiguen resultados competentes. Además resuelve un problema importante y que como hemos explicado conlleva mucho tiempo para el experto forense. Con este método el experto tendría que revisar los landmarks predichos para evitar errores, pero ahorraría tiempo.

\medskip

\noindent Por otra parte, no es frecuente contar con modelos $3D$ en los laboratorios forenses con los que ampliar el dataset de entrenamiento del modelo. Esto hace de nuestro modelo basado en \textit{3FabRec} una alternativa más realista para este tipo de tareas, que logra buenos resultados con pocos ejemplos de entrenamiento.

\medskip

\noindent Finalmente, cabe destacar la adaptación del framework \textit{3FabRec} para poder realizar el entrenamiento de imágenes con landmarks faltantes. Recordemos que en los datasets de landmarks faciales empleados durante el entrenamiento original del framework (\textit{AFLW}, \textit{300W} o \textit{WFLW}), en cada imagen de entrenamiento se encontraban todos los landmarks que se iban a predecir marcados. En nuestro caso hemos modificado la función de coste de la fase de aprendizaje supervisado de la red (el MSE entre los mapas de calor) para que, en cada mini batch de entrenamiento, tome en consideración únicamente los landmarks realmente presentes en las imágene, aquellos cuyas coordenadas no son $(-1,-1)$. Esto aumenta el potencial y la capacidad del framework para entrenar datasets más complejos y realistas, en los que hay valores perdidos.

\section{Objetivos Satisfechos}

Todos los objetivos que se habían propuesto al comienzo de este trabajo se han visto realizados con éxito:

\begin{enumerate}
    \item Se ha realizado una minuciosa investigación sobre el \textbf{estado del arte} en el campo concluyendo que estamos en una vía de estudio de la que apenas hay artículos publicados. Además, hemos resumido y estudiado todas las propuestas de los pocos trabajos encontrados relacionados con el problema de forma directa, con el fin de conocer qué vías se han explorado para su resolución con anterioridad.
    \item Hemos realizado un estudio para observar la \textbf{evolución} de los Autoencoders y las redes Adversarias, comenzando por describir lo que es un Autoencoder clásico, las novedades que incorporan las GANs, la aparición de los VAE, y finalmente la combinación de ambos en la arquitectura del AAE.
    \item Se ha realizado un \textbf{estudio de la base de datos} proporcionada viendo la frecuencia de aparición de landmarks en cada imagen, así como el rendimiento del detector de caras sobre las imágenes del dataset agrupadas por frontales, de perfil o $3/4$. Con esto se pudo hacer una estimación de los landmarks que serían más difíciles de predecir y se descartaron tres imágenes debido a que el detector de caras no pudo reconocer ninguna en las mismas. Con estos resultados, se construyó un \textbf{nuevo dataset} compuesto por las imágenes usadas finalmente junto con los \textit{bounding boxes} asociados a fin de que el framework realizara el cropping sobre las imágenes antes de ser usadas por la red.
    \item Finalmente se realizó un \textbf{estudio experimental} en el cual se probaron diversas técnicas para predecir los landmarks. En primer lugar se optó por entrenar las ITLs de la red a partir del conocimiento previo de la red en el dataset \textit{AFLW} (elegido por compartir características con el nuestro), se vieron que los resultados eran buenos pero los errores de reconstrucción altos. Tras esto se optó por tratar de reducir los errores de reconstrucción a ver si así mejoraba el marcado de landmarks, se entrenaron las ITLs de la red junto con el \textit{encoder} dejando congelados los pesos del \textit{decoder} y luego se repitió el mismo experimento pero entrenando el \textit{decoder} y congelando el \textit{encoder}. Los resultados de estos experimentos no fueron satisfactorios pues el error de reconstrucción apenas bajó y el marcado de landmarks no mejoró. Finalmente se optó por aplicar técnicas de \textit{Data augmentation} sobre el dataset original duplicándolo en tamaño. Realizando traslaciones, rotaciones y oclusiones parciales de forma aleatoria sobre cada imagen. Este último modelo fue entrenado durante $80$ épocas en total y obtuvo una mejora considerable de los resultados con respecto a los anteriores y fue el elegido como modelo final. Los resultados por landmark pueden consultarse en la \autoref{table:FinalModel_landmarks}.
\end{enumerate}


\section{Trabajos Futuros y comentarios}

\noindent Ante los resultados obtenidos en esta investigación, posibles vías de trabajo futuras podrían ser:

\begin{enumerate}
    \item La integración del modelo en un proceso real de detección del landmarks cefalométricos por parte de un equipo de expertos y estudiar su rendimiento y precisión.
    \item Realizar un ajuste fino previo de la parte no supervisada de la red para aprender a mejorar la reconstrucción de caras en imágenes de baja calidad, en escalas de grises y en distintas posiciones. Además, emplear un bounding box apropiado que permita ver correctamente todos los landmarks presentes en la imagen. Con todos estos cambios, ver el impacto en la mejora de la reconstrucción de las imágenes en el marcado de landmarks.
    \item Extender el conjunto de datos proporcionado aplicando diversas técnicas de \textit{data augmentation} a cada imagen del dataset, con el fin de mejorar aún más la precisión del marcado con más ejemplos de entrenamiento para el modelo.
\end{enumerate}

\medskip

\noindent Para finalizar, la realización de este trabajo fin de grado ha sido todo un reto. Hemos abordado un problema de la vida real abierto, del cual no hay artículos publicados y apenas técnicas que automaticen dicho proceso. El trabajo me ha permitido combinar todo el conocimiento adquirido en la carrera, sobre todo en el ámbito del aprendizaje automático y la visión por computador con otras nuevas destrezas propias de un trabajo de iniciación a la investigación y ponerlo en práctica con un caso práctico real, así como aprender a tomar decisiones sobre distintos procesos del problema. También he aprendido que en la vida real no siempre vamos a contar con todos los recursos necesarios para poder experimentar todo lo que se quiera, esto lleva a tener que decidir sobre qué vale la pena y que no explorar. Podemos concluir con este trabajo, que el aprendizaje automático, y más concretamente el \textit{deep learning}, tiene herramientas muy potentes que pueden ser de gran utilidad para tareas relacionadas con el procesamiento de imágenes. Como vimos, hay muchos artículos relacionado con el marcado de landmarks en imágenes por medio de técnicas de \textit{deep learning}. Sin embargo, estas herramientas también pueden tener un gran rendimiento en tareas más especializadas como por ejemplo en el marcado de landmarks \textit{cefalométricos} dentro del ámbito de la Antropología Forense y sin tener que contar con un gran número de ejemplos de entrenamiento, como ha quedado de manifiesto en los resultados obtenidos.


\endinput
%------------------------------------------------------------------------------------
% FIN DEL CAPÍTULO. 
%------------------------------------------------------------------------------------

