{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Particiones de los datos\n",
    "\n",
    "A continuaci칩n realizaremos las particiones de los datos en conjunto de entrenamiento y test. En primer lugar importamos todos los paquetes necesarios y establecemos una semilla para que los procesos aleatorios sean reproducibles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from facenet_pytorch import MTCNN\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io, transform\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import os\n",
    "workers = 0 if os.name == 'nt' else 4\n",
    "import numpy as np\n",
    "import cv2\n",
    "from PIL import Image, ImageDraw\n",
    "from IPython import display\n",
    "import matplotlib.patches as patches\n",
    "import shutil as sh\n",
    "import random\n",
    "import re\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "#SET SEED\n",
    "random.seed(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci칩n se definen las principales funciones empleadas y la clase que encapsula un dataset de im치genes con landmarks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main functions\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n",
    "def create_train_test_datasets(path,train_percentage=0.8,test_percentaje=0.2):\n",
    "    ids = list(range(164))\n",
    "    random.shuffle(ids)\n",
    "    num_images=len(ids)\n",
    "    num_images_train=int(num_images)*train_percentage\n",
    "    train_indices=ids[:int(num_images_train)]\n",
    "    #Create folders\n",
    "    if (os.path.isdir(\"./FORENSE_AM_TRAIN\")==False):\n",
    "        os.mkdir(\"./FORENSE_AM_TRAIN\")\n",
    "    if (os.path.isdir(\"./FORENSE_AM_TEST\")==False):\n",
    "        os.mkdir(\"./FORENSE_AM_TEST\")\n",
    "    os.chdir(path)\n",
    "    # iteramos en los archivos y los separamos en entrenamiento y test \n",
    "    i=0\n",
    "    files=sorted(os.listdir(), key=numericalSort)\n",
    "    os.chdir(\"..\")\n",
    "    for j in range(len(files)):\n",
    "        if i in train_indices:\n",
    "            sh.move(\"./FORENSE_AM/\"+files[j],\"./FORENSE_AM_TRAIN/\"+files[j])\n",
    "            if files[j].endswith(\".pts\"):\n",
    "                i+=1\n",
    "        else:\n",
    "            sh.move(\"./FORENSE_AM/\"+files[j],\"./FORENSE_AM_TEST/\"+files[j])\n",
    "            if files[j].endswith(\".pts\"):\n",
    "                test_indices.append(i)\n",
    "                i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Class \n",
    "def readLandmarks(landmarks_dir,alpha):\n",
    "        os.chdir(landmarks_dir)\n",
    "        fnames=[]\n",
    "        ids=[]\n",
    "        masks=[]\n",
    "        landmarks_list=[]\n",
    "        face_x=[]\n",
    "        face_y=[]\n",
    "        face_w=[]\n",
    "        face_h=[]\n",
    "        \n",
    "        # iteramos en los archivos y rellenamos los 4 primeros\n",
    "        i=0\n",
    "        for file in sorted(os.listdir(), key=numericalSort):\n",
    "            # Check whether file is in text format or not\n",
    "            if file.endswith(\".jpg\") or file.endswith(\".JPG\"):\n",
    "                image_file=file\n",
    "                fnames.append(image_file)\n",
    "                ids.append(i)\n",
    "                # Construimos las BB\n",
    "                image = io.imread(image_file)\n",
    "                if(len(image.shape)<3):\n",
    "                    #Grey scale to RGB\n",
    "                    image=np.array([image,image,image])\n",
    "                    image=np.moveaxis(image, 0, -1)\n",
    "                bb,prob=mtcnn.detect(image)\n",
    "                if file=='47_2.jpg':\n",
    "                    print(\"File 55 cuidado \", file)\n",
    "                    face_x.append(bb[1,0])\n",
    "                    face_y.append(bb[1,1]-5)\n",
    "                    face_w.append(abs(bb[1,0]-bb[1,2]))\n",
    "                    face_h.append(abs(bb[1,1]-bb[1,3])*alpha)\n",
    "                elif file=='47_4.jpg':\n",
    "                    print(\"File 57 cuidado \", file)\n",
    "                    face_x.append(bb[2,0])\n",
    "                    face_y.append(bb[2,1]-5)\n",
    "                    face_w.append(abs(bb[2,0]-bb[2,2]))\n",
    "                    face_h.append(abs(bb[2,1]-bb[2,3])*alpha)\n",
    "                else:\n",
    "                    print(\"File \", i , \"name: \", file)\n",
    "                    face_x.append(bb[0,0])\n",
    "                    face_y.append(bb[0,1]-5)\n",
    "                    face_w.append(abs(bb[0,0]-bb[0,2]))\n",
    "                    face_h.append(abs(bb[0,1]-bb[0,3])*alpha)\n",
    "                i+=1\n",
    "\n",
    "            if file.endswith(\".pts\"):\n",
    "                with open(file) as f:\n",
    "                    lines=f.readlines()\n",
    "                    \n",
    "                count=0\n",
    "                landmarks=[]\n",
    "                mask=[]\n",
    "                for line in lines: \n",
    "                    count +=1\n",
    "                    if(count >= 4 and count<=33):\n",
    "                        vector=[int(i) for i in line.split()]\n",
    "                        if(vector[0]==-1):\n",
    "                            mask.append(0)\n",
    "                        else:\n",
    "                            mask.append(1)\n",
    "                        landmarks.append(vector)\n",
    "                \n",
    "                landmarks_list.append(landmarks)\n",
    "                masks.append(mask)\n",
    "        \n",
    "        df=pd.DataFrame({\n",
    "            'fnames':fnames,\n",
    "            'ra':ids,\n",
    "            'landmarks_full':landmarks_list,\n",
    "            'masks': masks,\n",
    "            'face_x': face_x,\n",
    "            'face_y': face_y,\n",
    "            'face_w': face_w,\n",
    "            'face_h': face_h\n",
    "        })\n",
    "        print(df)\n",
    "        os.chdir(\"..\")\n",
    "        return df\n",
    "    \n",
    "class FaceLandmarksDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self,root_dir, alpha, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.landmarks_frame = readLandmarks(root_dir,alpha)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.landmarks_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.landmarks_frame.iloc[idx,0])\n",
    "        image = io.imread(img_name)\n",
    "        landmarks = self.landmarks_frame.iloc[idx, 2]\n",
    "        landmarks = np.array(landmarks)\n",
    "        landmarks = np.array([np.array(x) for x in landmarks])\n",
    "        bb=[self.landmarks_frame.iloc[idx,4],self.landmarks_frame.iloc[idx,5],self.landmarks_frame.iloc[idx,6],self.landmarks_frame.iloc[idx,7]]\n",
    "        sample = {'fname': image, 'landmarks': landmarks, 'bb':bb}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creamos las particiones de los datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_train_test_datasets(\"./FORENSE_AM\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicializamos el detector de caras:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create face detector\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "mtcnn = MTCNN(image_size=128,margin=0,select_largest=False, device=device)\n",
    "help(MTCNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "creamos el fichero *annotations.csv* en el cual almacenaremos para casa imagen la informaci칩n necesaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#face_dataset=FaceLandmarksDataset('./FORENSE_AM',1.1)\n",
    "#face_dataset.landmarks_frame.to_csv('./FORENSE_AM/annotations.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "face_dataset_train=FaceLandmarksDataset('./FORENSE_AM_TRAIN',1.1)\n",
    "face_dataset_train.landmarks_frame.to_csv('./FORENSE_AM_TRAIN/annotations.csv')\n",
    "face_dataset_test=FaceLandmarksDataset('./FORENSE_AM_TEST',1.1)\n",
    "face_dataset_test.landmarks_frame.to_csv('./FORENSE_AM_TEST/annotations.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos algunos ejemplos de bounding boxes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rendimeinto del detector de caras en el dataset \n",
    "for i in range(164):\n",
    "    image=face_dataset[i]['fname']\n",
    "    fig,ax=plt.subplots()\n",
    "    ax.imshow(image)\n",
    "    rect=patches.Rectangle((face_dataset[i]['bb'][0],face_dataset[i]['bb'][1]),face_dataset[i]['bb'][2],face_dataset[i]['bb'][3], linewidth=1,edgecolor='r',facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "\n",
    "    plt.show\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
